{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BentoML Example : Multiple Models with JsonInput\n",
    "# Titanic Survival Prediction with Xgboost and Lightgbm\n",
    "\n",
    "This is a BentoML Demo Project demonstrating how to package and serve LightBGM model for production using BentoML.\n",
    "\n",
    "[BentoML](http://bentoml.ai) is an open source platform for machine learning model serving and deployment.\n",
    "\n",
    "In this example, we will use scikit-learn API for both `xgboost` and `lightgbm`. In general, we can use any python model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "download dataset from https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 60302  100 60302    0     0   336k      0 --:--:-- --:--:-- --:--:--  336k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28210  100 28210    0     0   202k      0 --:--:-- --:--:-- --:--:--  202k\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir data\n",
    "curl https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv -o ./data/train.csv\n",
    "curl https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/test.csv -o ./data/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.pop(\"Survived\")\n",
    "cols = [\"Pclass\", \"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df[cols], y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier()\n",
    "lgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRFClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bytree=1, gamma=0, gpu_id=-1, importance_type='gain',\n",
       "                interaction_constraints='', max_delta_step=0, max_depth=6,\n",
       "                min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "                n_estimators=100, n_jobs=0, num_parallel_tree=100,\n",
       "                objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "                scale_pos_weight=1, tree_method='exact', validate_parameters=1,\n",
       "                verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRFClassifier()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"xgb\": xgb_model, \"lgb\": lgb_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BentoService for model serving\n",
    "We are going to use `JsonInput` and return the data as `JSON` object. `JSON` objects are passed as a **list**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting multiple_models_titanic_bento_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multiple_models_titanic_bento_service.py\n",
    "\n",
    "import json\n",
    "\n",
    "import bentoml\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from bentoml.adapters import JsonInput\n",
    "from bentoml.artifact import SklearnModelArtifact\n",
    "\n",
    "\n",
    "@bentoml.artifacts([SklearnModelArtifact(\"xgb\"), SklearnModelArtifact(\"lgb\")])\n",
    "@bentoml.env(\n",
    "    conda_channels=[\"conda-forge\"],\n",
    "    conda_dependencies=[\"lightgbm==2.3.*\", \"pandas==1.0.*\", \"xgboost==1.2.*\"],\n",
    ")\n",
    "class TitanicSurvivalPredictionService(bentoml.BentoService):\n",
    "    @bentoml.api(input=JsonInput())\n",
    "    def predict(self, datain):\n",
    "        # datain is a list of a json object.\n",
    "        df = pd.read_json(json.dumps(datain[0]), orient=\"table\")\n",
    "\n",
    "        data = df[[\"Pclass\", \"Age\", \"Fare\", \"SibSp\", \"Parch\"]]\n",
    "        result = pd.DataFrame()\n",
    "        result[\"xgb_proba\"] = self.artifacts.xgb.predict_proba(data)[:, 1]\n",
    "        result[\"lgb_proba\"] = self.artifacts.lgb.predict_proba(data)[:, 1]\n",
    "        # make sure to return as a list of json\n",
    "        return [result.to_json(orient=\"table\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save BentoML service archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-08-25 13:47:58,242] INFO - BentoService bundle 'TitanicSurvivalPredictionService:20200825134757_086746' saved to: /Users/thein/bentoml/repository/TitanicSurvivalPredictionService/20200825134757_086746\n"
     ]
    }
   ],
   "source": [
    "# 1) import the custom BentoService defined above\n",
    "from multiple_models_titanic_bento_service import TitanicSurvivalPredictionService\n",
    "\n",
    "# 2) `pack` it with required artifacts\n",
    "bento_service = TitanicSurvivalPredictionService()\n",
    "bento_service.pack(\"xgb\", xgb_model)\n",
    "bento_service.pack(\"lgb\", lgb_model)\n",
    "\n",
    "# 3) save your BentoSerivce\n",
    "saved_path = bento_service.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved BentoService for serving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-08-25 13:47:58,780] WARNING - Module `multiple_models_titanic_bento_service` already loaded, using existing imported module.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import bentoml\n",
    "\n",
    "bento_model = bentoml.load(saved_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Containerize REST API server with Docker\n",
    "\n",
    "\n",
    "The BentoService SavedBundle is structured to work as a docker build context, that can be directed used to build a docker image for API server. Simply use it as the docker build context directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  551.4kB\n",
      "Step 1/15 : FROM bentoml/model-server:0.8.5\n",
      " ---> 6639eed59dc6\n",
      "Step 2/15 : COPY . /bento\n",
      " ---> 8916c6323930\n",
      "Step 3/15 : WORKDIR /bento\n",
      " ---> Running in e8a222116d35\n",
      "Removing intermediate container e8a222116d35\n",
      " ---> ba725f7ade92\n",
      "Step 4/15 : ARG PIP_INDEX_URL=https://pypi.python.org/simple/\n",
      " ---> Running in e194a9e5087c\n",
      "Removing intermediate container e194a9e5087c\n",
      " ---> bfe333f7f373\n",
      "Step 5/15 : ARG PIP_TRUSTED_HOST=pypi.python.org\n",
      " ---> Running in dbf5f680e79d\n",
      "Removing intermediate container dbf5f680e79d\n",
      " ---> 0c9fc4ae7489\n",
      "Step 6/15 : ENV PIP_INDEX_URL $PIP_INDEX_URL\n",
      " ---> Running in cb44a811259f\n",
      "Removing intermediate container cb44a811259f\n",
      " ---> 7a6e44b43f45\n",
      "Step 7/15 : ENV PIP_TRUSTED_HOST $PIP_TRUSTED_HOST\n",
      " ---> Running in bca323581f0b\n",
      "Removing intermediate container bca323581f0b\n",
      " ---> 8f1f8b11a2d2\n",
      "Step 8/15 : RUN chmod +x /bento/bentoml-init.sh\n",
      " ---> Running in 3ddc42cb25c2\n",
      "Removing intermediate container 3ddc42cb25c2\n",
      " ---> 9b890a10990e\n",
      "Step 9/15 : RUN if [ -f /bento/bentoml-init.sh ]; then bash -c /bento/bentoml-init.sh; fi\n",
      " ---> Running in 5c32936f764e\n",
      "\u001b[91m+++ dirname /bento/bentoml-init.sh\n",
      "\u001b[0m\u001b[91m++ cd /bento\n",
      "++ pwd -P\n",
      "\u001b[0m\u001b[91m+ SAVED_BUNDLE_PATH=/bento\n",
      "+ cd /bento\n",
      "+ '[' -f ./setup.sh ']'\n",
      "\u001b[0m\u001b[91m+ command -v conda\n",
      "\u001b[0m\u001b[91m+ conda env update -n base -f ./environment.yml\n",
      "\u001b[0mCollecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "mkl-service-2.3.0    | 218 KB    | ########## | 100% \n",
      "xgboost-1.2.0        | 11 KB     | ########## | 100% \n",
      "intel-openmp-2020.1  | 780 KB    | ########## | 100% \n",
      "pip-20.2.2           | 1.8 MB    | ########## | 100% \n",
      "mkl-2020.1           | 129.0 MB  | ########## | 100% \n",
      "python-dateutil-2.8. | 215 KB    | ########## | 100% \n",
      "pytz-2020.1          | 184 KB    | ########## | 100% \n",
      "scipy-1.5.2          | 14.3 MB   | ########## | 100% \n",
      "certifi-2020.6.20    | 156 KB    | ########## | 100% \n",
      "python_abi-3.7       | 4 KB      | ########## | 100% \n",
      "libxgboost-1.2.0     | 3.1 MB    | ########## | 100% \n",
      "numpy-1.19.1         | 21 KB     | ########## | 100% \n",
      "py-xgboost-1.2.0     | 1.7 MB    | ########## | 100% \n",
      "openssl-1.1.1g       | 2.5 MB    | ########## | 100% \n",
      "mkl_random-1.1.1     | 322 KB    | ########## | 100% \n",
      "pandas-1.0.5         | 7.8 MB    | ########## | 100% \n",
      "joblib-0.16.0        | 210 KB    | ########## | 100% \n",
      "scikit-learn-0.23.1  | 5.0 MB    | ########## | 100% \n",
      "_py-xgboost-mutex-2. | 9 KB      | ########## | 100% \n",
      "numpy-base-1.19.1    | 4.1 MB    | ########## | 100% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "ca-certificates-2020 | 125 KB    | ########## | 100% \n",
      "threadpoolctl-2.1.0  | 17 KB     | ########## | 100% \n",
      "lightgbm-2.3.0       | 936 KB    | ########## | 100% \n",
      "libgfortran-ng-7.3.0 | 1006 KB   | ########## | 100% \n",
      "mkl_fft-1.1.0        | 143 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate base\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.2\n",
      "  latest version: 4.8.4\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[91m+ pip install -r ./requirements.txt --no-cache-dir\n",
      "\u001b[0mLooking in indexes: https://pypi.python.org/simple/\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from -r ./requirements.txt (line 1)) (0.23.1)\n",
      "Requirement already satisfied: bentoml==0.8.5 in /opt/conda/lib/python3.7/site-packages (from -r ./requirements.txt (line 2)) (0.8.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->-r ./requirements.txt (line 1)) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->-r ./requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->-r ./requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->-r ./requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.8.7)\n",
      "Requirement already satisfied: configparser in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (5.0.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.3.18)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (2020.6.20)\n",
      "Requirement already satisfied: cerberus in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (3.6.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (20.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (3.12.4)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (4.3.0)\n",
      "Requirement already satisfied: grpcio<=1.27.2 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.27.2)\n",
      "Collecting python-dateutil<2.8.1,>=2.1\n",
      "  Downloading python_dateutil-2.8.0-py2.py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (2.22.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.8.0)\n",
      "Requirement already satisfied: gunicorn in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (20.0.4)\n",
      "Requirement already satisfied: humanfriendly in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (8.2)\n",
      "Requirement already satisfied: flask in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (7.1.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (5.7.2)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.14.39)\n",
      "Requirement already satisfied: multidict in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (4.7.6)\n",
      "Requirement already satisfied: python-json-logger in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.1.11)\n",
      "Requirement already satisfied: alembic in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: py-zipkin in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.20.0)\n",
      "Requirement already satisfied: sqlalchemy-utils in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.36.8)\n",
      "Requirement already satisfied: ruamel.yaml>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.15.87)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from cerberus->bentoml==0.8.5->-r ./requirements.txt (line 2)) (45.2.0.post20200210)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.8.5->-r ./requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.8.5->-r ./requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.8.5->-r ./requirements.txt (line 2)) (19.3.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->bentoml==0.8.5->-r ./requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker->bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.57.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.8.5->-r ./requirements.txt (line 2)) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.25.8)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from flask->bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from flask->bentoml==0.8.5->-r ./requirements.txt (line 2)) (2.11.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from flask->bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.39 in /opt/conda/lib/python3.7/site-packages (from boto3->bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.17.39)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.1.3)\n",
      "Requirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic->bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.0.4)\n",
      "Requirement already satisfied: thriftpy2>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from py-zipkin->bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.4.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->bentoml==0.8.5->-r ./requirements.txt (line 2)) (3.7.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask->bentoml==0.8.5->-r ./requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.39->boto3->bentoml==0.8.5->-r ./requirements.txt (line 2)) (0.15.2)\n",
      "Requirement already satisfied: ply<4.0,>=3.4 in /opt/conda/lib/python3.7/site-packages (from thriftpy2>=0.4.0->py-zipkin->bentoml==0.8.5->-r ./requirements.txt (line 2)) (3.11)\n",
      "Installing collected packages: python-dateutil\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "Successfully installed python-dateutil-2.8.0\n",
      "\u001b[91m+ for filename in ./bundled_pip_dependencies/*.tar.gz\n",
      "+ '[' -e './bundled_pip_dependencies/*.tar.gz' ']'\n",
      "+ continue\n",
      "\u001b[0mRemoving intermediate container 5c32936f764e\n",
      " ---> 089fdb91acb3\n",
      "Step 10/15 : ENV PORT 5000\n",
      " ---> Running in f2c62158d05f\n",
      "Removing intermediate container f2c62158d05f\n",
      " ---> 0d33795106f8\n",
      "Step 11/15 : EXPOSE $PORT\n",
      " ---> Running in b4fb56d2e1c6\n",
      "Removing intermediate container b4fb56d2e1c6\n",
      " ---> df14a798ba76\n",
      "Step 12/15 : COPY docker-entrypoint.sh /usr/local/bin/\n",
      " ---> 9e24b68d273d\n",
      "Step 13/15 : RUN chmod +x /usr/local/bin/docker-entrypoint.sh\n",
      " ---> Running in 0ad73aa6f6f0\n",
      "Removing intermediate container 0ad73aa6f6f0\n",
      " ---> c608332dd924\n",
      "Step 14/15 : ENTRYPOINT [ \"docker-entrypoint.sh\" ]\n",
      " ---> Running in efee5b711dbf\n",
      "Removing intermediate container efee5b711dbf\n",
      " ---> d055e40fe3f9\n",
      "Step 15/15 : CMD [\"bentoml\", \"serve-gunicorn\", \"/bento\"]\n",
      " ---> Running in 3e0c629cfb1f\n",
      "Removing intermediate container 3e0c629cfb1f\n",
      " ---> fa9a266c2e10\n",
      "Successfully built fa9a266c2e10\n",
      "Successfully tagged multi_models_titanic:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t multi_models_titanic {saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can docker push the image to your choice of registry for deployment, or run it locally for development and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Conflict. The container name \"/multi_models_titanic\" is already in use by container \"c02d33542a30598a3fc3208f5a1eacfaa3468dc0269831b38a401c9f2ca3891d\". You have to remove (or rename) that container to be able to reuse that name.\n",
      "See 'docker run --help'.\n"
     ]
    }
   ],
   "source": [
    "# port forward to 7000 \n",
    "!docker run -d -p 7000:5000 --name multi_models_titanic multi_models_titanic --enable-microbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-08-25 02:14:10,050] INFO - Starting BentoML API server in production mode..\n",
      "[2020-08-25 02:14:10,640] INFO - get_gunicorn_num_of_workers: 4, calculated by cpu count\n",
      "[2020-08-25 02:14:10,653] INFO - Running micro batch service on :5000\n",
      "[2020-08-25 02:14:10 +0000] [1] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-08-25 02:14:10 +0000] [8] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-08-25 02:14:10 +0000] [8] [INFO] Listening at: http://0.0.0.0:5000 (8)\n",
      "[2020-08-25 02:14:10 +0000] [8] [INFO] Using worker: aiohttp.worker.GunicornWebWorker\n",
      "[2020-08-25 02:14:10 +0000] [1] [INFO] Listening at: http://0.0.0.0:60115 (1)\n",
      "[2020-08-25 02:14:10 +0000] [1] [INFO] Using worker: sync\n",
      "[2020-08-25 02:14:10 +0000] [9] [INFO] Booting worker with pid: 9\n",
      "[2020-08-25 02:14:10 +0000] [10] [INFO] Booting worker with pid: 10\n",
      "[2020-08-25 02:14:10,727] INFO - Micro batch enabled for API `predict`\n",
      "[2020-08-25 02:14:10,727] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
      "[2020-08-25 02:14:10 +0000] [11] [INFO] Booting worker with pid: 11\n",
      "[2020-08-25 02:14:10 +0000] [12] [INFO] Booting worker with pid: 12\n",
      "[2020-08-25 02:14:10 +0000] [13] [INFO] Booting worker with pid: 13\n"
     ]
    }
   ],
   "source": [
    "#check docker log to make sure there are no errors.\n",
    "!docker logs multi_models_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your running docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the content type in the request headers\n",
    "scoring_uri = \"http://localhost:7000/predict\"\n",
    "headers = {\"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = X_test.to_json(orient=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.post(scoring_uri, sample_data, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check your status\n",
    "result.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb_proba</th>\n",
       "      <th>lgb_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.294599</td>\n",
       "      <td>0.380532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.389786</td>\n",
       "      <td>0.381437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.263238</td>\n",
       "      <td>0.245288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801193</td>\n",
       "      <td>0.832492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311078</td>\n",
       "      <td>0.454472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   xgb_proba  lgb_proba\n",
       "0   0.294599   0.380532\n",
       "1   0.389786   0.381437\n",
       "2   0.263238   0.245288\n",
       "3   0.801193   0.832492\n",
       "4   0.311078   0.454472"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert your prediction back to json\n",
    "pd.read_json(result.json(), orient=\"table\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
