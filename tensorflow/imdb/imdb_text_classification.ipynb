{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# Text classification: Classify reviews of imdb\n",
    "\n",
    "**BentoML makes moving trained ML models to production easy:**\n",
    "\n",
    "* Package models trained with **any ML framework** and reproduce them for model serving in production\n",
    "* **Deploy anywhere** for online API serving or offline batch serving\n",
    "* High-Performance API model server with *adaptive micro-batching* support\n",
    "* Central hub for managing models and deployment process via Web UI and APIs\n",
    "* Modular and flexible design making it *adaptable to your infrastrcuture*\n",
    "\n",
    "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=tensorflow&ea=imdb_text_classification&dt=imdb_text_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ruhan/work_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q bentoml tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant variables\n",
    "MAX_WORDS = 10000\n",
    "REVIEW_CLASSES = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zXXx5Oc3pOmN"
   },
   "outputs": [],
   "source": [
    "## download dataset from keras.\n",
    "\n",
    "# 10000 high-frequency vocabulary\n",
    "(_X_train, _y_train), (_X_test, _y_test) = keras.datasets.imdb.load_data(num_words=MAX_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y8qCnve_-lkO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (25000,)\n",
      "y_train shape:(25000,)\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the data\n",
    "print(\"X_train shape: {}\\ny_train shape:{}\".format(_X_train.shape, _y_train.shape))\n",
    "print(type(_X_train.shape))\n",
    "_X_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wJg2FiYpuoX"
   },
   "source": [
    "## Reverse Word Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tr5s_1alpzop"
   },
   "outputs": [],
   "source": [
    "# word_index[<str>] = <int>\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  \n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# word_index.items  <str> to <int>\n",
    "# reverse_word_index <int> to <str>\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '#') for i in text])\n",
    "\n",
    "# <str> to <int>\n",
    "def encode_review(text):\n",
    "    words = text.split(' ')\n",
    "    ids = [word_index[\"<START>\"]]\n",
    "    for w in words:\n",
    "        v = word_index.get(w, word_index[\"<UNK>\"])\n",
    "        # >1000, signed as <UNUSED>\n",
    "        if v > MAX_WORDS:\n",
    "            v = word_index[\"<UNUSED>\"]\n",
    "        ids.append(v)\n",
    "    return ids    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFP_XKVRp4_S"
   },
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2jQv-omsHurp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (25000, 256) int32 int32\n"
     ]
    }
   ],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(_X_train,\n",
    "                                                     dtype='int32',\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(_X_test,\n",
    "                                                    dtype='int32',\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "\n",
    "\n",
    "# classification. convert y to 2 dims \n",
    "y_train = tf.one_hot(_y_train, depth=2)\n",
    "y_test = tf.one_hot(_y_test, depth=2)\n",
    "\n",
    "\n",
    "print(\"X: \", X_train.shape, X_train.dtype, X_test.dtype)\n",
    "#print(\"y: \", y_train.shape, y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setting\n",
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(10000, 8),\n",
    "            tf.keras.layers.GlobalAvgPool1D(),\n",
    "            tf.keras.layers.Dense(6, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(2, activation=\"sigmoid\"),\n",
    "        ])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "D6G9oqEV-Se-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.5368\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.6178\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.7058\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.7477\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.7886\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.8130\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.8366\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8546\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.8655\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8748\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8821\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.3600 - accuracy: 0.8888\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8918\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8976\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.9021\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.9062\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.9103\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.9131\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2481 - accuracy: 0.9159\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.9196\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2295 - accuracy: 0.9230\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2212 - accuracy: 0.9256\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2136 - accuracy: 0.9278\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9304\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9329\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9346\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1887 - accuracy: 0.9363\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1828 - accuracy: 0.9381\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1775 - accuracy: 0.9402\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1727 - accuracy: 0.9426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f98b37567f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 0s 517us/step - loss: 0.2875 - accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2874763607978821, 0.8834400177001953]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the test datasets\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'positive', 'negative']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a predict function for production\n",
    "def predict(texts):\n",
    "    # your verifing code here\n",
    "    X = [encode_review(t) for t in texts]\n",
    "    X = keras.preprocessing.sequence.pad_sequences(X,\n",
    "                                                   dtype=\"int32\",\n",
    "                                                   value=word_index[\"<PAD>\"],\n",
    "                                                   padding='post',\n",
    "                                                   maxlen=256)\n",
    "    y = model(X)\n",
    "    return [REVIEW_CLASSES[c] for c in tf.argmax(y, axis=1).numpy().tolist()]\n",
    "\n",
    "predict(['it is funfunnyny.', 'just so good', 'oh, bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BentoService class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tensorflow_text_classification.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tensorflow_text_classification.py\n",
    "\n",
    "import bentoml\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from bentoml.artifact import TensorflowSavedModelArtifact\n",
    "from bentoml.adapters import JsonInput\n",
    "\n",
    "\n",
    "\n",
    "REVIEW_CLASSES = ['negative', 'positive']\n",
    "\n",
    "MAX_WORDS = 10000\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# tf.keras.models.load_model(\"imdb_model/imdb\")\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def encode_review(text):\n",
    "    words = text.split(' ')\n",
    "    ids = [word_index[\"<START>\"]]\n",
    "    for w in words:\n",
    "        v = word_index.get(w, word_index[\"<UNK>\"])\n",
    "        # >1000, signed as <UNseED>\n",
    "        if v > MAX_WORDS:\n",
    "            v = word_index[\"<UNUSED>\"]\n",
    "        ids.append(v)\n",
    "    return ids\n",
    "\n",
    "\n",
    "@bentoml.env(pip_dependencies=['tensorflow'])\n",
    "@bentoml.artifacts([TensorflowSavedModelArtifact('model')])\n",
    "class ImdbTensorflow(bentoml.BentoService):\n",
    "\n",
    "    @bentoml.api(input=JsonInput(), batch=True)\n",
    "    def predict(self, texts):\n",
    "        X = [encode_review(t) for t in texts]\n",
    "        X = keras.preprocessing.sequence.pad_sequences(X,\n",
    "                                                       dtype=\"float32\",\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "        y = self.artifacts.model(X)\n",
    "        return [REVIEW_CLASSES[c] for c in tf.argmax(y, axis=1).numpy().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-16 10:03:25,821] WARNING - Importing from \"bentoml.artifact.*\" has been deprecated. Instead, use`bentoml.frameworks.*` and `bentoml.service.*`. e.g.:, `from bentoml.frameworks.sklearn import SklearnModelArtifact`, `from bentoml.service.artifacts import BentoServiceArtifact`, `from bentoml.service.artifacts.common import PickleArtifact`\n",
      "[2020-11-16 10:03:26,006] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-11-16 10:03:26,205] WARNING - pip package requirement tensorflow already exist\n",
      "WARNING:tensorflow:From /usr/local/Caskroom/miniconda/base/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/Caskroom/miniconda/base/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /var/folders/c0/p81lrfs94tq4hn8065r74b300000gn/T/tmpii8ip69a/assets\n",
      "[2020-11-16 10:03:31,575] INFO - Detected non-PyPI-released BentoML installed, copying local BentoML modulefiles to target saved bundle path..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "warning: no directories found matching 'bentoml/yatai/web/dist'\n",
      "no previously-included directories found matching 'e2e_tests'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'benchmark'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATING BentoML-0.9.2+25.g7796754/bentoml/_version.py\n",
      "set BentoML-0.9.2+25.g7796754/bentoml/_version.py to '0.9.2+25.g7796754'\n",
      "[2020-11-16 10:03:32,659] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.2, but loading from BentoML version 0.9.2+25.g7796754\n",
      "[2020-11-16 10:03:32,692] INFO - BentoService bundle 'ImdbTensorflow:20201116100327_8F8C4D' saved to: /Users/agent/bentoml/repository/ImdbTensorflow/20201116100327_8F8C4D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/agent/bentoml/repository/ImdbTensorflow/20201116100327_8F8C4D'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_text_classification\n",
    "\n",
    "service = tensorflow_text_classification.ImdbTensorflow()\n",
    "\n",
    "service.pack(\"model\", model)\n",
    "service.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BentoService with BentoML CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService Name>` list all of BentoService's versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml get ImdbTensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService name>:<bentoService version>` display detailed information of the specific BentoService version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-16 10:03:56,542] INFO - Getting latest version ImdbTensorflow:20201116100327_8F8C4D\n",
      "\u001b[39m{\n",
      "  \"name\": \"ImdbTensorflow\",\n",
      "  \"version\": \"20201116100327_8F8C4D\",\n",
      "  \"uri\": {\n",
      "    \"type\": \"LOCAL\",\n",
      "    \"uri\": \"/Users/agent/bentoml/repository/ImdbTensorflow/20201116100327_8F8C4D\"\n",
      "  },\n",
      "  \"bentoServiceMetadata\": {\n",
      "    \"name\": \"ImdbTensorflow\",\n",
      "    \"version\": \"20201116100327_8F8C4D\",\n",
      "    \"createdAt\": \"2020-11-16T02:03:31.513604Z\",\n",
      "    \"env\": {\n",
      "      \"condaEnv\": \"name: bentoml-default-conda-env\\nchannels:\\n- conda-forge\\n- defaults\\ndependencies:\\n- pip\\n\",\n",
      "      \"pythonVersion\": \"3.6.9\",\n",
      "      \"dockerBaseImage\": \"bentoml/model-server:0.9.2-py36\",\n",
      "      \"pipPackages\": [\n",
      "        \"bentoml==0.9.2\",\n",
      "        \"tensorflow==2.3.1\"\n",
      "      ]\n",
      "    },\n",
      "    \"artifacts\": [\n",
      "      {\n",
      "        \"name\": \"model\",\n",
      "        \"artifactType\": \"TensorflowSavedModelArtifact\",\n",
      "        \"metadata\": {}\n",
      "      }\n",
      "    ],\n",
      "    \"apis\": [\n",
      "      {\n",
      "        \"name\": \"predict\",\n",
      "        \"inputType\": \"JsonInput\",\n",
      "        \"docs\": \"BentoService inference API 'predict', input: 'JsonInput', output: 'DefaultOutput'\",\n",
      "        \"outputConfig\": {\n",
      "          \"cors\": \"*\"\n",
      "        },\n",
      "        \"outputType\": \"DefaultOutput\",\n",
      "        \"mbMaxLatency\": 10000,\n",
      "        \"mbMaxBatchSize\": 2000,\n",
      "        \"batch\": true\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml get ImdbTensorflow:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-16 10:15:27,439] INFO - Getting latest version ImdbTensorflow:20201116100327_8F8C4D\n",
      "[2020-11-16 10:15:28,487] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-11-16 10:15:28,501] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.2, but loading from BentoML version 0.9.2+25.g7796754\n",
      "[2020-11-16 10:15:30,494] WARNING - Importing from \"bentoml.artifact.*\" has been deprecated. Instead, use`bentoml.frameworks.*` and `bentoml.service.*`. e.g.:, `from bentoml.frameworks.sklearn import SklearnModelArtifact`, `from bentoml.service.artifacts import BentoServiceArtifact`, `from bentoml.service.artifacts.common import PickleArtifact`\n",
      "[2020-11-16 10:15:30,651] WARNING - pip package requirement tensorflow already exist\n",
      "2020-11-16 10:15:31.750823: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-16 10:15:31.762636: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd4fe936da0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-16 10:15:31.762659: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "[2020-11-16 10:15:31,956] INFO - {'service_name': 'ImdbTensorflow', 'service_version': '20201116100327_8F8C4D', 'api': 'predict', 'task': {'data': '\"just okay\"', 'task_id': '166e2fc7-9c2a-4d20-94c1-65e62369f394', 'cli_args': ('--input', '\"just okay\"')}, 'result': {'data': '\"negative\"', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '166e2fc7-9c2a-4d20-94c1-65e62369f394'}\n",
      "\"negative\"\n"
     ]
    }
   ],
   "source": [
    "!bentoml run ImdbTensorflow:latest predict --input '\"just okay\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Serve bentoml REST server**\n",
    "\n",
    "for testing: run this command in shell\n",
    "\n",
    "> bentoml serve ImdbTensorflow:latest\n",
    "\n",
    "for production:\n",
    "\n",
    "> bentoml serve-gunicorn ImdbTensorflow:latest --workers 1\n",
    "\n",
    "with mincro-batching enabled:\n",
    "\n",
    "> bentoml serve-gunicorn ImdbTensorflow:latest --workers 1 --enable-microbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "\"positive\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "# reviews, a <str>\n",
    "review = '\"good\"'\n",
    "json_response = requests.post(f'http://localhost:5000/predict', data=review, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with cURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"positive\""
     ]
    }
   ],
   "source": [
    "!curl -X POST \"http://localhost:5000/predict\" -H \"accept: */*\" -H \"Content-Type: application/json\" -d \"\\\"good\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
