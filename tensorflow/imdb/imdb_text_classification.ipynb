{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# Text classification: Classify reviews of imdb\n",
    "\n",
    "**BentoML makes moving trained ML models to production easy:**\n",
    "\n",
    "* Package models trained with **any ML framework** and reproduce them for model serving in production\n",
    "* **Deploy anywhere** for online API serving or offline batch serving\n",
    "* High-Performance API model server with *adaptive micro-batching* support\n",
    "* Central hub for managing models and deployment process via Web UI and APIs\n",
    "* Modular and flexible design making it *adaptable to your infrastrcuture*\n",
    "\n",
    "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=tensorflow&ea=imdb_text_classification&dt=imdb_text_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ruhan/work_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q bentoml tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant variables\n",
    "MAX_WORDS = 10000\n",
    "REVIEW_CLASSES = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zXXx5Oc3pOmN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/Caskroom/miniconda/base/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/Caskroom/miniconda/base/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "## download dataset from keras.\n",
    "\n",
    "# 10000 high-frequency vocabulary\n",
    "(_X_train, _y_train), (_X_test, _y_test) = keras.datasets.imdb.load_data(num_words=MAX_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y8qCnve_-lkO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (25000,)\n",
      "y_train shape:(25000,)\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the data\n",
    "print(\"X_train shape: {}\\ny_train shape:{}\".format(_X_train.shape, _y_train.shape))\n",
    "print(type(_X_train.shape))\n",
    "_X_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wJg2FiYpuoX"
   },
   "source": [
    "## Reverse Word Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tr5s_1alpzop"
   },
   "outputs": [],
   "source": [
    "# word_index[<str>] = <int>\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  \n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# word_index.items  <str> to <int>\n",
    "# reverse_word_index <int> to <str>\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '#') for i in text])\n",
    "\n",
    "# <str> to <int>\n",
    "def encode_review(text):\n",
    "    words = text.split(' ')\n",
    "    ids = [word_index[\"<START>\"]]\n",
    "    for w in words:\n",
    "        v = word_index.get(w, word_index[\"<UNK>\"])\n",
    "        # >1000, signed as <UNUSED>\n",
    "        if v > MAX_WORDS:\n",
    "            v = word_index[\"<UNUSED>\"]\n",
    "        ids.append(v)\n",
    "    return ids    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFP_XKVRp4_S"
   },
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2jQv-omsHurp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (25000, 256) int32 int32\n"
     ]
    }
   ],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(_X_train,\n",
    "                                                     dtype='int32',\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(_X_test,\n",
    "                                                    dtype='int32',\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "\n",
    "\n",
    "# classification. convert y to 2 dims \n",
    "y_train = tf.one_hot(_y_train, depth=2)\n",
    "y_test = tf.one_hot(_y_test, depth=2)\n",
    "\n",
    "\n",
    "print(\"X: \", X_train.shape, X_train.dtype, X_test.dtype)\n",
    "#print(\"y: \", y_train.shape, y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setting\n",
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(10000, 8),\n",
    "            tf.keras.layers.GlobalAvgPool1D(),\n",
    "            tf.keras.layers.Dense(6, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(2, activation=\"sigmoid\"),\n",
    "        ])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D6G9oqEV-Se-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.6455\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.6530\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.7085\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.7457\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.7714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f87906806d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 679us/step - loss: 0.6267 - accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.626689076423645, 0.7730000019073486]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the test datasets\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'positive', 'positive']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a predict function for production\n",
    "def predict(texts):\n",
    "    # your verifing code here\n",
    "    X = [encode_review(t) for t in texts]\n",
    "    X = keras.preprocessing.sequence.pad_sequences(X,\n",
    "                                                   dtype=\"int32\",\n",
    "                                                   value=word_index[\"<PAD>\"],\n",
    "                                                   padding='post',\n",
    "                                                   maxlen=256)\n",
    "    y = model(X)\n",
    "    return [REVIEW_CLASSES[c] for c in tf.argmax(y, axis=1).numpy().tolist()]\n",
    "\n",
    "predict(['it is funfunnyny.', 'just so good', 'oh, bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BentoService class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tensorflow_text_classification.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tensorflow_text_classification.py\n",
    "\n",
    "import bentoml\n",
    "\n",
    "from bentoml.artifact import TensorflowSavedModelArtifact, PickleArtifact\n",
    "from bentoml.adapters import JsonInput\n",
    "\n",
    "\n",
    "REVIEW_CLASSES = ['negative', 'positive']\n",
    "MAX_WORDS = 10000\n",
    "\n",
    "\n",
    "@bentoml.env(pip_dependencies=['tensorflow'])\n",
    "@bentoml.artifacts([TensorflowSavedModelArtifact('model'), PickleArtifact('word_index')])\n",
    "class ImdbTensorflow(bentoml.BentoService):\n",
    "    def encode_review(self, text):\n",
    "        words = text.split(' ')\n",
    "        ids = [self.artifacts.word_index[\"<START>\"]]\n",
    "        for w in words:\n",
    "            v = self.artifacts.word_index.get(w, self.artifacts.word_index[\"<UNK>\"])\n",
    "            # >1000, signed as <UNseED>\n",
    "            if v > MAX_WORDS:\n",
    "                v = self.artifacts.word_index[\"<UNUSED>\"]\n",
    "            ids.append(v)\n",
    "        return ids\n",
    "\n",
    "    @bentoml.api(input=JsonInput(), batch=True)\n",
    "    def predict(self, texts_array):\n",
    "        import importlib\n",
    "        import tensorflow as tf\n",
    "\n",
    "        importlib.reload(tf)\n",
    "        keras = tf.keras\n",
    "\n",
    "        X = [self.encode_review(t) for t in texts_array]\n",
    "        X = keras.preprocessing.sequence.pad_sequences(X,\n",
    "                                                       dtype=\"float32\",\n",
    "                                                       value=self.artifacts.word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "        y = self.artifacts.model(X)\n",
    "        return [REVIEW_CLASSES[c] for c in tf.argmax(y, axis=1).numpy().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bento service and pack models\n",
    "\n",
    "import tensorflow_text_classification\n",
    "import importlib\n",
    "\n",
    "importlib.reload(tensorflow_text_classification)\n",
    "\n",
    "service = tensorflow_text_classification.ImdbTensorflow()\n",
    "service.pack(\"model\", model)\n",
    "service.pack(\"word_index\", word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-12-09 12:35:28,130] WARNING - pip package requirement tensorflow already exist\n",
      "INFO:tensorflow:Assets written to: /var/folders/c0/p81lrfs94tq4hn8065r74b300000gn/T/tmpvmfcekb9/assets\n",
      "[2020-12-09 12:35:28,783] WARNING - Due to TensorFlow's internal mechanism, only methods wrapped under `@tf.function` decorator and the Keras default function `__call__(inputs, training=False)` can be restored after a save & load.\n",
      "You can test the restored model object by referring:\n",
      "<bento_svc>.artifacts.model\n",
      "\n",
      "[2020-12-09 12:35:28,784] INFO - Found restored functions:\n",
      "model(inputs, training, mask)\n",
      "------------\n",
      "Arguments Option 1:\n",
      "  Positional arguments (3 total):\n",
      "    * TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_input')\n",
      "    * True\n",
      "    * None\n",
      "  Keyword arguments:\n",
      "    {}\n",
      "\n",
      "Arguments Option 2:\n",
      "  Positional arguments (3 total):\n",
      "    * TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs')\n",
      "    * False\n",
      "    * None\n",
      "  Keyword arguments:\n",
      "    {}\n",
      "\n",
      "Arguments Option 3:\n",
      "  Positional arguments (3 total):\n",
      "    * TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs')\n",
      "    * True\n",
      "    * None\n",
      "  Keyword arguments:\n",
      "    {}\n",
      "\n",
      "Arguments Option 4:\n",
      "  Positional arguments (3 total):\n",
      "    * TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_input')\n",
      "    * False\n",
      "    * None\n",
      "  Keyword arguments:\n",
      "    {}\n",
      "\n",
      "Return:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "\n",
      "\n",
      "model.signature['serving_default'](embedding_input)\n",
      "------------\n",
      "Arguments Option 1:\n",
      "  Positional arguments (0 total):\n",
      "    * \n",
      "  Keyword arguments:\n",
      "    {'embedding_input': TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_input')}\n",
      "\n",
      "Return:\n",
      "  {'dense_1': TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense_1')}\n",
      "\n",
      "\n",
      "\n",
      "[2020-12-09 12:35:28,785] WARNING - BentoML detected that TensorflowSavedModelArtifact is being used to pack a Keras API based model. In order to get optimal serving performance, we recommend either replacing TensorflowSavedModelArtifact with KerasModelArtifact, or wrapping the keras_model.predict method with tf.function decorator.\n",
      "[2020-12-09 12:35:30,328] INFO - Detected non-PyPI-released BentoML installed, copying local BentoML modulefiles to target saved bundle path..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "warning: no directories found matching 'bentoml/yatai/web/dist'\n",
      "no previously-included directories found matching 'e2e_tests'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'benchmark'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATING BentoML-0.9.2+62.gfdee45a/bentoml/_version.py\n",
      "set BentoML-0.9.2+62.gfdee45a/bentoml/_version.py to '0.9.2+62.gfdee45a'\n",
      "[2020-12-09 12:35:31,883] INFO - BentoService bundle 'ImdbTensorflow:20201209123528_BBC10A' created at: /var/folders/c0/p81lrfs94tq4hn8065r74b300000gn/T/tmpq0tf2bv6\n",
      "[2020-12-09 12:35:33,527] INFO - Starting BentoML API server in development mode..\n",
      "[2020-12-09 12:35:34,722] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-12-09 12:35:34,739] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.2, but loading from BentoML version 0.9.2+62.gfdee45a\n",
      "[2020-12-09 12:35:34,742] WARNING - Importing from \"bentoml.artifact.*\" has been deprecated. Instead, use`bentoml.frameworks.*` and `bentoml.service.*`. e.g.:, `from bentoml.frameworks.sklearn import SklearnModelArtifact`, `from bentoml.service.artifacts import BentoServiceArtifact`, `from bentoml.service.artifacts.common import PickleArtifact`\n",
      "[2020-12-09 12:35:39,148] WARNING - Due to TensorFlow's internal mechanism, only methods wrapped under `@tf.function` decorator and the Keras default function `__call__(inputs, training=False)` can be restored after a save & load.\n",
      "You can test the restored model object by referring:\n",
      "<bento_svc>.artifacts.model\n",
      "\n",
      "[2020-12-09 12:35:39,148] INFO - Found restored functions:\n",
      "model(inputs, training, mask)\n",
      "------------\n",
      "Arguments Option 1:\n",
      "  Positional arguments (3 total):\n",
      "    * TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_input')\n",
      "    * True\n",
      "    * None\n",
      "  Keyword arguments:\n",
      "    {}\n",
      "\n",
      "Arguments Option 2:\n",
      "  Positional arguments (3 total):\n",
      "    * TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs')\n",
      "    * False\n",
      "    * None\n",
      "  Keyword arguments:\n",
      "    {}\n",
      "\n",
      "Arguments Option 3:\n",
      "  Positional arguments (3 total):\n",
      "    * TensorSpec(shape=(None, None), dtype=tf.float32, name='inputs')\n",
      "    * True\n",
      "    * None\n",
      "  Keyword arguments:\n",
      "    {}\n",
      "\n",
      "Arguments Option 4:\n",
      "  Positional arguments (3 total):\n",
      "    * TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_input')\n",
      "    * False\n",
      "    * None\n",
      "  Keyword arguments:\n",
      "    {}\n",
      "\n",
      "Return:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "\n",
      "\n",
      "model.signature['serving_default'](embedding_input)\n",
      "------------\n",
      "Arguments Option 1:\n",
      "  Positional arguments (0 total):\n",
      "    * \n",
      "  Keyword arguments:\n",
      "    {'embedding_input': TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_input')}\n",
      "\n",
      "Return:\n",
      "  {'dense_1': TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense_1')}\n",
      "\n",
      "\n",
      "\n",
      "[2020-12-09 12:35:39,148] WARNING - BentoML detected that TensorflowSavedModelArtifact is being used to pack a Keras API based model. In order to get optimal serving performance, we recommend either replacing TensorflowSavedModelArtifact with KerasModelArtifact, or wrapping the keras_model.predict method with tf.function decorator.\n",
      "[2020-12-09 12:35:39,186] WARNING - pip package requirement tensorflow already exist\n",
      " * Serving Flask app \"ImdbTensorflow\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      "[2020-12-09 12:36:36,090] INFO - {'service_name': 'ImdbTensorflow', 'service_version': '20201209123528_BBC10A', 'api': 'predict', 'task': {'data': '\"good\"', 'task_id': '7bc8be33-c10d-49a8-aee0-bf09fdbe7dfa', 'http_headers': (('Host', 'localhost:5000'), ('User-Agent', 'python-requests/2.24.0'), ('Accept-Encoding', 'gzip, deflate'), ('Accept', '*/*'), ('Connection', 'keep-alive'), ('Content-Type', 'application/json'), ('Content-Length', '6'))}, 'result': {'data': '\"positive\"', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '7bc8be33-c10d-49a8-aee0-bf09fdbe7dfa'}\n",
      "[2020-12-09 12:36:48,846] INFO - {'service_name': 'ImdbTensorflow', 'service_version': '20201209123528_BBC10A', 'api': 'predict', 'task': {'data': '\"good\"', 'task_id': '9cc4da3e-718b-41ba-9400-50e1e0d4c7bc', 'http_headers': (('Host', 'localhost:5000'), ('User-Agent', 'python-requests/2.24.0'), ('Accept-Encoding', 'gzip, deflate'), ('Accept', '*/*'), ('Connection', 'keep-alive'), ('Content-Type', 'application/json'), ('Content-Length', '6'))}, 'result': {'data': '\"positive\"', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '9cc4da3e-718b-41ba-9400-50e1e0d4c7bc'}\n"
     ]
    }
   ],
   "source": [
    "# start a dev server on port 5000\n",
    "service.start_dev_server(port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "\"positive\"\n"
     ]
    }
   ],
   "source": [
    "# test the service\n",
    "import requests\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "# reviews, a <str>\n",
    "review = '\"good\"'\n",
    "json_response = requests.post(f'http://localhost:5000/predict', data=review, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-12-09 12:16:48,639] WARNING - No dev server is running.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT forget to stop the dev server\n",
    "\n",
    "service.stop_dev_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-12-09 12:39:49,164] INFO - Detected non-PyPI-released BentoML installed, copying local BentoML modulefiles to target saved bundle path..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "warning: no directories found matching 'bentoml/yatai/web/dist'\n",
      "no previously-included directories found matching 'e2e_tests'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'benchmark'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATING BentoML-0.9.2+62.gfdee45a/bentoml/_version.py\n",
      "set BentoML-0.9.2+62.gfdee45a/bentoml/_version.py to '0.9.2+62.gfdee45a'\n",
      "[2020-12-09 12:39:50,541] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.2, but loading from BentoML version 0.9.2+62.g7b99190.dirty\n",
      "[2020-12-09 12:39:50,582] INFO - BentoService bundle 'ImdbTensorflow:20201209123528_BBC10A' saved to: /Users/agent/bentoml/repository/ImdbTensorflow/20201209123528_BBC10A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/agent/bentoml/repository/ImdbTensorflow/20201209123528_BBC10A'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the service to yatai(the bundle/model management service of bentoml)\n",
    "\n",
    "service.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BentoService with BentoML CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService Name>` list all of BentoService's versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml get ImdbTensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService name>:<bentoService version>` display detailed information of the specific BentoService version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-16 10:03:56,542] INFO - Getting latest version ImdbTensorflow:20201116100327_8F8C4D\n",
      "\u001b[39m{\n",
      "  \"name\": \"ImdbTensorflow\",\n",
      "  \"version\": \"20201116100327_8F8C4D\",\n",
      "  \"uri\": {\n",
      "    \"type\": \"LOCAL\",\n",
      "    \"uri\": \"/Users/agent/bentoml/repository/ImdbTensorflow/20201116100327_8F8C4D\"\n",
      "  },\n",
      "  \"bentoServiceMetadata\": {\n",
      "    \"name\": \"ImdbTensorflow\",\n",
      "    \"version\": \"20201116100327_8F8C4D\",\n",
      "    \"createdAt\": \"2020-11-16T02:03:31.513604Z\",\n",
      "    \"env\": {\n",
      "      \"condaEnv\": \"name: bentoml-default-conda-env\\nchannels:\\n- conda-forge\\n- defaults\\ndependencies:\\n- pip\\n\",\n",
      "      \"pythonVersion\": \"3.6.9\",\n",
      "      \"dockerBaseImage\": \"bentoml/model-server:0.9.2-py36\",\n",
      "      \"pipPackages\": [\n",
      "        \"bentoml==0.9.2\",\n",
      "        \"tensorflow==2.3.1\"\n",
      "      ]\n",
      "    },\n",
      "    \"artifacts\": [\n",
      "      {\n",
      "        \"name\": \"model\",\n",
      "        \"artifactType\": \"TensorflowSavedModelArtifact\",\n",
      "        \"metadata\": {}\n",
      "      }\n",
      "    ],\n",
      "    \"apis\": [\n",
      "      {\n",
      "        \"name\": \"predict\",\n",
      "        \"inputType\": \"JsonInput\",\n",
      "        \"docs\": \"BentoService inference API 'predict', input: 'JsonInput', output: 'DefaultOutput'\",\n",
      "        \"outputConfig\": {\n",
      "          \"cors\": \"*\"\n",
      "        },\n",
      "        \"outputType\": \"DefaultOutput\",\n",
      "        \"mbMaxLatency\": 10000,\n",
      "        \"mbMaxBatchSize\": 2000,\n",
      "        \"batch\": true\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml get ImdbTensorflow:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-16 10:15:27,439] INFO - Getting latest version ImdbTensorflow:20201116100327_8F8C4D\n",
      "[2020-11-16 10:15:28,487] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-11-16 10:15:28,501] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.2, but loading from BentoML version 0.9.2+25.g7796754\n",
      "[2020-11-16 10:15:30,494] WARNING - Importing from \"bentoml.artifact.*\" has been deprecated. Instead, use`bentoml.frameworks.*` and `bentoml.service.*`. e.g.:, `from bentoml.frameworks.sklearn import SklearnModelArtifact`, `from bentoml.service.artifacts import BentoServiceArtifact`, `from bentoml.service.artifacts.common import PickleArtifact`\n",
      "[2020-11-16 10:15:30,651] WARNING - pip package requirement tensorflow already exist\n",
      "2020-11-16 10:15:31.750823: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-16 10:15:31.762636: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd4fe936da0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-16 10:15:31.762659: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "[2020-11-16 10:15:31,956] INFO - {'service_name': 'ImdbTensorflow', 'service_version': '20201116100327_8F8C4D', 'api': 'predict', 'task': {'data': '\"just okay\"', 'task_id': '166e2fc7-9c2a-4d20-94c1-65e62369f394', 'cli_args': ('--input', '\"just okay\"')}, 'result': {'data': '\"negative\"', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '166e2fc7-9c2a-4d20-94c1-65e62369f394'}\n",
      "\"negative\"\n"
     ]
    }
   ],
   "source": [
    "!bentoml run ImdbTensorflow:latest predict --input '\"just okay\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Serve bentoml REST server**\n",
    "\n",
    "for testing: run this command in shell\n",
    "\n",
    "> bentoml serve ImdbTensorflow:latest\n",
    "\n",
    "for production:\n",
    "\n",
    "> bentoml serve-gunicorn ImdbTensorflow:latest --workers 1\n",
    "\n",
    "with mincro-batching enabled:\n",
    "\n",
    "> bentoml serve-gunicorn ImdbTensorflow:latest --workers 1 --enable-microbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "\"positive\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "# reviews, a <str>\n",
    "review = '\"good\"'\n",
    "json_response = requests.post(f'http://localhost:5000/predict', data=review, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with cURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(b'TEXT', 1, 1), (b'TEXT', 1, 1)],\n",
       "      dtype=[('f0', 'S4'), ('f1', '<i4'), ('f2', '<i4')])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "res = np.array([(\"TEXT\", 1, 1), (\"TEXT\", 1, 1)], dtype='|S4, i4, i4')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', 'S4'), ('f1', '<i4'), ('f2', '<i4')])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data()\n",
    "\n",
    "model = create_model()\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# X_train >> \"i4\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones([10, 3, 3]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \n",
    "example_array = np.array([], dtype=\"i4\")\n",
    "\n",
    "\n",
    "@artifacts([ModelArtifact])\n",
    "class BentoSvc:\n",
    "    @api(input=NumpyNDArrayInput(example_array=example_array, batch_dim=0), batch=True)\n",
    "    def predict(self, ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POST <url> '''\n",
    "[\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.ImageArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(batch, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'array',\n",
       " 'items': {'type': 'object',\n",
       "  'properties': {'f0': {'type': 'string', 'format': 'binary'},\n",
       "   'f1': {'type': 'integer', 'format': 'int32'},\n",
       "   'f2': {'type': 'integer', 'format': 'int32'}}},\n",
       " 'example': [{'f0': 'VEVYVA==', 'f1': 1, 'f2': 1}]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "\n",
    "isch = NumpyParameterType(res)\n",
    "isch.input_to_swagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(b'1234', 1, 1)],\n",
       "      dtype=[('f0', 'S4'), ('f1', '<i4'), ('f2', '<i4')])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isch.deserialize_input([('12345', 1.1, 1), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-08f18f8a90a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"anno1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"anno2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m ], dtype=\"|i4, S10\")\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0misch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNumpyParameterType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0misch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_to_swagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "res2 = np.array([\n",
    "    (np.ones([18, 18, 3]).tolist(), \"anno1\"),\n",
    "    (np.zeros([18, 18, 3]).tolist(), \"anno2\"),\n",
    "], dtype=\"|i4, S10\")\n",
    "isch2 = NumpyParameterType(res2)\n",
    "isch2.input_to_swagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \"http://localhost:5000/predict\" -H \"accept: */*\" -H \"Content-Type: application/json\" -d \"\\\"good\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bento_svc.pack()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
