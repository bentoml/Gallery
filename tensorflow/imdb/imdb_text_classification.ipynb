{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# Text classification: Classify reviews of imdb\n",
    "\n",
    "**BentoML makes moving trained ML models to production easy:**\n",
    "\n",
    "* Package models trained with **any ML framework** and reproduce them for model serving in production\n",
    "* **Deploy anywhere** for online API serving or offline batch serving\n",
    "* High-Performance API model server with *adaptive micro-batching* support\n",
    "* Central hub for managing models and deployment process via Web UI and APIs\n",
    "* Modular and flexible design making it *adaptable to your infrastrcuture*\n",
    "\n",
    "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=tensorflow&ea=imdb_text_classification&dt=imdb_text_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ruhan/work_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q bentoml tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant variables\n",
    "MAX_WORDS = 10000\n",
    "REVIEW_CLASSES = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zXXx5Oc3pOmN"
   },
   "outputs": [],
   "source": [
    "## download dataset from keras.\n",
    "(_X_train, _y_train), (_X_test, _y_test) = keras.datasets.imdb.load_data(num_words=MAX_WORDS) # 10000 high-frequency vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y8qCnve_-lkO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (25000,)\n",
      "y_train shape:(25000,)\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the data\n",
    "print(\"X_train shape: {}\\ny_train shape:{}\".format(_X_train.shape, _y_train.shape))\n",
    "print(type(_X_train.shape))\n",
    "_X_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wJg2FiYpuoX"
   },
   "source": [
    "## Reverse Word Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tr5s_1alpzop"
   },
   "outputs": [],
   "source": [
    "# word_index[<str>] = <int>\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  \n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# word_index.items  <str> to <int>\n",
    "# reverse_word_index <int> to <str>\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '#') for i in text])\n",
    "\n",
    "# <str> to <int>\n",
    "def encode_review(text):\n",
    "    words = text.split(' ')\n",
    "    ids = [word_index[\"<START>\"]]\n",
    "    for w in words:\n",
    "        v = word_index.get(w, word_index[\"<UNK>\"])\n",
    "        # >1000, signed as <UNUSED>\n",
    "        if v > MAX_WORDS:\n",
    "            v = word_index[\"<UNUSED>\"]\n",
    "        ids.append(v)\n",
    "    return ids    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFP_XKVRp4_S"
   },
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2jQv-omsHurp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (25000, 256) int32 int32\n"
     ]
    }
   ],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(_X_train,\n",
    "                                                     dtype='int32',\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(_X_test,\n",
    "                                                    dtype='int32',\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "\n",
    "# classification. convert y to 2 dims \n",
    "y_train = tf.one_hot(_y_train, depth=2)\n",
    "y_test = tf.one_hot(_y_test, depth=2)\n",
    "\n",
    "\n",
    "print(\"X: \", X_train.shape, X_train.dtype, X_test.dtype)\n",
    "\n",
    "#print(\"y: \", y_train.shape, y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setting\n",
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(10000, 8),\n",
    "            tf.keras.layers.GlobalAvgPool1D(),\n",
    "            tf.keras.layers.Dense(6, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(2, activation=\"sigmoid\"),\n",
    "        ])\n",
    "\n",
    "# \n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "D6G9oqEV-Se-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.5666\n",
      "Epoch 2/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.6171\n",
      "Epoch 3/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.7017\n",
      "Epoch 4/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.7433\n",
      "Epoch 5/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.7792\n",
      "Epoch 6/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.7972\n",
      "Epoch 7/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.8190\n",
      "Epoch 8/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.8362\n",
      "Epoch 9/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.8518\n",
      "Epoch 10/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8618\n",
      "Epoch 11/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8706\n",
      "Epoch 12/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8779\n",
      "Epoch 13/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8834\n",
      "Epoch 14/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8882\n",
      "Epoch 15/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8927\n",
      "Epoch 16/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.8976\n",
      "Epoch 17/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2798 - accuracy: 0.9005\n",
      "Epoch 18/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.9039\n",
      "Epoch 19/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2585 - accuracy: 0.9075\n",
      "Epoch 20/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2494 - accuracy: 0.9106\n",
      "Epoch 21/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2410 - accuracy: 0.9126\n",
      "Epoch 22/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2331 - accuracy: 0.9169\n",
      "Epoch 23/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9188\n",
      "Epoch 24/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.2194 - accuracy: 0.9207\n",
      "Epoch 25/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2131 - accuracy: 0.9242\n",
      "Epoch 26/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.9272\n",
      "Epoch 27/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2015 - accuracy: 0.9280\n",
      "Epoch 28/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.9297\n",
      "Epoch 29/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1915 - accuracy: 0.9320\n",
      "Epoch 30/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1866 - accuracy: 0.9344\n",
      "Epoch 31/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1819 - accuracy: 0.9358\n",
      "Epoch 32/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1779 - accuracy: 0.9375\n",
      "Epoch 33/40\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1734 - accuracy: 0.9394\n",
      "Epoch 34/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1696 - accuracy: 0.9409\n",
      "Epoch 35/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9429\n",
      "Epoch 36/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9438\n",
      "Epoch 37/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9458\n",
      "Epoch 38/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9474\n",
      "Epoch 39/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9486\n",
      "Epoch 40/40\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fabb9d66850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=40, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 0s 582us/step - loss: 0.2944 - accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2944161593914032, 0.881600022315979]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the test datasets\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ruhan/work_env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/ruhan/work_env/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: imdb_model/imdb/assets\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 8)           80000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 80,068\n",
      "Trainable params: 80,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p imdb_model\n",
    "# model saving\n",
    "model.save('imdb_model/imdb')\n",
    "# use keras to load model\n",
    "saved_model = tf.keras.models.load_model('imdb_model/imdb')\n",
    "# \n",
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'negative', 'negative']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a predict function for production\n",
    "def predict(texts):\n",
    "    X = [encode_review(t) for t in texts]\n",
    "    X = keras.preprocessing.sequence.pad_sequences(X,\n",
    "                                                   dtype=\"int32\",\n",
    "                                                   value=word_index[\"<PAD>\"],\n",
    "                                                   padding='post',\n",
    "                                                   maxlen=256)\n",
    "    y = saved_model(X)\n",
    "    return [REVIEW_CLASSES[c] for c in tf.argmax(y, axis=1).numpy().tolist()]\n",
    "\n",
    "predict(['it is funfunnyny.', 'just so good', 'oh, bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zOMKywn4zReN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 0s - loss: 0.2944 - accuracy: 0.8816\n",
      "[0.2944161593914032, 0.881600022315979]\n"
     ]
    }
   ],
   "source": [
    "# use new model to evaluate\n",
    "results = saved_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BentoService class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tensorflow_text_classification.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tensorflow_text_classification.py\n",
    "\n",
    "import bentoml\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from bentoml.artifact import TensorflowSavedModelArtifact\n",
    "from bentoml.adapters import JsonInput\n",
    "\n",
    "\n",
    "\n",
    "REVIEW_CLASSES = ['negative', 'positive']\n",
    "\n",
    "MAX_WORDS = 10000\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# tf.keras.models.load_model(\"imdb_model/imdb\")\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def encode_review(text):\n",
    "    words = text.split(' ')\n",
    "    ids = [word_index[\"<START>\"]]\n",
    "    for w in words:\n",
    "        v = word_index.get(w, word_index[\"<UNK>\"])\n",
    "        # >1000, signed as <UNseED>\n",
    "        if v > MAX_WORDS:\n",
    "            v = word_index[\"<UNUSED>\"]\n",
    "        ids.append(v)\n",
    "    return ids\n",
    "\n",
    "\n",
    "@bentoml.env(pip_dependencies=['tensorflow'])\n",
    "@bentoml.artifacts([TensorflowSavedModelArtifact('model')])\n",
    "class ImdbTensorflow(bentoml.BentoService):\n",
    "\n",
    "    @bentoml.api(input=JsonInput(), batch=True)\n",
    "    def predict(self, texts):\n",
    "        X = [encode_review(t) for t in texts]\n",
    "        X = keras.preprocessing.sequence.pad_sequences(X,\n",
    "                                                       dtype=\"float32\",\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "        y = self.artifacts.model(X)\n",
    "        return [REVIEW_CLASSES[c] for c in tf.argmax(y, axis=1).numpy().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-04 21:35:38,536] WARNING - Importing from \"bentoml.artifact.*\" has been deprecated. Instead, use`bentoml.frameworks.*` and `bentoml.service.*`. e.g.:, `from bentoml.frameworks.sklearn import SklearnModelArtifact`, `from bentoml.service.artifacts import BentoServiceArtifact`, `from bentoml.service.artifacts.common import PickleArtifact`\n",
      "[2020-11-04 21:35:38,670] WARNING - pip package requirement tensorflow already exist\n",
      "INFO:tensorflow:Assets written to: /tmp/bentoml-temp-qwrlvy7c/ImdbTensorflow/artifacts/model_saved_model/assets\n",
      "[2020-11-04 21:35:40,627] INFO - BentoService bundle 'ImdbTensorflow:20201104213539_7F3867' saved to: /home/ruhan/bentoml/repository/ImdbTensorflow/20201104213539_7F3867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ruhan/bentoml/repository/ImdbTensorflow/20201104213539_7F3867'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_text_classification\n",
    "\n",
    "# import importlib\n",
    "# importlib.reload(tensorflow_text_classification)\n",
    "\n",
    "service = tensorflow_text_classification.ImdbTensorflow()\n",
    "\n",
    "service.pack(\"model\", model)\n",
    "service.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BentoService with BentoML CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService Name>` list all of BentoService's versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39mBENTO_SERVICE                         AGE                         APIS                                      ARTIFACTS                            LABELS\n",
      "ImdbTensorflow:20201104213539_7F3867  0.83 seconds                predict<JsonInput:DefaultOutput>          model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104213353_E9D9A3  1 minute and 45.84 seconds  predict<JsonInput:DefaultOutput>          model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104165124_8722E4  4 hours and 44 minutes      predict<JsonInput:DefaultOutput>          model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104164837_D92DB2  4 hours and 47 minutes      predict<JsonInput:DefaultOutput>          model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104145151_E24226  6 hours and 43 minutes      predict<JsonInput:DefaultOutput>          model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104144303_962D3F  6 hours and 52 minutes      predict<JsonInput:DefaultOutput>          model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104115502_2C30C3  9 hours and 40 minutes      predict<JsonInput:DefaultOutput>          model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104115409_C26740  9 hours and 41 minutes      predict<JsonInput:DefaultOutput>          model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104115331_A30FBA  9 hours and 42 minutes      predict<JsonInput:DefaultOutput>          model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104114912_966289  9 hours and 46 minutes      predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104114834_761C42  9 hours and 47 minutes      predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104113917_C69D92  9 hours and 56 minutes      predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104112844_72A82D  10 hours and 6 minutes      predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104112631_63A1F2  10 hours and 9 minutes      predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104112407_5C2C5A  10 hours and 11 minutes     predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104112231_CF6F30  10 hours and 13 minutes     predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104111905_2AF479  10 hours and 16 minutes     encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104111656_6BFA3E  10 hours and 18 minutes     encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104111433_D44529  10 hours and 21 minutes     encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104111310_27D8B1  10 hours and 22 minutes     encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104110236_84D576  10 hours and 33 minutes     encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104105209_44D070  10 hours and 43 minutes     encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104104841_E1EFAE  10 hours and 46 minutes     encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104104354_7EF313  10 hours and 51 minutes     encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104103345_801470  11 hours and 1 minute       encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104103141_201FBB  11 hours and 3 minutes      encode_review<StringInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104102417_B5CAA1  11 hours and 11 minutes     predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104102054_F4269F  11 hours and 14 minutes     predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201104101707_766F8F  11 hours and 18 minutes     predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201103215849_49E3A7  23 hours and 36 minutes     predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201103212423_1B5FDE  1 day and 11 minutes        predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201103212349_CE60DC  1 day and 11 minutes        predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\n",
      "ImdbTensorflow:20201103211548_CA3A7E  1 day and 19 minutes        predict<StringInput:DefaultOutput>        model<TensorflowSavedModelArtifact>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml get ImdbTensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService name>:<bentoService version>` display detailed information of the specific BentoService version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-04 21:35:43,520] INFO - Getting latest version ImdbTensorflow:20201104213539_7F3867\n",
      "\u001b[39m{\n",
      "  \"name\": \"ImdbTensorflow\",\n",
      "  \"version\": \"20201104213539_7F3867\",\n",
      "  \"uri\": {\n",
      "    \"type\": \"LOCAL\",\n",
      "    \"uri\": \"/home/ruhan/bentoml/repository/ImdbTensorflow/20201104213539_7F3867\"\n",
      "  },\n",
      "  \"bentoServiceMetadata\": {\n",
      "    \"name\": \"ImdbTensorflow\",\n",
      "    \"version\": \"20201104213539_7F3867\",\n",
      "    \"createdAt\": \"2020-11-04T13:35:40.593944Z\",\n",
      "    \"env\": {\n",
      "      \"condaEnv\": \"name: bentoml-default-conda-env\\nchannels:\\n- conda-forge\\n- defaults\\ndependencies:\\n- pip\\n\",\n",
      "      \"pythonVersion\": \"3.7.9\",\n",
      "      \"dockerBaseImage\": \"bentoml/model-server:0.9.2-py37\",\n",
      "      \"pipPackages\": [\n",
      "        \"bentoml==0.9.2\",\n",
      "        \"tensorflow==2.3.1\"\n",
      "      ]\n",
      "    },\n",
      "    \"artifacts\": [\n",
      "      {\n",
      "        \"name\": \"model\",\n",
      "        \"artifactType\": \"TensorflowSavedModelArtifact\"\n",
      "      }\n",
      "    ],\n",
      "    \"apis\": [\n",
      "      {\n",
      "        \"name\": \"predict\",\n",
      "        \"inputType\": \"JsonInput\",\n",
      "        \"docs\": \"BentoService inference API 'predict', input: 'JsonInput', output: 'DefaultOutput'\",\n",
      "        \"outputConfig\": {\n",
      "          \"cors\": \"*\"\n",
      "        },\n",
      "        \"outputType\": \"DefaultOutput\",\n",
      "        \"mbMaxLatency\": 10000,\n",
      "        \"mbMaxBatchSize\": 2000,\n",
      "        \"batch\": true\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml get ImdbTensorflow:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Serve bentoml REST server locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !bentoml serve ImdbTensorflow:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "\"positive\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "# reviews, a <str>\n",
    "review = '\"good\"'\n",
    "json_response = requests.post(f'http://localhost:5000/predict', data=review, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with cURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"positive\""
     ]
    }
   ],
   "source": [
    "!curl -X POST \"http://localhost:5000/predict\" -H \"accept: */*\" -H \"Content-Type: application/json\" -d \"\\\"good\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
