{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Basic classification: Classify images of clothing\n",
    "\n",
    "BentoML is an open-source framework for machine learning **model serving**, aiming to **bridge the gap between Data Science and DevOps.**\n",
    "\n",
    "Data Scientists can easily package their models trained with any ML framework using BentoMl and reproduce the model for serving in production. BentoML helps with managing packaged models in the BentoML format, and allows DevOps to deploy them as online API serving endpoints or offline batch inference jobs, on any cloud platform.\n",
    "\n",
    "Before reading this example project, be sure to check out the [Getting started guide](https://github.com/bentoml/BentoML/blob/master/guides/quick-start/bentoml-quick-start-guide.ipynb) to learn about the basic concepts in BentoML.\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=tensorflow&ea=tensorflow_1_fashion_mnist&dt=tensorflow_1_fashion_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bentoml tensorflow==1.14.0 matplotlib \"numpy<1.17\"\n",
    "# why numpy<1.17: https://github.com/tensorflow/tensorflow/issues/30427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import io\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(_train_images, train_labels), (_test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "train_images = _train_images / 255.0\n",
    "test_images = _test_images / 255.0\n",
    "\n",
    "train_x = np.reshape(train_images, [-1, 28, 28, 1])\n",
    "train_y = np.eye(10)[train_labels]  # one hot\n",
    "\n",
    "test_x = np.reshape(test_images, [-1, 28, 28, 1])\n",
    "test_y = np.eye(10)[test_labels]  # one hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [None, 28, 28, 1]\n",
    "number_of_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function below builds model graph \n",
    "def cnn_model_fn(input_shape, number_of_classes, learning_rate):\n",
    "    raw = tf.placeholder(tf.string, shape=[None])\n",
    "    with tf.device(\"/cpu:0\"): # map_fn has issues on GPU https://github.com/tensorflow/tensorflow/issues/28007\n",
    "        img_array = tf.map_fn(lambda i: tf.io.decode_png(i, channels=1), raw, dtype=tf.uint8)\n",
    "    img_array = tf.cast(img_array, tf.float32)\n",
    "    img_array = (255.0 - img_array) / 255.0\n",
    "    \n",
    "    input_layer = tf.reshape(img_array, [-1, 28, 28, 1])\n",
    "\n",
    "    #input_layer = tf.placeholder(tf.float32, shape=input_shape)\n",
    "    labels = tf.placeholder(tf.float32, shape=[None, number_of_classes])\n",
    "    \n",
    "    #Train mode is used with dropout layers. We want effectively disable the dropout layers while\n",
    "    #evaluation and predict and use it only while training\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "    \n",
    "    #Architecture: image ->conv2d->maxpooling->conv2d->maxpooling->flatten->dense->dropout->logits->softmax\n",
    "    \n",
    "    #convolution layer 1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer, \n",
    "        filters=32, \n",
    "        kernel_size=[5, 5], \n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    #pooling layer 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    #convolution layer 2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1, \n",
    "        filters=64, \n",
    "        kernel_size=[5, 5], \n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    #pooling layer 1\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    #flatten the output volume of pool2 into a vector\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, 7*7*64])\n",
    "    \n",
    "    #dense layer\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=pool2_flat, \n",
    "        units=1024,\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    #dropout regularization\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, \n",
    "        rate=0.3, \n",
    "        training= train_mode)\n",
    "    \n",
    "    #logits layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\" : tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\" : tf.nn.softmax(logits=logits)\n",
    "    }\n",
    "    \n",
    "    #loss\n",
    "    loss = tf.losses.softmax_cross_entropy(labels, logits)\n",
    "    \n",
    "    #training operartion\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    \n",
    "    #accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)), tf.float32))\n",
    "    \n",
    "    return { \"logits\": logits,\n",
    "             \"predictions\": predictions,\n",
    "             \"loss\": loss,\n",
    "             \"train_op\": train_op,\n",
    "             \"accuracy\": accuracy,\n",
    "             \"raw_x\": raw,\n",
    "             \"x\": input_layer,\n",
    "             \"y\": labels,\n",
    "             \"train_mode\": train_mode }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-a4d551b98882>:26: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8411bc1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8411bc1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8411bc1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8411bc1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-10-a4d551b98882>:29: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f8411bc1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f8411bc1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f8411bc1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f8411bc1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8411bc1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8411bc1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8411bc1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8411bc1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f8411bc1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f8411bc1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f8411bc1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f8411bc1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-10-a4d551b98882>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8411bc13c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8411bc13c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8411bc13c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8411bc13c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-10-a4d551b98882>:55: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8411bc13c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8411bc13c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8411bc13c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f8411bc13c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8411a8ef98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8411a8ef98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8411a8ef98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8411a8ef98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 1000\n",
    "epoch = 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "cnn_model = cnn_model_fn(input_shape, number_of_classes, learning_rate)\n",
    "x = cnn_model[\"x\"]\n",
    "y= cnn_model[\"y\"]\n",
    "train_mode = cnn_model[\"train_mode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ODch-OFCaW4"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:Start\n",
      "Epoch 1:\n",
      "############################################################\n",
      "loss: 1.16 accuracy: 0.66 \n",
      "val_loss: 0.49 val_accuracy: 0.82\n",
      "Epoch 2:\n",
      "############################################################\n",
      "loss: 0.41 accuracy: 0.86 \n",
      "val_loss: 0.36 val_accuracy: 0.86\n",
      "Epoch 3:\n",
      "############################################################\n",
      "loss: 0.33 accuracy: 0.89 \n",
      "val_loss: 0.33 val_accuracy: 0.88\n",
      "Epoch 4:\n",
      "############################################################\n",
      "loss: 0.29 accuracy: 0.90 \n",
      "val_loss: 0.32 val_accuracy: 0.88\n",
      "Epoch 5:\n",
      "############################################################\n",
      "loss: 0.27 accuracy: 0.91 \n",
      "val_loss: 0.30 val_accuracy: 0.89\n",
      "Training:End\n",
      "Test accuracy 0.89\n",
      "WARNING:tensorflow:From <ipython-input-12-f5b7ede6452d>:76: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: test_model/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #Divide input training set into mini batches of size batch_size.\n",
    "        #If the total number of training examles is not exactly divisible by batch_size, \n",
    "        #the last batch will have less number of examples than batch_size.\n",
    "\n",
    "        total_size = train_x.shape[0]\n",
    "        number_of_batches = int(total_size/batch_size)\n",
    "\n",
    "        print(\"Training:Start\")\n",
    "        for e in range(epoch):\n",
    "            epoch_cost = 0\n",
    "            epoch_accuracy = 0\n",
    "            print(\"Epoch {}:\".format(e+1))\n",
    "            for i in range(number_of_batches):\n",
    "                print(\"#\", end='')\n",
    "                mini_x = train_x[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "                mini_y = train_y[i*batch_size:(i+1)*batch_size, :]\n",
    "                _, cost = sess.run([cnn_model[\"train_op\"], cnn_model[\"loss\"]], \n",
    "                    feed_dict={x:mini_x, \n",
    "                               y:mini_y,\n",
    "                               train_mode:True})\n",
    "                train_accuracy = sess.run(cnn_model[\"accuracy\"], \n",
    "                    feed_dict={x:mini_x, \n",
    "                               y:mini_y,\n",
    "                               train_mode:False})\n",
    "                epoch_cost += cost\n",
    "                epoch_accuracy += train_accuracy\n",
    "\n",
    "            #If the total number of training examles is not exactly divisible by batch_size, \n",
    "            #we have one more batch of size (total_size - number_of_batches*batch_size)\n",
    "            if total_size % batch_size != 0:\n",
    "                print(\"#\", end='')\n",
    "                mini_x = train_x[number_of_batches*batch_size:total_size, :, :, :]\n",
    "                mini_y = train_y[number_of_batches*batch_size:total_size, :]\n",
    "                _, cost = sess.run([cnn_model[\"train_op\"], cnn_model[\"loss\"]], \n",
    "                    feed_dict={x:mini_x, \n",
    "                               y:mini_y,\n",
    "                               train_mode:True})\n",
    "                train_accuracy = sess.run(cnn_model[\"accuracy\"], \n",
    "                    feed_dict={x:mini_x, \n",
    "                               y:mini_y,\n",
    "                               train_mode: False})\n",
    "                epoch_cost += cost\n",
    "                epoch_accuracy += train_accuracy\n",
    "\n",
    "            epoch_cost /= number_of_batches\n",
    "\n",
    "            if total_size % batch_size != 0:\n",
    "                epoch_accuracy /= (number_of_batches+1)\n",
    "            else:\n",
    "                epoch_accuracy /= number_of_batches\n",
    "            print()    \n",
    "            print(\"loss: {:02.2f} accuracy: {:02.2f} \".format(np.squeeze(epoch_cost), epoch_accuracy))\n",
    "            #Cross validation loss and accuracy\n",
    "            cv_loss, cv_accuracy = sess.run([cnn_model[\"loss\"], cnn_model[\"accuracy\"]], \n",
    "                                        {x:test_x, \n",
    "                                         y:test_y,\n",
    "                                         train_mode: False})\n",
    "            print(\"val_loss: {:02.2f} val_accuracy: {:02.2f}\".format(np.squeeze(cv_loss), cv_accuracy))\n",
    "\n",
    "        print(\"Training:End\")\n",
    "\n",
    "\n",
    "        #prediction for test set\n",
    "        test_accuracy, prediction = sess.run([cnn_model[\"accuracy\"], \n",
    "                                              cnn_model[\"predictions\"][\"classes\"]], \n",
    "                                             {x:test_x, y:test_y, train_mode:False})\n",
    "        print(\"Test accuracy {:02.2f}\".format(test_accuracy))\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        inputs = {\"x\":cnn_model['raw_x'], \"train_mode\":cnn_model['train_mode']}\n",
    "        outputs = {\"prediction\": cnn_model['predictions']['classes']}\n",
    "        tf.saved_model.simple_save(sess, 'test_model', inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference test run (Ipython kernel restarting required!!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "with open(\"test.png\", \"rb\") as f:\n",
    "    img_bytes = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ankle boot']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "loaded = tf.compat.v2.saved_model.load('test_model')\n",
    "loaded_func = loaded.signatures[tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "pred = loaded_func(x=tf.constant([img_bytes], dtype=tf.string), train_mode=tf.constant(False))\n",
    "output = pred['prediction']\n",
    "[class_names[c] for c in output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "And the model predicts a label as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BentoService class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tensorflow_1_fashion_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tensorflow_1_fashion_mnist.py\n",
    "\n",
    "import bentoml\n",
    "import tensorflow as tf\n",
    "\n",
    "from bentoml.frameworks.tensorflow import TensorflowSavedModelArtifact\n",
    "from bentoml.adapters import TfTensorInput\n",
    "\n",
    "tf.compat.v1.enable_eager_execution() # required\n",
    "\n",
    "FASHION_MNIST_CLASSES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "\n",
    "@bentoml.env(pip_packages=['tensorflow', 'numpy', 'pillow'])\n",
    "@bentoml.artifacts([TensorflowSavedModelArtifact('trackable')])\n",
    "class FashionMnistTensorflow(bentoml.BentoService):\n",
    "\n",
    "    @bentoml.api(input=TfTensorInput(), batch=True)\n",
    "    def predict(self, inputs):\n",
    "        loaded_func = self.artifacts.trackable.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "        pred = loaded_func(x=inputs, train_mode=tf.constant(False))\n",
    "        output = pred['prediction']\n",
    "        return [FASHION_MNIST_CLASSES[c] for c in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-30 04:31:44,754] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-07-30 04:31:44,775] WARNING - pillow package does not exist in the current python session\n",
      "[2020-07-30 04:31:57,643] INFO - Detect BentoML installed in development model, copying local BentoML module file to target saved bundle path\n",
      "running sdist\n",
      "running egg_info\n",
      "writing BentoML.egg-info/PKG-INFO\n",
      "writing dependency_links to BentoML.egg-info/dependency_links.txt\n",
      "writing entry points to BentoML.egg-info/entry_points.txt\n",
      "writing requirements to BentoML.egg-info/requires.txt\n",
      "writing top-level names to BentoML.egg-info/top_level.txt\n",
      "reading manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "warning: no directories found matching 'bentoml/server/static'\n",
      "warning: no directories found matching 'bentoml/yatai/web/dist'\n",
      "no previously-included directories found matching 'e2e_tests'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'benchmark'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating BentoML-0.8.3+42.gb8d36b6\n",
      "creating BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/clipper\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/configuration\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/handlers\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/client\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/__pycache__\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions/__pycache__\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/validator\n",
      "copying files to BentoML-0.8.3+42.gb8d36b6...\n",
      "copying LICENSE -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying MANIFEST.in -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying README.md -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying pyproject.toml -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying setup.cfg -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying setup.py -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying versioneer.py -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying BentoML.egg-info/PKG-INFO -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/SOURCES.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/dependency_links.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/entry_points.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/requires.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/top_level.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying bentoml/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/_version.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/exceptions.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/service.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/service_env.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/adapters/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/base_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/base_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/clipper_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/dataframe_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/dataframe_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/default_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/fastai_image_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/file_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/image_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/json_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/json_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/legacy_image_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/legacy_json_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/multi_image_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/pytorch_tensor_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/tensorflow_tensor_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/tensorflow_tensor_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/artifact/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/fastai2_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/fastai_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/fasttext_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/h2o_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/json_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/keras_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/lightgbm_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/onnx_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/pickle_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/pytorch_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/sklearn_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/spacy_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/text_file_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/tf_savedmodel_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/xgboost_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/cli/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/aws_lambda.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/aws_sagemaker.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/azure_functions.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/bento_management.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/bento_service.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/click_utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/config.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/deployment.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/yatai_service.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/clipper/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/clipper\n",
      "copying bentoml/configuration/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration\n",
      "copying bentoml/configuration/configparser.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration\n",
      "copying bentoml/configuration/default_bentoml.cfg -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration\n",
      "copying bentoml/configuration/__pycache__/__init__.cpython-36.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/__init__.cpython-37.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/__init__.cpython-38.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/configparser.cpython-36.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/configparser.cpython-37.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/configparser.cpython-38.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/handlers/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/handlers\n",
      "copying bentoml/marshal/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "copying bentoml/marshal/dispatcher.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "copying bentoml/marshal/marshal.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "copying bentoml/marshal/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "copying bentoml/saved_bundle/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/bentoml-init.sh -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/bundler.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/config.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/docker-entrypoint.sh -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/loader.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/pip_pkg.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/py_module_utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/templates.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/server/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/api_server.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/gunicorn_config.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/gunicorn_server.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/instruments.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/marshal_server.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/open_api.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/trace.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/utils/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/alg.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/benchmark.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/cloudpickle.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/dataframe_util.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/flask_ngrok.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/hybridmethod.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/lazy_loader.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/log.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/s3.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/tempdir.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/usage_stats.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/yatai/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/alembic.ini -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/db.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/deployment_utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/status.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/yatai_service.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/yatai_service_impl.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/client/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/client\n",
      "copying bentoml/yatai/client/bento_repository_api.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/client\n",
      "copying bentoml/yatai/client/deployment_api.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/client\n",
      "copying bentoml/yatai/deployment/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "copying bentoml/yatai/deployment/operator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "copying bentoml/yatai/deployment/store.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "copying bentoml/yatai/deployment/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "copying bentoml/yatai/deployment/aws_lambda/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/aws_lambda/download_extra_resources.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/aws_lambda/lambda_app.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/aws_lambda/operator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/aws_lambda/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/azure_functions/Dockerfile -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/app_init.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/constants.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/host.json -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/local.settings.json -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/operator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/templates.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/sagemaker/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/model_server.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/nginx.conf -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/operator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/serve -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/wsgi.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/migrations/README -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "copying bentoml/yatai/migrations/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "copying bentoml/yatai/migrations/env.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "copying bentoml/yatai/migrations/script.py.mako -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "copying bentoml/yatai/migrations/__pycache__/env.cpython-36.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/__pycache__\n",
      "copying bentoml/yatai/migrations/versions/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions\n",
      "copying bentoml/yatai/migrations/versions/a6b00ae45279_add_last_updated_at_for_deployments.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions\n",
      "copying bentoml/yatai/migrations/versions/__pycache__/a6b00ae45279_add_last_updated_at_for_deployments.cpython-36.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions/__pycache__\n",
      "copying bentoml/yatai/proto/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/deployment_pb2.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/repository_pb2.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/status_pb2.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/yatai_service_pb2.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/yatai_service_pb2_grpc.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/repository/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/base_repository.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/local_repository.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/metadata_store.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/repository.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/s3_repository.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/validator/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/validator\n",
      "copying bentoml/yatai/validator/deployment_pb_validator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/validator\n",
      "Writing BentoML-0.8.3+42.gb8d36b6/setup.cfg\n",
      "UPDATING BentoML-0.8.3+42.gb8d36b6/bentoml/_version.py\n",
      "set BentoML-0.8.3+42.gb8d36b6/bentoml/_version.py to '0.8.3+42.gb8d36b6'\n",
      "Creating tar archive\n",
      "removing 'BentoML-0.8.3+42.gb8d36b6' (and everything under it)\n",
      "[2020-07-30 04:31:58,786] INFO - BentoService bundle 'FashionMnistTensorflow:20200730043145_D7CFA7' saved to: /home/bentoml/bentoml/repository/FashionMnistTensorflow/20200730043145_D7CFA7\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_1_fashion_mnist import FashionMnistTensorflow\n",
    "\n",
    "bento_svc = FashionMnistTensorflow()\n",
    "bento_svc.pack(\"trackable\", \"test_model/\")\n",
    "saved_path = bento_svc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST API Model Serving\n",
    "\n",
    "\n",
    "To start a REST API model server with the BentoService saved above, use the bentoml serve command:## Use BentoService with BentoML CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-30 04:32:54,971] INFO - Getting latest version FashionMnistTensorflow:20200730043145_D7CFA7\n",
      "[2020-07-30 04:32:54,972] INFO - Starting BentoML API server in development mode..\n",
      "[2020-07-30 04:32:55,995] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-07-30 04:32:56,019] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.8.3, but loading from BentoML version 0.8.3+42.gb8d36b6\n",
      "[2020-07-30 04:32:57,330] WARNING - pillow package does not exist in the current python session\n",
      "2020-07-30 04:32:57.431393: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2020-07-30 04:32:57.445711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-30 04:32:57.446136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-07-30 04:32:57.446314: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-30 04:32:57.447907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-30 04:32:57.449390: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-30 04:32:57.449679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-30 04:32:57.451276: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-30 04:32:57.452252: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-30 04:32:57.456047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-30 04:32:57.456312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-30 04:32:57.456922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-30 04:32:57.457266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-07-30 04:32:57.457504: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-07-30 04:32:57.481153: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2699905000 Hz\n",
      "2020-07-30 04:32:57.481420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c778a64030 executing computations on platform Host. Devices:\n",
      "2020-07-30 04:32:57.481440: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-07-30 04:32:57.481628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-30 04:32:57.482007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-07-30 04:32:57.482042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-30 04:32:57.482056: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-30 04:32:57.482069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-30 04:32:57.482081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-30 04:32:57.482094: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-30 04:32:57.482107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-30 04:32:57.482119: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-30 04:32:57.482167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-30 04:32:57.482516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-30 04:32:57.482843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-07-30 04:32:57.482870: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-30 04:32:57.602843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-07-30 04:32:57.602880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-07-30 04:32:57.602888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-07-30 04:32:57.603093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-30 04:32:57.607368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-30 04:32:57.607893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-30 04:32:57.608255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5465 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2020-07-30 04:32:57.610924: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c77d013140 executing computations on platform CUDA. Devices:\n",
      "2020-07-30 04:32:57.610962: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1060, Compute Capability 6.1\n",
      "[2020-07-30 04:32:58,238] WARNING - Importing SavedModels from TensorFlow 1.x.\n",
      "                `outputs = imported(inputs)` is not supported in bento service due to\n",
      "                tensorflow API.\n",
      "\n",
      "                Recommended usage:\n",
      "\n",
      "                ```python\n",
      "                from tensorflow.python.saved_model import signature_constants\n",
      "\n",
      "                imported = tf.saved_model.load(path_to_v1_saved_model)\n",
      "                wrapped_function = imported.signatures[\n",
      "                    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
      "                wrapped_function(tf.ones([]))\n",
      "                ```\n",
      "\n",
      "                See https://www.tensorflow.org/api_docs/python/tf/saved_model/load for\n",
      "                details.\n",
      "                \n",
      " * Serving Flask app \"FashionMnistTensorflow\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve FashionMnistTensorflow:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running this notebook from Google Colab, you can start the dev server with `--run-with-ngrok` option, to gain acccess to the API endpoint via a public endpoint managed by [ngrok](https://ngrok.com/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve FashionMnistTensorflow:latest --run-with-ngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {\"instances\": [{\"b64\": \"iVBORw0KGgoAAAANSUhEUgAAAB ... ufkz8DPG//sD/AX8I8DvdgnOxdB4B1wAAAAASUVORK5CYII=\"}]}\n",
      "<Response [200]>\n",
      "[\"Ankle boot\"]\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import requests\n",
    "\n",
    "with open(\"test.png\", \"rb\") as f:\n",
    "    img_bytes = f.read()\n",
    "img_b64 = base64.b64encode(img_bytes).decode()\n",
    "\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "data = json.dumps(\n",
    "       {\"instances\": [{\"b64\": img_b64}]}\n",
    ")\n",
    "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))\n",
    "\n",
    "json_response = requests.post(f'http://localhost:5000/predict', data=data, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containerize model server with Docker\n",
    "\n",
    "\n",
    "One common way of distributing this model API server for production deployment, is via Docker containers. And BentoML provides a convenient way to do that.\n",
    "\n",
    "Note that docker is **not available in Google Colab**. You will need to download and run this notebook locally to try out this containerization with docker feature.\n",
    "\n",
    "If you already have docker configured, simply run the follow command to product a docker container serving the IrisClassifier prediction service created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256:ab1acf390e1827b442c4d11a44a9b7ee49e9cb85e097d5febb42cfaaf2357f45\n"
     ]
    }
   ],
   "source": [
    "!bentoml containerize FashionMnistTensorflow:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-29 20:40:37,074] INFO - Starting BentoML API server in production mode..\n",
      "[2020-07-29 20:40:37,486] INFO - Running micro batch service on :5000\n",
      "[2020-07-29 20:40:37 +0000] [13] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-07-29 20:40:37 +0000] [1] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-07-29 20:40:37 +0000] [13] [INFO] Listening at: http://0.0.0.0:5000 (13)\n",
      "[2020-07-29 20:40:37 +0000] [13] [INFO] Using worker: aiohttp.worker.GunicornWebWorker\n",
      "[2020-07-29 20:40:37 +0000] [1] [INFO] Listening at: http://0.0.0.0:41595 (1)\n",
      "[2020-07-29 20:40:37 +0000] [1] [INFO] Using worker: sync\n",
      "[2020-07-29 20:40:37 +0000] [15] [INFO] Booting worker with pid: 15\n",
      "[2020-07-29 20:40:37 +0000] [14] [INFO] Booting worker with pid: 14\n",
      "[2020-07-29 20:40:37,514] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deplying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-07-29 20:40:37,536] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.8.3, but loading from BentoML version 0.8.3+42.gb8d36b6\n",
      "[2020-07-29 20:40:37,547] INFO - Micro batch enabled for API `predict`\n",
      "[2020-07-29 20:40:37,548] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
      "[2020-07-29 20:40:38,490] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deplying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-07-29 20:40:38,527] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.8.3, but loading from BentoML version 0.8.3+42.gb8d36b6\n",
      "2020-07-29 20:40:38.663167: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2020-07-29 20:40:38.663256: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'dense/kernel:0' shape=(3136, 1024) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "2020-07-29 20:40:40.032709: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-07-29 20:40:40.032738: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-07-29 20:40:40.032760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2020-07-29 20:40:40.033047: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-07-29 20:40:40.057160: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2699905000 Hz\n",
      "2020-07-29 20:40:40.057753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560bd8c90030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-29 20:40:40.057838: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'dense/kernel:0' shape=(3136, 1024) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'dense/kernel:0' shape=(3136, 1024) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'dense/kernel:0' shape=(3136, 1024) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "^C\n",
      "[2020-07-29 20:40:56 +0000] [1] [INFO] Handling signal: int\n",
      "[2020-07-29 20:40:56 +0000] [15] [INFO] Worker exiting (pid: 15)\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 5000:5000 fashionmnisttensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved BentoService\n",
    "\n",
    "bentoml.load is the API for loading a BentoML packaged model in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bentoml import load\n",
    "\n",
    "\n",
    "load_svc = load(saved_path)\n",
    "\n",
    "print(load_svc.predict([data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch inference job from CLI\n",
    "\n",
    "BentoML cli supports loading and running a packaged model from CLI. With the DataframeInput adapter, the CLI command supports reading input Dataframe data from CLI argument or local csv or json files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml run FashionMnistTensorflow:latest --input {data} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Options\n",
    "\n",
    "If you are at a small team with limited engineering or DevOps resources, try out automated deployment with BentoML CLI, currently supporting AWS Lambda, AWS SageMaker, and Azure Functions:\n",
    "- [AWS Lambda Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_lambda.html)\n",
    "- [AWS SageMaker Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_sagemaker.html)\n",
    "- [Azure Functions Deployment Guide](https://docs.bentoml.org/en/latest/deployment/azure_functions.html)\n",
    "\n",
    "If the cloud platform you are working with is not on the list above, try out these step-by-step guide on manually deploying BentoML packaged model to cloud platforms:\n",
    "- [AWS ECS Deployment](https://docs.bentoml.org/en/latest/deployment/aws_ecs.html)\n",
    "- [Google Cloud Run Deployment](https://docs.bentoml.org/en/latest/deployment/google_cloud_run.html)\n",
    "- [Azure container instance Deployment](https://docs.bentoml.org/en/latest/deployment/azure_container_instance.html)\n",
    "- [Heroku Deployment](https://docs.bentoml.org/en/latest/deployment/heroku.html)\n",
    "\n",
    "Lastly, if you have a DevOps or ML Engineering team who's operating a Kubernetes or OpenShift cluster, use the following guides as references for implementating your deployment strategy:\n",
    "- [Kubernetes Deployment](https://docs.bentoml.org/en/latest/deployment/kubernetes.html)\n",
    "- [Knative Deployment](https://docs.bentoml.org/en/latest/deployment/knative.html)\n",
    "- [Kubeflow Deployment](https://docs.bentoml.org/en/latest/deployment/kubeflow.html)\n",
    "- [KFServing Deployment](https://docs.bentoml.org/en/latest/deployment/kfserving.html)\n",
    "- [Clipper.ai Deployment Guide](https://docs.bentoml.org/en/latest/deployment/clipper.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
