{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using tensorflow to create `Convolutional Neural Network`(`CNN`) with `fashion_mnist` example\n",
    "\n",
    "**BentoML makes moving trained ML models to production easy:**\n",
    "\n",
    "* Package models trained with **any ML framework** and reproduce them for model serving in production\n",
    "* **Deploy anywhere** for online API serving or offline batch serving\n",
    "* High-Performance API model server with *adaptive micro-batching* support\n",
    "* Central hub for managing models and deployment process via Web UI and APIs\n",
    "* Modular and flexible design making it *adaptable to your infrastrcuture*\n",
    "\n",
    "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=tensorflow&ea=CNN_fashion_mnist_without_keras&dt=CNN_fashion_mnist_without_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `CNN` will make it easier to process image classification. By using `tensorflow` without `keras` version to implement a very simple, `CNN` will help readers to understand `tensorflow`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from  PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "use `tf.keras.datasets` to complete the data import (Use keras may have faster network speed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(images_train, labels_train), (images_test, labels_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(images_test[1]).save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = images_train / 255.0\n",
    "images_test = images_test / 255.0\n",
    "# For an ordinary picture, there are usually 3 dimensions, of which the last dimension is 3, \n",
    "# by useing the grayscale image as an example, so only one dimension is expanded, and the last dimension is 1.\n",
    "images_train = np.reshape(images_train, (60000, 28, 28, 1))\n",
    "images_test = np.reshape(images_test, (10000, 28, 28, 1))\n",
    "# print(\"images train shape:{}\\nimages test shape:{}\".format(images_train.shape, labels_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the layers \n",
    "Generally speaking, we use the following three operations:\n",
    "- [`conv2d`](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) with `padding=\"SAME\"` and performing Leaky ReLU activation function\n",
    "- [`maxpool`](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool2d) by `2 x 2`\n",
    "- [`dense`](https://www.tensorflow.org/api_docs/python/tf/nn/leaky_relu) perform Leaky ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu_alpha = 0.2\n",
    "dropout_rate = 0.5 \n",
    "\n",
    "# conv2d\n",
    "def conv2d(inputs, filters, stride_size):\n",
    "    out = tf.nn.conv2d(inputs, filters, strides=[1, stride_size, stride_size, 1], padding=\"SAME\") \n",
    "    return tf.nn.leaky_relu(out, alpha=leaky_relu_alpha) \n",
    "# max pool\n",
    "def maxpool(inputs, pool_size, stride_size):\n",
    "    return tf.nn.max_pool2d(inputs, ksize=[1, pool_size, pool_size, 1], padding='VALID', strides=[1, stride_size, stride_size, 1])\n",
    "\n",
    "# Leaky ReLU\n",
    "def dense(inputs, weights):\n",
    "    x = tf.nn.leaky_relu(tf.matmul(inputs, weights), alpha=leaky_relu_alpha)\n",
    "    return tf.nn.dropout(x, rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets\n",
    "output_classes = 10\n",
    "# Glorot uniform initializer to initialize weithts\n",
    "initializer = tf.initializers.glorot_uniform()\n",
    "def get_weight(shape, name):\n",
    "    return tf.Variable(initializer(shape), name=name, trainable=True, dtype=tf.float32 )\n",
    "\n",
    "# shapes of each layer operation\n",
    "shapes = [\n",
    "    [3, 3, 1, 4], # conv2d 28 x 28  x 4 \n",
    "    [3, 3, 4, 4], # conv2d 28 x 28  x 4\n",
    "    # maxpool  14 x 14 x 4 \n",
    "    [784, 128], # dense 784 to 128\n",
    "    [128, output_classes], # 128 to 10\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "In this case, the operations includes   \n",
    "`convolution layer 1(60000x28x28x4)` $\\rightarrow$ `convolution layer 2(60000x28x28x4)`   \n",
    "$\\rightarrow$ `max pooling(60000x14x14x4)` $\\rightarrow$ `fully connected layer(60000x784)`   \n",
    "$\\rightarrow$ `fully connected layer(60000x128)` $\\rightarrow$ `fully connected layer(60000x10)`  \n",
    "Finally get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.Module):\n",
    "    # def __init__(self, in_features, out_features, name=None):\n",
    "    def __init__(self):\n",
    "        # # initialize the weights\n",
    "        self.weights=[]\n",
    "        for i in range(len(shapes)):\n",
    "            self.weights.append(get_weight(shapes[i], \"weight{}\".format(i)))\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name='x')])\n",
    "    def __call__(self, x):\n",
    "        x = tf.cast(x, dtype=tf.float32) \n",
    "        # convolution layer 1\n",
    "        c1 = conv2d(x,self.weights[0], stride_size=1) \n",
    "        # convolution layer 2\n",
    "        c2 = conv2d(c1, self.weights[1], stride_size=1)\n",
    "        # maxpool\n",
    "        p2 = maxpool(c2, pool_size=2, stride_size=2)\n",
    "        # flatten the output into a vector\n",
    "        flatten = tf.reshape(p2, shape=(tf.shape(p2)[0], -1))\n",
    "        # fully connected layer\n",
    "        d3 = dense(flatten, self.weights[2])\n",
    "        logits = tf.matmul(d3, self.weights[3])\n",
    "        # return the last layer\n",
    "        return tf.nn.softmax(logits)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss(pred, target):\n",
    "    return tf.losses.categorical_crossentropy(target, pred)\n",
    "\n",
    "# accuracydefining model\n",
    "def accur(pred, target):\n",
    "    pred_true = tf.argmax(pred, axis=1)\n",
    "    y_true = tf.argmax(target, axis=1)\n",
    "    y_eq = tf.cast(tf.equal(pred_true, y_true), tf.float16)\n",
    "    return tf.reduce_mean(y_eq)\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "\n",
    "#training operartions\n",
    "def train_step(model, inputs, outputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(inputs)\n",
    "        current_loss = loss(pred, outputs)\n",
    "    grads = tape.gradient(current_loss, model.weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.weights))\n",
    "    #print(tf.reduce_mean(current_loss).numpy(), accur(pred, outputs))\n",
    "    return accur(pred, outputs).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3984\n",
      "0.438\n",
      "0.4478\n",
      "0.4563\n",
      "0.4568\n",
      "0.4614\n",
      "0.4636\n",
      "0.4663\n",
      "0.4683\n",
      "0.4697\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "y = tf.one_hot(labels_train, depth=10)\n",
    "X = images_train\n",
    "for e in range(num_epochs):\n",
    "    accurs = []\n",
    "    for b in range(0, len(X), batch_size): \n",
    "        acc = train_step(model, X[b: b + batch_size], y[b: b + batch_size])\n",
    "        accurs.append(acc)\n",
    "    print(np.mean(accurs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BentoService class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install BentoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bentoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CNN_fashion_mnist_without_keras.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile CNN_fashion_mnist_without_keras.py\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import bentoml\n",
    "\n",
    "from bentoml.artifact import TensorflowSavedModelArtifact\n",
    "from bentoml.adapters import ImageInput\n",
    "\n",
    "FASHION_MNIST_CLASSES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "\n",
    "@bentoml.env(pip_dependencies=['tensorflow', 'numpy', 'pillow'])\n",
    "@bentoml.artifacts([TensorflowSavedModelArtifact('model')])\n",
    "class FashionMnistTensorflow(bentoml.BentoService):\n",
    "    @bentoml.api(input=ImageInput(pilmode=\"L\"), batch=True)\n",
    "    def predict(self, inputs):\n",
    "        X = tf.constant(inputs, dtype=tf.uint8)\n",
    "        X = tf.expand_dims(X, -1)\n",
    "        outputs = self.artifacts.model(X)\n",
    "        output_classes = tf.math.argmax(outputs, axis=1)\n",
    "        return [FASHION_MNIST_CLASSES[c] for c in output_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-06 17:50:10,242] WARNING - Importing from \"bentoml.artifact.*\" has been deprecated. Instead, use`bentoml.frameworks.*` and `bentoml.service.*`. e.g.:, `from bentoml.frameworks.sklearn import SklearnModelArtifact`, `from bentoml.service.artifacts import BentoServiceArtifact`, `from bentoml.service.artifacts.common import PickleArtifact`\n",
      "[2020-11-06 17:50:10,294] WARNING - pip package requirement tensorflow already exist\n",
      "INFO:tensorflow:Assets written to: /tmp/bentoml-temp-ljk0o6pa/FashionMnistTensorflow/artifacts/model_saved_model/assets\n",
      "[2020-11-06 17:50:11,702] INFO - BentoService bundle 'FashionMnistTensorflow:20201106175010_C46220' saved to: /home/ruhan/bentoml/repository/FashionMnistTensorflow/20201106175010_C46220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ruhan/bentoml/repository/FashionMnistTensorflow/20201106175010_C46220'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import CNN_fashion_mnist_without_keras\n",
    "import bentoml\n",
    "import importlib\n",
    "\n",
    "\n",
    "importlib.reload(CNN_fashion_mnist_without_keras)\n",
    "importlib.reload(bentoml)\n",
    "\n",
    "service = CNN_fashion_mnist_without_keras.FashionMnistTensorflow()\n",
    "service.pack(\"model\", model)\n",
    "service.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trouser']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test localy\n",
    "import imageio\n",
    "img_array = imageio.imread('test.png')\n",
    "inputs = [img_array]\n",
    "\n",
    "service.predict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BentoService with BentoML CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39mBENTO_SERVICE                                 AGE                           APIS                                  ARTIFACTS                            LABELS\n",
      "FashionMnistTensorflow:20201106175010_C46220  0.84 seconds                  predict<ImageInput:DefaultOutput>     model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106173151_5F9336  18 minutes and 19.53 seconds  predict<ImageInput:DefaultOutput>     model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106172745_5D67B2  22 minutes and 25.88 seconds  predict<ImageInput:DefaultOutput>     model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106171319_1EB882  36 minutes and 52.19 seconds  predict<ImageInput:DefaultOutput>     model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106170537_541DC5  44 minutes and 33.47 seconds  predict<ImageInput:DefaultOutput>     model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106165520_2C2D52  54 minutes and 50.64 seconds  predict<ImageInput:DefaultOutput>     model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106151707_E1A06D  2 hours and 33 minutes        predict<ImageInput:DefaultOutput>     model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106151459_9CDB3F  2 hours and 35 minutes        predict<ImageInput:DefaultOutput>     model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106151348_73C358  2 hours and 36 minutes        predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106145911_A81DDE  2 hours and 50 minutes        predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106142447_B7C297  3 hours and 25 minutes        predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106141537_C84DF4  3 hours and 34 minutes        predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106110118_17D81A  6 hours and 48 minutes        predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106105431_E114BE  6 hours and 55 minutes        predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106105217_700A8C  6 hours and 57 minutes        predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106105015_938079  6 hours and 59 minutes        predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106104652_6FE596  7 hours and 3 minutes         predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106104553_E8D9E4  7 hours and 4 minutes         predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106104318_EAFFC9  7 hours and 6 minutes         predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201106103322_1A0167  7 hours and 16 minutes        predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201105200918_D0B53B  21 hours and 40 minutes       predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201019164508_10851E  2 weeks and 4 days            predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201019164252_B0A601  2 weeks and 4 days            predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201019163549_F0AD7C  2 weeks and 4 days            predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201019163152_C571AC  2 weeks and 4 days            predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201019162315_4541B7  2 weeks and 4 days            predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201019162019_A7A07B  2 weeks and 4 days            predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201019161952_169ECD  2 weeks and 4 days            predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\n",
      "FashionMnistTensorflow:20201019154847_5D151D  2 weeks and 4 days            predict<TfTensorInput:DefaultOutput>  model<TensorflowSavedModelArtifact>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml get FashionMnistTensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService name>:<bentoService version>` display detailed information of the specific BentoService version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-06 17:50:14,508] INFO - Getting latest version FashionMnistTensorflow:20201106175010_C46220\n",
      "\u001b[39m{\n",
      "  \"name\": \"FashionMnistTensorflow\",\n",
      "  \"version\": \"20201106175010_C46220\",\n",
      "  \"uri\": {\n",
      "    \"type\": \"LOCAL\",\n",
      "    \"uri\": \"/home/ruhan/bentoml/repository/FashionMnistTensorflow/20201106175010_C46220\"\n",
      "  },\n",
      "  \"bentoServiceMetadata\": {\n",
      "    \"name\": \"FashionMnistTensorflow\",\n",
      "    \"version\": \"20201106175010_C46220\",\n",
      "    \"createdAt\": \"2020-11-06T09:50:11.676366Z\",\n",
      "    \"env\": {\n",
      "      \"condaEnv\": \"name: bentoml-default-conda-env\\nchannels:\\n- conda-forge\\n- defaults\\ndependencies:\\n- pip\\n\",\n",
      "      \"pythonVersion\": \"3.7.9\",\n",
      "      \"dockerBaseImage\": \"bentoml/model-server:0.9.2-py37\",\n",
      "      \"pipPackages\": [\n",
      "        \"bentoml==0.9.2\",\n",
      "        \"tensorflow==2.3.1\",\n",
      "        \"numpy==1.18.5\",\n",
      "        \"pillow==8.0.0\",\n",
      "        \"imageio==2.9.0\"\n",
      "      ]\n",
      "    },\n",
      "    \"artifacts\": [\n",
      "      {\n",
      "        \"name\": \"model\",\n",
      "        \"artifactType\": \"TensorflowSavedModelArtifact\"\n",
      "      }\n",
      "    ],\n",
      "    \"apis\": [\n",
      "      {\n",
      "        \"name\": \"predict\",\n",
      "        \"inputType\": \"ImageInput\",\n",
      "        \"docs\": \"BentoService inference API 'predict', input: 'ImageInput', output: 'DefaultOutput'\",\n",
      "        \"inputConfig\": {\n",
      "          \"pilmode\": \"L\",\n",
      "          \"accept_image_formats\": [\n",
      "            \".webp\",\n",
      "            \".bmp\",\n",
      "            \".tiff\",\n",
      "            \".jpeg\",\n",
      "            \".jpg\",\n",
      "            \".png\"\n",
      "          ]\n",
      "        },\n",
      "        \"outputConfig\": {\n",
      "          \"cors\": \"*\"\n",
      "        },\n",
      "        \"outputType\": \"DefaultOutput\",\n",
      "        \"mbMaxLatency\": 10000,\n",
      "        \"mbMaxBatchSize\": 2000,\n",
      "        \"batch\": true\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml get FashionMnistTensorflow:latest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Serve bentoml REST server locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !bentoml serve FashionMnistTensorflow:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "'\"Trouser\"'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "with open(\"test.png\", \"rb\") as f:\n",
    "    img_bytes = f.read()\n",
    "\n",
    "\n",
    "headers = {\"Content-Type\": \"image/png\"}\n",
    "\n",
    "json_response = requests.post(f'http://127.0.0.1:5000/predict', data=img_bytes, headers=headers)\n",
    "print(json_response)\n",
    "print(repr(json_response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reference\n",
    "- [Image Classification From Scratch  With TensorFlow 2.0](https://colab.research.google.com/drive/15QZMSIrvE4MgVq2GnQ0XUsqQssY6sn7w#scrollTo=8T1Pf4mbuVRI&forceEdit=true&sandboxMode=true)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
