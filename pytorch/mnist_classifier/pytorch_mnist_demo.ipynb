{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a682ea0b",
   "metadata": {},
   "source": [
    "# BentoML PyTorch MNIST Tutorial\n",
    "\n",
    "Link to source code: https://github.com/bentoml/gallery/tree/main/pytorch_mnist_demo/\n",
    "\n",
    "Install required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad00863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/larme/notebooks/venv/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (0.23.2)\n",
      "Requirement already satisfied: torch in /home/larme/notebooks/venv/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.9.0+cpu)\n",
      "Requirement already satisfied: bentoml in /home/larme/codes/BentoML (from -r requirements.txt (line 3)) (1.0.0a1.post17+gb561a861.d20220110)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from scikit-learn->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.21.4)\n",
      "Requirement already satisfied: typing-extensions in /home/larme/notebooks/venv/lib/python3.7/site-packages (from torch->-r requirements.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: PyYAML in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (6.0)\n",
      "Requirement already satisfied: aiofiles in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: aiohttp in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (21.2.0)\n",
      "Requirement already satisfied: cattrs in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (1.8.0)\n",
      "Requirement already satisfied: chardet in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: circus in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.17.1)\n",
      "Requirement already satisfied: click>=7.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (7.1.2)\n",
      "Requirement already satisfied: cloudpickle in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: deepmerge in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.3.0)\n",
      "Requirement already satisfied: fs in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (2.4.14)\n",
      "Requirement already satisfied: packaging in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (21.3)\n",
      "Requirement already satisfied: pathspec in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: pip-tools in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (6.4.0)\n",
      "Requirement already satisfied: prometheus-client in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: psutil in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (5.8.0)\n",
      "Requirement already satisfied: python-dateutil in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (2.8.1)\n",
      "Requirement already satisfied: python-json-logger in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (2.0.2)\n",
      "Requirement already satisfied: python-multipart in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.0.5)\n",
      "Requirement already satisfied: requests in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (2.26.0)\n",
      "Requirement already satisfied: rich in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (10.15.1)\n",
      "Requirement already satisfied: schema in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.7.4)\n",
      "Requirement already satisfied: simple-di>=0.1.4 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.1.4)\n",
      "Requirement already satisfied: starlette in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.17.1)\n",
      "Requirement already satisfied: uvicorn in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (0.15.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/larme/notebooks/venv/lib/python3.7/site-packages (from bentoml->-r requirements.txt (line 3)) (4.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from packaging->bentoml->-r requirements.txt (line 3)) (3.0.6)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from aiohttp->bentoml->-r requirements.txt (line 3)) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from aiohttp->bentoml->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from aiohttp->bentoml->-r requirements.txt (line 3)) (4.0.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from aiohttp->bentoml->-r requirements.txt (line 3)) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from aiohttp->bentoml->-r requirements.txt (line 3)) (2.0.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from aiohttp->bentoml->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from aiohttp->bentoml->-r requirements.txt (line 3)) (5.2.0)\n",
      "Requirement already satisfied: pyzmq>=17.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from circus->bentoml->-r requirements.txt (line 3)) (22.3.0)\n",
      "Requirement already satisfied: tornado>=5.0.2 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from circus->bentoml->-r requirements.txt (line 3)) (6.1)\n",
      "Requirement already satisfied: setuptools in /home/larme/notebooks/venv/lib/python3.7/site-packages (from fs->bentoml->-r requirements.txt (line 3)) (59.6.0)\n",
      "Requirement already satisfied: pytz in /home/larme/notebooks/venv/lib/python3.7/site-packages (from fs->bentoml->-r requirements.txt (line 3)) (2021.3)\n",
      "Requirement already satisfied: six~=1.10 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from fs->bentoml->-r requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from fs->bentoml->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from importlib-metadata->bentoml->-r requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: pep517 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from pip-tools->bentoml->-r requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: pip>=21.2 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from pip-tools->bentoml->-r requirements.txt (line 3)) (21.3.1)\n",
      "Requirement already satisfied: wheel in /home/larme/notebooks/venv/lib/python3.7/site-packages (from pip-tools->bentoml->-r requirements.txt (line 3)) (0.37.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from requests->bentoml->-r requirements.txt (line 3)) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from requests->bentoml->-r requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from requests->bentoml->-r requirements.txt (line 3)) (2021.10.8)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from rich->bentoml->-r requirements.txt (line 3)) (2.10.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from rich->bentoml->-r requirements.txt (line 3)) (0.9.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from rich->bentoml->-r requirements.txt (line 3)) (0.4.4)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from schema->bentoml->-r requirements.txt (line 3)) (21.6.0)\n",
      "Requirement already satisfied: anyio<4,>=3.0.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from starlette->bentoml->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: h11>=0.8 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from uvicorn->bentoml->-r requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: asgiref>=3.4.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from uvicorn->bentoml->-r requirements.txt (line 3)) (3.4.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sniffio>=1.1 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from anyio<4,>=3.0.0->starlette->bentoml->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/larme/notebooks/venv/lib/python3.7/site-packages (from pep517->pip-tools->bentoml->-r requirements.txt (line 3)) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62db15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import bentoml\n",
    "\n",
    "# reproducible setup for testing\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def _dataloader_init_fn(worker_id):\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38888f0a",
   "metadata": {},
   "source": [
    "## Training and Saving the model\n",
    "\n",
    "First we define a simple PyTorch network and some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539b5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLDS = 5\n",
    "NUM_EPOCHS = 5\n",
    "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_dataset():\n",
    "    # Prepare MNIST dataset by concatenating Train/Test part; we split later.\n",
    "    train_set = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor(), train=True)\n",
    "    test_set = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor(), train=False)\n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "class SimpleConvNet(nn.Module):\n",
    "    '''\n",
    "    Simple Convolutional Neural Network\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(26 * 26 * 10, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def predict(self, inp):\n",
    "        \"\"\"predict digit for input\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            raw_output = self(inp)\n",
    "            _, pred = torch.max(raw_output, 1)\n",
    "            return pred\n",
    "\n",
    "def train_epoch(model, optimizer, loss_function, train_loader, epoch, device=\"cpu\"):\n",
    "    # Mark training flag\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 499 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(inputs), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, device=\"cpu\"):\n",
    "    correct, total = 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    return correct, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2db4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larme/notebooks/venv/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_set, test_set = get_dataset()\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=10,\n",
    "    sampler=torch.utils.data.RandomSampler(test_set),\n",
    "    worker_init_fn=_dataloader_init_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c19a0",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "We can do some cross validation and the results can be saved with the model as metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2fdd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(dataset, epochs=NUM_EPOCHS, k_folds=K_FOLDS):\n",
    "    results = {}\n",
    "\n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "    \n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            dataset, \n",
    "            batch_size=10,\n",
    "            sampler=train_subsampler,\n",
    "            worker_init_fn=_dataloader_init_fn,\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=10,\n",
    "            sampler=test_subsampler,\n",
    "            worker_init_fn=_dataloader_init_fn,\n",
    "        )\n",
    "\n",
    "        # Train this fold\n",
    "        model = SimpleConvNet()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        for epoch in range(epochs):\n",
    "            train_epoch(model, optimizer, loss_function, train_loader, epoch)\n",
    "\n",
    "        # Evaluation for this fold\n",
    "        correct, total = test_model(model, test_loader)\n",
    "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "        print('--------------------------------')\n",
    "        results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {K_FOLDS} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "\n",
    "    print(f'Average: {sum/len(results.items())} %')\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd06de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.273126\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 1.362214\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.411741\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 1.001374\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.102851\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.511350\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.054312\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.229270\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.369209\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.130033\n",
      "Accuracy for fold 0: 91 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.327491\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 1.318107\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.485992\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 1.216311\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.419983\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.758953\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.147877\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.171751\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.317925\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.670031\n",
      "Accuracy for fold 1: 91 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.218862\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 1.440863\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.390614\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 0.372517\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.524596\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.206334\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.041542\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.221804\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.570448\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.220443\n",
      "Accuracy for fold 2: 90 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.316931\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 0.965537\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.240633\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 0.375479\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.150217\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.608827\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.035714\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.419792\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.178607\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.158449\n",
      "Accuracy for fold 3: 92 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.352834\n",
      "Train Epoch: 0 [4990/60000 (10%)]\tLoss: 0.953529\n",
      "Train Epoch: 0 [9980/60000 (21%)]\tLoss: 0.918020\n",
      "Train Epoch: 0 [14970/60000 (31%)]\tLoss: 0.850265\n",
      "Train Epoch: 0 [19960/60000 (42%)]\tLoss: 0.246312\n",
      "Train Epoch: 0 [24950/60000 (52%)]\tLoss: 0.234261\n",
      "Train Epoch: 0 [29940/60000 (62%)]\tLoss: 0.446011\n",
      "Train Epoch: 0 [34930/60000 (73%)]\tLoss: 0.225173\n",
      "Train Epoch: 0 [39920/60000 (83%)]\tLoss: 0.253967\n",
      "Train Epoch: 0 [44910/60000 (94%)]\tLoss: 0.179806\n",
      "Accuracy for fold 4: 90 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 91.11666666666667 %\n",
      "Fold 1: 91.30833333333334 %\n",
      "Fold 2: 90.83333333333333 %\n",
      "Fold 3: 92.05833333333334 %\n",
      "Fold 4: 90.85 %\n",
      "Average: 91.23333333333332 %\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(train_set, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2104a6",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d311c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs=NUM_EPOCHS, device=\"cpu\"):\n",
    "\n",
    "    train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=10,\n",
    "        sampler=train_sampler,\n",
    "        worker_init_fn=_dataloader_init_fn,\n",
    "    )\n",
    "    model = SimpleConvNet()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_epoch(model, optimizer, loss_function, train_loader, epoch, device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8df05c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.371420\n",
      "Train Epoch: 0 [4990/60000 (8%)]\tLoss: 1.000866\n",
      "Train Epoch: 0 [9980/60000 (17%)]\tLoss: 1.110684\n",
      "Train Epoch: 0 [14970/60000 (25%)]\tLoss: 0.737674\n",
      "Train Epoch: 0 [19960/60000 (33%)]\tLoss: 0.364441\n",
      "Train Epoch: 0 [24950/60000 (42%)]\tLoss: 0.390488\n",
      "Train Epoch: 0 [29940/60000 (50%)]\tLoss: 0.282015\n",
      "Train Epoch: 0 [34930/60000 (58%)]\tLoss: 0.199643\n",
      "Train Epoch: 0 [39920/60000 (67%)]\tLoss: 0.367593\n",
      "Train Epoch: 0 [44910/60000 (75%)]\tLoss: 0.554671\n",
      "Train Epoch: 0 [49900/60000 (83%)]\tLoss: 0.017668\n",
      "Train Epoch: 0 [54890/60000 (91%)]\tLoss: 0.086637\n",
      "Train Epoch: 0 [59880/60000 (100%)]\tLoss: 0.249381\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.222885\n",
      "Train Epoch: 1 [4990/60000 (8%)]\tLoss: 0.288009\n",
      "Train Epoch: 1 [9980/60000 (17%)]\tLoss: 0.151059\n",
      "Train Epoch: 1 [14970/60000 (25%)]\tLoss: 0.118367\n",
      "Train Epoch: 1 [19960/60000 (33%)]\tLoss: 0.757163\n",
      "Train Epoch: 1 [24950/60000 (42%)]\tLoss: 0.100752\n",
      "Train Epoch: 1 [29940/60000 (50%)]\tLoss: 0.131567\n",
      "Train Epoch: 1 [34930/60000 (58%)]\tLoss: 1.147583\n",
      "Train Epoch: 1 [39920/60000 (67%)]\tLoss: 0.029441\n",
      "Train Epoch: 1 [44910/60000 (75%)]\tLoss: 0.175337\n",
      "Train Epoch: 1 [49900/60000 (83%)]\tLoss: 0.096961\n",
      "Train Epoch: 1 [54890/60000 (91%)]\tLoss: 0.553873\n",
      "Train Epoch: 1 [59880/60000 (100%)]\tLoss: 0.014491\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.116301\n",
      "Train Epoch: 2 [4990/60000 (8%)]\tLoss: 0.009910\n",
      "Train Epoch: 2 [9980/60000 (17%)]\tLoss: 0.034026\n",
      "Train Epoch: 2 [14970/60000 (25%)]\tLoss: 0.111415\n",
      "Train Epoch: 2 [19960/60000 (33%)]\tLoss: 0.126229\n",
      "Train Epoch: 2 [24950/60000 (42%)]\tLoss: 0.103714\n",
      "Train Epoch: 2 [29940/60000 (50%)]\tLoss: 0.008615\n",
      "Train Epoch: 2 [34930/60000 (58%)]\tLoss: 0.268847\n",
      "Train Epoch: 2 [39920/60000 (67%)]\tLoss: 0.122714\n",
      "Train Epoch: 2 [44910/60000 (75%)]\tLoss: 0.114698\n",
      "Train Epoch: 2 [49900/60000 (83%)]\tLoss: 0.119902\n",
      "Train Epoch: 2 [54890/60000 (91%)]\tLoss: 0.054226\n",
      "Train Epoch: 2 [59880/60000 (100%)]\tLoss: 0.673954\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.138765\n",
      "Train Epoch: 3 [4990/60000 (8%)]\tLoss: 0.255896\n",
      "Train Epoch: 3 [9980/60000 (17%)]\tLoss: 0.064158\n",
      "Train Epoch: 3 [14970/60000 (25%)]\tLoss: 0.058995\n",
      "Train Epoch: 3 [19960/60000 (33%)]\tLoss: 0.020747\n",
      "Train Epoch: 3 [24950/60000 (42%)]\tLoss: 0.024482\n",
      "Train Epoch: 3 [29940/60000 (50%)]\tLoss: 0.115054\n",
      "Train Epoch: 3 [34930/60000 (58%)]\tLoss: 0.087848\n",
      "Train Epoch: 3 [39920/60000 (67%)]\tLoss: 0.281597\n",
      "Train Epoch: 3 [44910/60000 (75%)]\tLoss: 0.017622\n",
      "Train Epoch: 3 [49900/60000 (83%)]\tLoss: 0.096848\n",
      "Train Epoch: 3 [54890/60000 (91%)]\tLoss: 0.046338\n",
      "Train Epoch: 3 [59880/60000 (100%)]\tLoss: 0.292747\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.492516\n",
      "Train Epoch: 4 [4990/60000 (8%)]\tLoss: 0.013784\n",
      "Train Epoch: 4 [9980/60000 (17%)]\tLoss: 0.091850\n",
      "Train Epoch: 4 [14970/60000 (25%)]\tLoss: 0.030553\n",
      "Train Epoch: 4 [19960/60000 (33%)]\tLoss: 0.052157\n",
      "Train Epoch: 4 [24950/60000 (42%)]\tLoss: 0.485635\n",
      "Train Epoch: 4 [29940/60000 (50%)]\tLoss: 0.143971\n",
      "Train Epoch: 4 [34930/60000 (58%)]\tLoss: 0.035665\n",
      "Train Epoch: 4 [39920/60000 (67%)]\tLoss: 0.312370\n",
      "Train Epoch: 4 [44910/60000 (75%)]\tLoss: 0.286132\n",
      "Train Epoch: 4 [49900/60000 (83%)]\tLoss: 0.185151\n",
      "Train Epoch: 4 [54890/60000 (91%)]\tLoss: 0.005761\n",
      "Train Epoch: 4 [59880/60000 (100%)]\tLoss: 0.011963\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9b23c",
   "metadata": {},
   "source": [
    "### saving the model with some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe9c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, total = test_model(trained_model, test_loader)\n",
    "metadata = {\n",
    "    \"accuracy\": float(correct)/total,\n",
    "    \"cv_stats\": cv_results,\n",
    "}\n",
    "\n",
    "tag = bentoml.pytorch.save(\n",
    "    \"pytorch_mnist_demo\",\n",
    "    trained_model,\n",
    "    metadata=metadata,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf35e55",
   "metadata": {},
   "source": [
    "## Create a BentoML Service for serving the model\n",
    "\n",
    "Note: using `%%writefile` here because `bentoml.Service` instance must be created in a separate `.py` file\n",
    "\n",
    "Even though we have only one model, we can create as many api endpoints as we want. Here we create two end points `predict_ndarray` and `predict_image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3e2f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pytorch_mnist_demo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "\n",
    "import typing as t\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from PIL.Image import Image as PILImage\n",
    "\n",
    "import bentoml\n",
    "from bentoml.io import Image\n",
    "from bentoml.io import NumpyNdarray\n",
    "\n",
    "\n",
    "mnist_runner = bentoml.pytorch.load_runner(\n",
    "    \"pytorch_mnist_demo\",\n",
    "    name=\"mnist_runner\",\n",
    "    predict_fn_name=\"predict\",\n",
    ")\n",
    "\n",
    "svc = bentoml.Service(\n",
    "    name=\"pytorch_mnist_demo\",\n",
    "    runners=[\n",
    "        mnist_runner,\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "@svc.api(\n",
    "    input=NumpyNdarray(dtype=\"float32\", enforce_dtype=True),\n",
    "    output=NumpyNdarray(dtype=\"int64\"),\n",
    ")\n",
    "async def predict_ndarray(\n",
    "    inp: \"np.ndarray[t.Any, np.dtype[t.Any]]\",\n",
    ") -> \"np.ndarray[t.Any, np.dtype[t.Any]]\":\n",
    "    assert inp.shape == (28, 28)\n",
    "    # We are using greyscale image and our PyTorch model expect one\n",
    "    # extra channel dimension\n",
    "    inp = np.expand_dims(inp, 0)\n",
    "    output_tensor = await mnist_runner.async_run(inp)\n",
    "    return output_tensor.numpy()\n",
    "\n",
    "\n",
    "@svc.api(input=Image(), output=NumpyNdarray(dtype=\"int64\"))\n",
    "async def predict_image(f: PILImage) -> \"np.ndarray[t.Any, np.dtype[t.Any]]\":\n",
    "    assert isinstance(f, PILImage)\n",
    "    arr = np.array(f)/255.0\n",
    "    assert arr.shape == (28, 28)\n",
    "\n",
    "    # We are using greyscale image and our PyTorch model expect one\n",
    "    # extra channel dimension\n",
    "    arr = np.expand_dims(arr, 0).astype(\"float32\")\n",
    "    output_tensor = await mnist_runner.async_run(arr)\n",
    "    return output_tensor.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590147aa",
   "metadata": {},
   "source": [
    "Start a dev model server to test out the service defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29173871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[08:55:07 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting development BentoServer from                    \n",
      "                       \u001b[32m\"pytorch_mnist_demo.py:svc\"\u001b[0m                              \n",
      "\u001b[2;36m[08:55:07 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Service imported from source:                            \n",
      "                       \u001b[1;35mbentoml.Service\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m\"pytorch_mnist_demo\"\u001b[0m,               \n",
      "                       \u001b[33mimport_str\u001b[0m=\u001b[32m\"pytorch_mnist_demo\u001b[0m\u001b[32m:svc\"\u001b[0m,                     \n",
      "                       \u001b[33mworking_dir\u001b[0m=\u001b[32m\"/home/larme/notebooks/gallery/pytorch\"\u001b[0m\u001b[1m)\u001b[0m     \n",
      "\u001b[2;36m[08:55:07 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started server process \u001b[1m[\u001b[0m\u001b[1;36m21916\u001b[0m\u001b[1m]\u001b[0m               \u001b]8;id=863904;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/server.py\u001b\\\u001b[2mserver.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=301963;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/server.py#84\u001b\\\u001b[2m84\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m             \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Waiting for application startup.                 \u001b]8;id=147010;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/lifespan/on.py\u001b\\\u001b[2mon.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=904060;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/lifespan/on.py#45\u001b\\\u001b[2m45\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m             \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Application startup complete.                    \u001b]8;id=342315;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/lifespan/on.py\u001b\\\u001b[2mon.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=957982;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/lifespan/on.py#59\u001b\\\u001b[2m59\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m             \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Uvicorn running on \u001b[4;94mhttp://127.0.0.1:5000\u001b[0m    \u001b]8;id=949900;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/server.py\u001b\\\u001b[2mserver.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=487193;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/server.py#222\u001b\\\u001b[2m222\u001b[0m\u001b]8;;\u001b\\\n",
      "                       \u001b[1m(\u001b[0mPress CTRL+C to quit\u001b[1m)\u001b[0m                                   \n",
      "^C\n",
      "\u001b[2;36m[08:55:13 PM]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Shutting down                               \u001b]8;id=159702;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/server.py\u001b\\\u001b[2mserver.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=616624;file:///home/larme/notebooks/venv/lib/python3.7/site-packages/uvicorn/server.py#263\u001b\\\u001b[2m263\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve pytorch_mnist_demo.py:svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c1b36",
   "metadata": {},
   "source": [
    "Now you can use something like:\n",
    "\n",
    "`curl -H \"Content-Type: multipart/form-data\" -F'fileobj=@samples/1.png;type=image/png' http://127.0.0.1:5000/predict_image`\n",
    "    \n",
    "to send an image to the digit recognition service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f03564",
   "metadata": {},
   "source": [
    "## Build a Bento for distribution and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207561bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bentoml.build(\n",
    "    \"service.py:svc\",\n",
    "    include=[\"*.py\"],\n",
    "    exclude=[\"tests/\"],\n",
    "    description=\"file:./README.md\",\n",
    "    python=dict(\n",
    "        packages=[\"scikit-learn\", \"torch\", \"Pillow\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508db76e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "pytorch_mnist.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
