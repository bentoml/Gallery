{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BentoML Example: Fast AI with Tabular data\n",
    "\n",
    "**BentoML makes moving trained ML models to production easy:**\n",
    "\n",
    "* Package models trained with **any ML framework** and reproduce them for model serving in production\n",
    "* **Deploy anywhere** for online API serving or offline batch serving\n",
    "* High-Performance API model server with *adaptive micro-batching* support\n",
    "* Central hub for managing models and deployment process via Web UI and APIs\n",
    "* Modular and flexible design making it *adaptable to your infrastrcuture*\n",
    "\n",
    "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
    "Before reading this example project, be sure to check out the [Getting started guide](https://github.com/bentoml/BentoML/blob/master/guides/quick-start/bentoml-quick-start-guide.ipynb) to learn about the basic concepts in BentoML.\n",
    "\n",
    "\n",
    "This notebook is based on fastai v1's cours v3 lesson 4.  It will train a model that predict salary range base on the data we provided.\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=fast-ai&ea=fast-ai-salary-range-prediction&dt=fast-ai-salary-range-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/usr/local/anaconda3/envs/dev-py3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U 'fastai<=1.0.61'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'salary'\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TabularList.from_df(df.iloc[800:1000].copy(), path=path, cat_names=cat_names, cont_names=cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
    "                           .split_by_idx(list(range(800,1000)))\n",
    "                           .label_from_df(cols=dep_var)\n",
    "                           .add_test(test)\n",
    "                           .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.3624</td>\n",
       "      <td>-1.3855</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.4357</td>\n",
       "      <td>1.0365</td>\n",
       "      <td>-0.0312</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4491</td>\n",
       "      <td>-0.3046</td>\n",
       "      <td>1.1422</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Local-gov</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1896</td>\n",
       "      <td>-0.0845</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.7760</td>\n",
       "      <td>-1.3352</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.8493</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8365</td>\n",
       "      <td>-0.4172</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.2891</td>\n",
       "      <td>-1.3147</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6166</td>\n",
       "      <td>0.7047</td>\n",
       "      <td>-0.0312</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>9th</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.4095</td>\n",
       "      <td>-0.3273</td>\n",
       "      <td>-1.9869</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch(rows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(data, layers=[200,100], metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.371307</td>\n",
       "      <td>0.374452</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category tensor(1), tensor(1), tensor([0.4633, 0.5367]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df.iloc[0] # sample input date for testing\n",
    "\n",
    "learn.predict(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BentoService for model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tabular_csv.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tabular_csv.py\n",
    "\n",
    "from bentoml import env, api, artifacts, BentoService\n",
    "from bentoml.frameworks.fastai import Fastai1ModelArtifact\n",
    "from bentoml.adapters import DataframeInput\n",
    "\n",
    "\n",
    "@env(pip_packages=['fastai'])\n",
    "@artifacts([Fastai1ModelArtifact('model')])\n",
    "class FastaiTabularModel(BentoService):\n",
    "    \n",
    "    @api(input=DataframeInput(), batch=True)\n",
    "    def predict(self, df):\n",
    "        results = []\n",
    "        for _, row in df.iterrows():       \n",
    "            prediction = self.artifacts.model.predict(row)\n",
    "            results.append(prediction[0].obj)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save BentoService to file archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-10-01 14:45:17,839] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-10-01 14:45:18,011] INFO - Using default docker base image: `None` specified inBentoML config file or env var. User must make sure that the docker base image either has Python 3.7 or conda installed.\n",
      "[2020-10-01 14:45:18,013] WARNING - BentoML by default does not include spacy and torchvision package when using FastaiModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2020-10-01 14:45:18,015] WARNING - Overwriting existing pip package requirement 'fastai==1.0.61' to 'fastai<2.0.0'\n",
      "[2020-10-01 14:45:18,517] INFO - Detected non-PyPI-released BentoML installed, copying local BentoML modulefiles to target saved bundle path..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "no previously-included directories found matching 'e2e_tests'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'benchmark'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATING BentoML-0.9.1+1.g0655cf16.dirty/bentoml/_version.py\n",
      "set BentoML-0.9.1+1.g0655cf16.dirty/bentoml/_version.py to '0.9.1+1.g0655cf16.dirty'\n",
      "[2020-10-01 14:45:22,277] INFO - BentoService bundle 'FastaiTabularModel:20201001144518_0C60FD' saved to: /Users/bozhaoyu/bentoml/repository/FastaiTabularModel/20201001144518_0C60FD\n"
     ]
    }
   ],
   "source": [
    "# 1) import the custom BentoService defined above\n",
    "from tabular_csv import FastaiTabularModel\n",
    "\n",
    "# 2) `pack` it with required artifacts\n",
    "svc = FastaiTabularModel()\n",
    "svc.pack('model', learn)\n",
    "\n",
    "# 3) save your BentoSerivce\n",
    "saved_path = svc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST API Model Serving\n",
    "\n",
    "\n",
    "To start a REST API model server with the BentoService saved above, use the bentoml serve command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-22 16:56:10,329] INFO - Getting latest version FastaiTabularModel:20200922163833_30289D\n",
      "[2020-09-22 16:56:10,330] INFO - Starting BentoML API server in development mode..\n",
      "[2020-09-22 16:56:10,622] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-09-22 16:56:10,640] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
      "[2020-09-22 16:56:11,014] INFO - Using default docker base image: `None` specified inBentoML config file or env var. User must make sure that the docker base image either has Python 3.7 or conda installed.\n",
      "[2020-09-22 16:56:13,998] WARNING - BentoML by default does not include spacy and torchvision package when using FastaiModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2020-09-22 16:56:14,000] WARNING - pip package requirement fastai already exist\n",
      " * Serving Flask app \"FastaiTabularModel\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "[2020-09-22 16:56:23,936] INFO - {'service_name': 'FastaiTabularModel', 'service_version': '20200922163833_30289D', 'api': 'predict', 'task': {'data': {}, 'task_id': 'd93bf027-f1db-4eef-bff9-c60e96d394ba', 'batch': 1, 'http_headers': (('Host', 'localhost:5000'), ('User-Agent', 'curl/7.65.3'), ('Accept', '*/*'), ('Content-Type', 'application/json'), ('Content-Length', '370'))}, 'result': {'data': '[\"<50k\"]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': 'd93bf027-f1db-4eef-bff9-c60e96d394ba'}\n",
      "127.0.0.1 - - [22/Sep/2020 16:56:23] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0922 16:56:23.937808 4711075264 _internal.py:122] 127.0.0.1 - - [22/Sep/2020 16:56:23] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve FastaiTabularModel:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running this notebook from Google Colab, you can start the dev server with `--run-with-ngrok` option, to gain acccess to the API endpoint via a public endpoint managed by [ngrok](https://ngrok.com/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve FastaiTabularModel:latest --run-with-ngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send prediction requeset to the REST API server\n",
    "\n",
    "#### JSON Request\n",
    "\n",
    "```bash\n",
    "curl -X POST \\\n",
    "  http://localhost:5000/predict \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '[{\n",
    "  \"age\": 49,\n",
    "  \"workclass\": \"Private\",\n",
    "  \"fnlwgt\": 101320,\n",
    "  \"education\": \"Assoc-acdm\",\n",
    "  \"education-num\": 12.0,\n",
    "  \"marital-status\": \"Married-civ-spouse\",\n",
    "  \"occupation\": \"\",\n",
    "  \"relationship\": \"Wift\",\n",
    "  \"race\": \"White\",\n",
    "  \"sex\": \"Female\",\n",
    "  \"capital-gain\": 0,\n",
    "  \"capital-loss\": 1902,\n",
    "  \"hours-per-week\": 40,\n",
    "  \"native-country\": \"United-States\",\n",
    "  \"salary\": \">=50k\"\n",
    "}]'\n",
    "```\n",
    "\n",
    "#### CSV Request\n",
    "\n",
    "```bash\n",
    "curl -X POST \"http://127.0.0.1:5000/predict\" \\\n",
    "    -H \"Content-Type: text/csv\" \\\n",
    "    --data-binary @test.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containerize model server with Docker\n",
    "\n",
    "\n",
    "One common way of distributing this model API server for production deployment, is via Docker containers. And BentoML provides a convenient way to do that.\n",
    "\n",
    "Note that docker is **not available in Google Colab**. You will need to download and run this notebook locally to try out this containerization with docker feature.\n",
    "\n",
    "If you already have docker configured, simply run the follow command to product a docker container serving the IrisClassifier prediction service created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-22 16:56:43,434] INFO - Getting latest version FastaiTabularModel:20200922163833_30289D\n",
      "\u001b[39mFound Bento: /Users/bozhaoyu/bentoml/repository/FastaiTabularModel/20200922163833_30289D\u001b[0m\n",
      "[2020-09-22 16:56:43,475] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-09-22 16:56:43,496] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
      "\u001b[39mTag not specified, using tag parsed from BentoService: 'fastaitabularmodel:20200922163833_30289D'\u001b[0m\n",
      "Building Docker image fastaitabularmodel:20200922163833_30289D from FastaiTabularModel:latest \n",
      "-we in here\n",
      "processed docker file\n",
      "(None, None)\n",
      "root in create archive /Users/bozhaoyu/bentoml/repository/FastaiTabularModel/20200922163833_30289D ['Dockerfile', 'FastaiTabularModel', 'FastaiTabularModel/__init__.py', 'FastaiTabularModel/__pycache__', 'FastaiTabularModel/__pycache__/tabular_csv.cpython-37.pyc', 'FastaiTabularModel/artifacts', 'FastaiTabularModel/artifacts/__init__.py', 'FastaiTabularModel/artifacts/model.pkl', 'FastaiTabularModel/bentoml.yml', 'FastaiTabularModel/tabular_csv.py', 'MANIFEST.in', 'README.md', 'bentoml-init.sh', 'bentoml.yml', 'bundled_pip_dependencies', 'bundled_pip_dependencies/BentoML-0.9.0rc0+3.gcebf2015.tar.gz', 'docker-entrypoint.sh', 'environment.yml', 'python_version', 'requirements.txt', 'setup.py']\n",
      "about to build\n",
      "about to upgrade params\n",
      "check each param and update\n",
      "if use config proxy\n",
      "if buildargs\n",
      "if shmsize\n",
      "if labels\n",
      "if cache from\n",
      "if target\n",
      "if network_mode\n",
      "if squash\n",
      "if extra hosts is not None\n",
      "if platform is not None\n",
      "if isolcation is not None\n",
      "if context is not None\n",
      "setting auth {'Content-Type': 'application/tar'}\n",
      "\b-docker build <tempfile._TemporaryFileWrapper object at 0x7fc514d73cf8> {'t': 'fastaitabularmodel:20200922163833_30289D', 'remote': None, 'q': False, 'nocache': False, 'rm': False, 'forcerm': False, 'pull': False, 'dockerfile': (None, None)}\n",
      "\b/docker response <Response [200]>\n",
      "context closes\n",
      "print responses\n",
      "\u001b[39mStep 1/15 : FROM bentoml/model-server:0.9.0.pre\u001b[0m\n",
      "\u001b[39m ---> a25066aa8b0e\u001b[0m\n",
      "\u001b[39mStep 2/15 : ARG EXTRA_PIP_INSTALL_ARGS=\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> fc6e47d06522\u001b[0m\n",
      "\u001b[39mStep 3/15 : ENV EXTRA_PIP_INSTALL_ARGS $EXTRA_PIP_INSTALL_ARGS\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> db8172e98571\u001b[0m\n",
      "\u001b[39mStep 4/15 : COPY environment.yml requirements.txt setup.sh* bentoml-init.sh python_version* /bento/\u001b[0m\n",
      "\b|\u001b[39m ---> 55a0a6097230\u001b[0m\n",
      "\u001b[39mStep 5/15 : WORKDIR /bento\u001b[0m\n",
      "\b\\\u001b[39m ---> Running in 608a0ecc0656\u001b[0m\n",
      "\b-\u001b[39m ---> 7671d9cbcbe2\u001b[0m\n",
      "\u001b[39mStep 6/15 : RUN chmod +x /bento/bentoml-init.sh\u001b[0m\n",
      "\u001b[39m ---> Running in 51de07768042\u001b[0m\n",
      "\b|\u001b[39m ---> d76239495190\u001b[0m\n",
      "\u001b[39mStep 7/15 : RUN if [ -f /bento/bentoml-init.sh ]; then bash -c /bento/bentoml-init.sh; fi\u001b[0m\n",
      "\u001b[39m ---> Running in be68f5f82c22\u001b[0m\n",
      "\b/\u001b[39m\u001b[91m+++ dirname /bento/bentoml-init.sh\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[39m\u001b[91m++ cd /bento\n",
      "++ pwd -P\n",
      "+ SAVED_BUNDLE_PATH=/bento\n",
      "+ cd /bento\n",
      "+ '[' -f ./setup.sh ']'\n",
      "+ '[' -f ./python_version ']'\n",
      "++ cat ./python_version\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[39m\u001b[91m+ PY_VERSION_SAVED=3.7.3\n",
      "+ DESIRED_PY_VERSION=3.7\n",
      "++ python -c 'import sys; print(f\"{sys.version_info.major}.{sys.version_info.minor}\")'\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[39m\u001b[91m+ CURRENT_PY_VERSION=3.7\n",
      "+ [[ 3.7 == \\3\\.\\7 ]]\n",
      "+ echo 'Python Version in docker base image 3.7 matches requirement python=3.7. Skipping.'\n",
      "+ command -v conda\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[39m\u001b[91m+ echo 'Updating conda base environment with environment.yml'\n",
      "+ conda env update -n base -f ./environment.yml\n",
      "\u001b[0m\u001b[0m\n",
      "\u001b[39mPython Version in docker base image 3.7 matches requirement python=3.7. Skipping.\u001b[0m\n",
      "\u001b[39mUpdating conda base environment with environment.yml\u001b[0m\n",
      "\b|\u001b[39mCollecting package metadata (repodata.json): ...working... \u001b[0m\n",
      "\b|\u001b[39mdone\n",
      "Solving environment: ...working... \u001b[0m\n",
      "\b\\\u001b[39mdone\u001b[0m\n",
      "\b-\u001b[39m\n",
      "Downloading and Extracting Packages\n",
      "openssl-1.1.1h       | 2.1 MB    |            |   0% \u001b[0m\n",
      "openssl-1.1.1h       | 2.1 MB    |            |   1% \u001b[0m\n",
      "openssl-1.1.1h       | 2.1 MB    | ###2       |  32% \u001b[0m\n",
      "openssl-1.1.1h       | 2.1 MB    | ########7  |  88% \u001b[0m\n",
      "openssl-1.1.1h       | 2.1 MB    | ########## | 100% \u001b[0m\n",
      "\u001b[39m\n",
      "pip-20.2.3           | 1.1 MB    |            |   0% \u001b[0m\n",
      "pip-20.2.3           | 1.1 MB    | #####2     |  53% \u001b[0m\n",
      "pip-20.2.3           | 1.1 MB    | ########## | 100% \u001b[0m\n",
      "pip-20.2.3           | 1.1 MB    | ########## | 100% \u001b[0m\n",
      "\u001b[39m\n",
      "certifi-2020.6.20    | 151 KB    |            |   0% \u001b[0m\n",
      "certifi-2020.6.20    | 151 KB    | ########## | 100% \u001b[0m\n",
      "\u001b[39m\n",
      "cffi-1.14.3          | 223 KB    |            |   0% \u001b[0m\n",
      "cffi-1.14.3          | 223 KB    | ########## | 100% \u001b[0m\n",
      "cffi-1.14.3          | 223 KB    | ########## | 100% \u001b[0m\n",
      "\u001b[39m\n",
      "ca-certificates-2020 | 145 KB    |            |   0% \u001b[0m\n",
      "ca-certificates-2020 | 145 KB    | ########## | 100% \u001b[0m\n",
      "\u001b[39m\n",
      "python_abi-3.7       | 4 KB      |            |   0% \u001b[0m\n",
      "python_abi-3.7       | 4 KB      | ########## | 100% \u001b[0m\n",
      "\u001b[39m\n",
      "libffi-3.2.1         | 47 KB     |            |   0% \u001b[0m\n",
      "libffi-3.2.1         | 47 KB     | ########## | 100% \u001b[0m\n",
      "\u001b[39m\n",
      "Preparing transaction: \u001b[0m\n",
      "\u001b[39m...working... \u001b[0m\n",
      "\b-\u001b[39mdone\u001b[0m\n",
      "\u001b[39mVerifying transaction: ...working... \u001b[0m\n",
      "\b/\u001b[39mdone\u001b[0m\n",
      "\u001b[39mExecuting transaction: \u001b[0m\n",
      "\u001b[39m...working... \u001b[0m\n",
      "\b\\\u001b[39mdone\u001b[0m\n",
      "\b-\u001b[39m#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate base\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\u001b[0m\n",
      "\b-\u001b[39m\u001b[91m+ pip install -r ./requirements.txt --no-cache-dir\n",
      "\u001b[0m\u001b[0m\n",
      "\b-\u001b[39mRequirement already satisfied: bentoml==0.9.0.pre in /opt/conda/lib/python3.7/site-packages (from -r ./requirements.txt (line 1)) (0.9.0rc0)\u001b[0m\n",
      "\b/\u001b[39mCollecting fastai==1.0.61\u001b[0m\n",
      "\b|\u001b[39m  Downloading fastai-1.0.61-py3-none-any.whl (239 kB)\u001b[0m\n",
      "\b\\\u001b[39mCollecting pandas==0.24.2\u001b[0m\n",
      "\u001b[39m  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\u001b[0m\n",
      "\b\\\u001b[39mCollecting torch==1.6.0\u001b[0m\n",
      "\b-\u001b[39m  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\u001b[0m\n",
      "\b-\u001b[39mRequirement already satisfied: humanfriendly in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (8.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: alembic in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.4.3)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.8.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (7.1.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: flask in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.1.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: cerberus in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.3.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: gunicorn in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (20.0.4)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2020.6.20)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: docker in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (4.3.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: configparser in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (5.0.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: sqlalchemy-utils<0.36.8 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.36.7)\u001b[0m\n",
      "\b/\u001b[39mRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.13.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.19.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (20.4)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.6.2)\u001b[0m\n",
      "\b|\u001b[39mRequirement already satisfied: py-zipkin in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.20.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.3.19)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: ruamel.yaml>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.15.87)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (5.7.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: python-json-logger in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.1.11)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: multidict in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (4.7.6)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: grpcio<=1.27.2 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.27.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.15.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.24.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.8.7)\u001b[0m\n",
      "\b/\u001b[39mCollecting scipy\u001b[0m\n",
      "\b|\u001b[39m  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\u001b[0m\n",
      "\b/\u001b[39mCollecting beautifulsoup4\u001b[0m\n",
      "\u001b[39m  Downloading beautifulsoup4-4.9.1-py3-none-any.whl (115 kB)\u001b[0m\n",
      "\b|\u001b[39mCollecting nvidia-ml-py3\u001b[0m\n",
      "\u001b[39m  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\u001b[0m\n",
      "\b|\u001b[39mCollecting pyyaml\u001b[0m\n",
      "\b\\\u001b[39m  Downloading PyYAML-5.3.1.tar.gz (269 kB)\u001b[0m\n",
      "\b|\u001b[39mCollecting matplotlib\u001b[0m\n",
      "\u001b[39m  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\u001b[0m\n",
      "\b\\\u001b[39mCollecting Pillow\u001b[0m\n",
      "\b-\u001b[39m  Downloading Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\u001b[0m\n",
      "\b|\u001b[39mCollecting torchvision\u001b[0m\n",
      "\u001b[39m  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\u001b[0m\n",
      "\b\\\u001b[39mCollecting fastprogress>=0.2.1\u001b[0m\n",
      "\u001b[39m  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\b/\u001b[39mCollecting spacy>=2.0.18; python_version < \"3.8\"\u001b[0m\n",
      "\b|\u001b[39m  Downloading spacy-2.3.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\u001b[0m\n",
      "\b/\u001b[39mCollecting bottleneck\u001b[0m\n",
      "\b|\u001b[39m  Downloading Bottleneck-1.3.2.tar.gz (88 kB)\u001b[0m\n",
      "\u001b[39m  Installing build dependencies: started\u001b[0m\n",
      "\b\\\u001b[39m  Installing build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[39m  Getting requirements to build wheel: started\u001b[0m\n",
      "\b/\u001b[39m  Getting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\b|\u001b[39m    Preparing wheel metadata: started\u001b[0m\n",
      "\b/\u001b[39m    Preparing wheel metadata: finished with status 'done'\u001b[0m\n",
      "\b\\\u001b[39mCollecting numexpr\u001b[0m\n",
      "\u001b[39m  Downloading numexpr-2.7.1-cp37-cp37m-manylinux1_x86_64.whl (162 kB)\u001b[0m\n",
      "\b/\u001b[39mCollecting pytz>=2011k\u001b[0m\n",
      "\u001b[39m  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\u001b[0m\n",
      "\b\\\u001b[39mCollecting future\u001b[0m\n",
      "\u001b[39m  Downloading future-0.18.2.tar.gz (829 kB)\u001b[0m\n",
      "\b-\u001b[39mRequirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.1.3)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.0.4)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from flask->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from flask->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from flask->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.11.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from cerberus->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (49.6.0.post20200814)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from docker->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.57.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.0.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (20.2.0)\u001b[0m\n",
      "\b/\u001b[39mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.5.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: chardet<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: thriftpy2>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from py-zipkin->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.4.11)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.3.3)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: botocore<1.19.0,>=1.18.2 in /opt/conda/lib/python3.7/site-packages (from boto3->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.18.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.25.10)\u001b[0m\n",
      "\b|\u001b[39mCollecting soupsieve>1.2\u001b[0m\n",
      "\u001b[39m  Downloading soupsieve-2.0.1-py3-none-any.whl (32 kB)\u001b[0m\n",
      "\b\\\u001b[39mCollecting kiwisolver>=1.0.1\u001b[0m\n",
      "\u001b[39m  Downloading kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\u001b[0m\n",
      "\b-\u001b[39mCollecting cycler>=0.10\u001b[0m\n",
      "\u001b[39m  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\b|\u001b[39mCollecting preshed<3.1.0,>=3.0.2\u001b[0m\n",
      "\u001b[39m  Downloading preshed-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (118 kB)\u001b[0m\n",
      "\b\\\u001b[39mCollecting blis<0.5.0,>=0.4.0\u001b[0m\n",
      "\u001b[39m  Downloading blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\u001b[0m\n",
      "\b/\u001b[39mCollecting thinc==7.4.1\u001b[0m\n",
      "\u001b[39m  Downloading thinc-7.4.1-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\u001b[0m\n",
      "\b\\\u001b[39mCollecting catalogue<1.1.0,>=0.0.7\u001b[0m\n",
      "\b-\u001b[39m  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai==1.0.61->-r ./requirements.txt (line 2)) (4.48.2)\u001b[0m\n",
      "\u001b[39mCollecting plac<1.2.0,>=0.9.6\u001b[0m\n",
      "\b/\u001b[39m  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\b|\u001b[39mCollecting srsly<1.1.0,>=1.0.2\u001b[0m\n",
      "\u001b[39m  Downloading srsly-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (185 kB)\u001b[0m\n",
      "\b-\u001b[39mCollecting cymem<2.1.0,>=2.0.2\u001b[0m\n",
      "\u001b[39m  Downloading cymem-2.0.3-cp37-cp37m-manylinux1_x86_64.whl (32 kB)\u001b[0m\n",
      "\b/\u001b[39mCollecting wasabi<1.1.0,>=0.4.0\u001b[0m\n",
      "\u001b[39m  Downloading wasabi-0.8.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\b\\\u001b[39mCollecting murmurhash<1.1.0,>=0.28.0\u001b[0m\n",
      "\u001b[39m  Downloading murmurhash-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (19 kB)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from Mako->alembic->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (1.1.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.7.4.3)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied: ply<4.0,>=3.4 in /opt/conda/lib/python3.7/site-packages (from thriftpy2>=0.4.0->py-zipkin->bentoml==0.9.0.pre->-r ./requirements.txt (line 1)) (3.11)\u001b[0m\n",
      "\b-\u001b[39mCollecting importlib-metadata>=0.20; python_version < \"3.8\"\u001b[0m\n",
      "\u001b[39m  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\u001b[0m\n",
      "\b/\u001b[39mCollecting zipp>=0.5\u001b[0m\n",
      "\u001b[39m  Downloading zipp-3.2.0-py3-none-any.whl (5.1 kB)\u001b[0m\n",
      "\b|\u001b[39mBuilding wheels for collected packages: nvidia-ml-py3, pyyaml, bottleneck, future\u001b[0m\n",
      "\u001b[39m  Building wheel for nvidia-ml-py3 (setup.py): started\u001b[0m\n",
      "\b/\u001b[39m  Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[39m  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19191 sha256=9133f42be2d5c905262136fe2f11fafeee49d48405dfeccf433b1a1f6880596c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3pc2f4g3/wheels/df/99/da/c34f202dc8fd1dffd35e0ecf1a7d7f8374ca05fbcbaf974b83\u001b[0m\n",
      "\u001b[39m  Building wheel for pyyaml (setup.py): started\u001b[0m\n",
      "\b\\\u001b[39m  Building wheel for pyyaml (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[39m  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44619 sha256=06b029825047443a06a6d902a0a8aea3043fcda80e5b64aee2d9a3885fdb1686\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3pc2f4g3/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\u001b[0m\n",
      "\u001b[39m  Building wheel for bottleneck (PEP 517): started\u001b[0m\n",
      "\b\\\u001b[39m  Building wheel for bottleneck (PEP 517): finished with status 'done'\u001b[0m\n",
      "\u001b[39m  Created wheel for bottleneck: filename=Bottleneck-1.3.2-cp37-cp37m-linux_x86_64.whl size=386286 sha256=ff257a0246aa8e3b327ff8d4bce3f82cbe0fa07b81cd4447c680962e28c27f22\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3pc2f4g3/wheels/87/85/9c/a325c89ff0498660ef8a335fb4b3912939c273ea4f094af29f\u001b[0m\n",
      "\u001b[39m  Building wheel for future (setup.py): started\u001b[0m\n",
      "\b/\u001b[39m  Building wheel for future (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[39m  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=d614ba77d286ffaa4b10e65903c7aa37d69cc5a21e84864cd70caffd39ef17f8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3pc2f4g3/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\u001b[0m\n",
      "\u001b[39mSuccessfully built nvidia-ml-py3 pyyaml bottleneck future\u001b[0m\n",
      "\b-\u001b[39mInstalling collected packages: scipy, soupsieve, beautifulsoup4, nvidia-ml-py3, pyyaml, Pillow, kiwisolver, cycler, matplotlib, future, torch, torchvision, pytz, pandas, fastprogress, cymem, murmurhash, preshed, blis, plac, wasabi, zipp, importlib-metadata, catalogue, srsly, thinc, spacy, bottleneck, numexpr, fastai\u001b[0m\n",
      "\b\\\u001b[39mSuccessfully installed Pillow-7.2.0 beautifulsoup4-4.9.1 blis-0.4.1 bottleneck-1.3.2 catalogue-1.0.0 cycler-0.10.0 cymem-2.0.3 fastai-1.0.61 fastprogress-1.0.0 future-0.18.2 importlib-metadata-2.0.0 kiwisolver-1.2.0 matplotlib-3.3.2 murmurhash-1.0.2 numexpr-2.7.1 nvidia-ml-py3-7.352.0 pandas-0.24.2 plac-1.1.3 preshed-3.0.2 pytz-2020.1 pyyaml-5.3.1 scipy-1.5.2 soupsieve-2.0.1 spacy-2.3.2 srsly-1.0.2 thinc-7.4.1 torch-1.6.0 torchvision-0.7.0 wasabi-0.8.0 zipp-3.2.0\u001b[0m\n",
      "\b\\\u001b[39m ---> d72434920c0a\u001b[0m\n",
      "\u001b[39mStep 8/15 : COPY . /bento\u001b[0m\n",
      "\b|\u001b[39m ---> 296bc01ddba4\u001b[0m\n",
      "\u001b[39mStep 9/15 : RUN if [ -d /bento/bundled_pip_dependencies ]; then pip install -U bundled_pip_dependencies/* ;fi\u001b[0m\n",
      "\b\\\u001b[39m ---> Running in 63a0655d30a7\u001b[0m\n",
      "\b|\u001b[39mProcessing ./bundled_pip_dependencies/BentoML-0.9.0rc0+3.gcebf2015.tar.gz\u001b[0m\n",
      "\b|\u001b[39m  Installing build dependencies: started\u001b[0m\n",
      "\b/\u001b[39m  Installing build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[39m  Getting requirements to build wheel: started\u001b[0m\n",
      "\b|\u001b[39m  Getting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[39m    Preparing wheel metadata: started\u001b[0m\n",
      "\b-\u001b[39m    Preparing wheel metadata: finished with status 'done'\u001b[0m\n",
      "\b|\u001b[39mRequirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (3.13.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: alembic in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.4.3)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: humanfriendly in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (8.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: prometheus-client in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.8.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (7.1.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: cerberus in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.3.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (2.24.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (2.8.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: flask in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.1.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.19.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: psutil in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (5.7.2)\u001b[0m\n",
      "\b\\\u001b[39mRequirement already satisfied, skipping upgrade: multidict in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (4.7.6)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: py-zipkin in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.20.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: tabulate in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.8.7)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: grpcio<=1.27.2 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.27.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: docker in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (4.3.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.3.19)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: boto3 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (1.15.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: gunicorn in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (20.0.4)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: certifi in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (2020.6.20)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (20.4)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: ruamel.yaml>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.15.87)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: python-json-logger in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.1.11)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: aiohttp in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (3.6.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: sqlalchemy-utils<0.36.8 in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (0.36.7)\u001b[0m\n",
      "\b-\u001b[39mRequirement already satisfied, skipping upgrade: configparser in /opt/conda/lib/python3.7/site-packages (from BentoML==0.9.0rc0+3.gcebf2015) (5.0.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->BentoML==0.9.0rc0+3.gcebf2015) (49.6.0.post20200814)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.0->BentoML==0.9.0rc0+3.gcebf2015) (1.15.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic->BentoML==0.9.0rc0+3.gcebf2015) (1.0.4)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->BentoML==0.9.0rc0+3.gcebf2015) (1.1.3)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.9.0rc0+3.gcebf2015) (1.25.10)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.9.0rc0+3.gcebf2015) (3.0.4)\u001b[0m\n",
      "\b/\u001b[39mRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->BentoML==0.9.0rc0+3.gcebf2015) (2.10)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from flask->BentoML==0.9.0rc0+3.gcebf2015) (1.1.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from flask->BentoML==0.9.0rc0+3.gcebf2015) (2.11.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from flask->BentoML==0.9.0rc0+3.gcebf2015) (1.0.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: thriftpy2>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from py-zipkin->BentoML==0.9.0rc0+3.gcebf2015) (0.4.11)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker->BentoML==0.9.0rc0+3.gcebf2015) (0.57.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->BentoML==0.9.0rc0+3.gcebf2015) (0.3.3)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: botocore<1.19.0,>=1.18.2 in /opt/conda/lib/python3.7/site-packages (from boto3->BentoML==0.9.0rc0+3.gcebf2015) (1.18.2)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->BentoML==0.9.0rc0+3.gcebf2015) (0.10.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->BentoML==0.9.0rc0+3.gcebf2015) (2.4.7)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->BentoML==0.9.0rc0+3.gcebf2015) (20.2.0)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->BentoML==0.9.0rc0+3.gcebf2015) (3.0.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->BentoML==0.9.0rc0+3.gcebf2015) (1.5.1)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from Mako->alembic->BentoML==0.9.0rc0+3.gcebf2015) (1.1.1)\u001b[0m\n",
      "\b|\u001b[39mRequirement already satisfied, skipping upgrade: ply<4.0,>=3.4 in /opt/conda/lib/python3.7/site-packages (from thriftpy2>=0.4.0->py-zipkin->BentoML==0.9.0rc0+3.gcebf2015) (3.11)\u001b[0m\n",
      "\u001b[39mRequirement already satisfied, skipping upgrade: typing-extensions>=3.7.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->BentoML==0.9.0rc0+3.gcebf2015) (3.7.4.3)\u001b[0m\n",
      "\u001b[39mBuilding wheels for collected packages: BentoML\u001b[0m\n",
      "\u001b[39m  Building wheel for BentoML (PEP 517): started\u001b[0m\n",
      "\b|\u001b[39m  Building wheel for BentoML (PEP 517): finished with status 'done'\u001b[0m\n",
      "\u001b[39m  Created wheel for BentoML: filename=BentoML-0.9.0rc0+3.gcebf2015-py3-none-any.whl size=3064091 sha256=762aa6ea85795b1fa82fe6196527c7db0fe6e17da0a48a128cbc2e5b2f846d2d\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/45/41/62152db705af4ff47e7a3d6abf6247986eef4aa1b94a58d3b9\u001b[0m\n",
      "\u001b[39mSuccessfully built BentoML\u001b[0m\n",
      "\b\\\u001b[39mInstalling collected packages: BentoML\n",
      "  Attempting uninstall: BentoML\u001b[0m\n",
      "\u001b[39m    Found existing installation: BentoML 0.9.0rc0\u001b[0m\n",
      "\b/\u001b[39m    Uninstalling BentoML-0.9.0rc0:\u001b[0m\n",
      "\b\\\u001b[39m      Successfully uninstalled BentoML-0.9.0rc0\u001b[0m\n",
      "\b-\u001b[39mSuccessfully installed BentoML-0.9.0rc0+3.gcebf2015\u001b[0m\n",
      "\b\\\u001b[39m ---> e2f758c32fe8\u001b[0m\n",
      "\u001b[39mStep 10/15 : ENV PORT 5000\u001b[0m\n",
      "\u001b[39m ---> Running in bcf40c69a9b0\u001b[0m\n",
      "\b-\u001b[39m ---> 3e6f27372f5d\u001b[0m\n",
      "\u001b[39mStep 11/15 : EXPOSE $PORT\u001b[0m\n",
      "\b/\u001b[39m ---> Running in 022d6305af14\u001b[0m\n",
      "\b|\u001b[39m ---> 1466c0426ea9\u001b[0m\n",
      "\u001b[39mStep 12/15 : COPY docker-entrypoint.sh /usr/local/bin/\u001b[0m\n",
      "\b\\\u001b[39m ---> cfd5416160a9\u001b[0m\n",
      "\u001b[39mStep 13/15 : RUN chmod +x /usr/local/bin/docker-entrypoint.sh\u001b[0m\n",
      "\b-\u001b[39m ---> Running in 1696f568c09a\u001b[0m\n",
      "\b/\u001b[39m ---> ff0ad7d18c18\u001b[0m\n",
      "\u001b[39mStep 14/15 : ENTRYPOINT [ \"docker-entrypoint.sh\" ]\u001b[0m\n",
      "\b|\u001b[39m ---> Running in 649edeb9207b\u001b[0m\n",
      "\b\\\u001b[39m ---> 5aa2d29a2153\u001b[0m\n",
      "\u001b[39mStep 15/15 : CMD [\"bentoml\", \"serve-gunicorn\", \"/bento\"]\u001b[0m\n",
      "\u001b[39m ---> Running in 2863ca14b743\u001b[0m\n",
      "\b-\u001b[39m ---> 031f971273f4\u001b[0m\n",
      "\u001b[39mSuccessfully built 031f971273f4\u001b[0m\n",
      "\u001b[39mSuccessfully tagged fastaitabularmodel:20200922163833_30289D\u001b[0m\n",
      "\u001b[32mFinished building fastaitabularmodel:20200922163833_30289D from FastaiTabularModel:latest\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml containerize FastaiTabularModel:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-23 00:01:08,992] INFO - Starting BentoML API server in production mode..\n",
      "[2020-09-23 00:01:09,478] INFO - get_gunicorn_num_of_workers: 3, calculated by cpu count\n",
      "[2020-09-23 00:01:09 +0000] [1] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-09-23 00:01:09 +0000] [1] [INFO] Listening at: http://0.0.0.0:5000 (1)\n",
      "[2020-09-23 00:01:09 +0000] [1] [INFO] Using worker: sync\n",
      "[2020-09-23 00:01:09 +0000] [12] [INFO] Booting worker with pid: 12\n",
      "[2020-09-23 00:01:09 +0000] [13] [INFO] Booting worker with pid: 13\n",
      "[2020-09-23 00:01:09 +0000] [14] [INFO] Booting worker with pid: 14\n",
      "[2020-09-23 00:01:09,734] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-09-23 00:01:09,736] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-09-23 00:01:09,759] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
      "[2020-09-23 00:01:09,760] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.7.3, but current environment version is 3.7.6.\n",
      "[2020-09-23 00:01:09,761] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
      "[2020-09-23 00:01:09,762] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.7.3, but current environment version is 3.7.6.\n",
      "[2020-09-23 00:01:09,799] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-09-23 00:01:09,822] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+3.gcebf2015\n",
      "[2020-09-23 00:01:09,822] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.7.3, but current environment version is 3.7.6.\n",
      "^C\n",
      "[2020-09-23 00:01:12 +0000] [1] [INFO] Handling signal: int\n",
      "[2020-09-23 00:01:12 +0000] [14] [INFO] Worker exiting (pid: 14)\n",
      "[2020-09-23 00:01:12 +0000] [13] [INFO] Worker exiting (pid: 13)\n",
      "[2020-09-23 00:01:12 +0000] [12] [INFO] Worker exiting (pid: 12)\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 5000:5000 fastaitabularmodel:20200922163833_30289D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved BentoService\n",
    "\n",
    "bentoml.load is the API for loading a BentoML packaged model in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-10-01 14:45:29,278] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.1, but loading from BentoML version 0.9.1+1.g0655cf16.dirty\n",
      "[2020-10-01 14:45:29,279] WARNING - Module `tabular_csv` already loaded, using existing imported module.\n",
      "[2020-10-01 14:45:29,286] WARNING - pip package requirement pandas already exist\n",
      "[2020-10-01 14:45:29,287] WARNING - BentoML by default does not include spacy and torchvision package when using FastaiModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2020-10-01 14:45:29,288] WARNING - pip package requirement torch already exist\n",
      "[2020-10-01 14:45:29,290] WARNING - pip package requirement fastai<2.0.0 already exist\n",
      "['>=50k']\n"
     ]
    }
   ],
   "source": [
    "from bentoml import load\n",
    "\n",
    "svc = load(saved_path)\n",
    "print(svc.predict(df.iloc[0:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch inference job from CLI\n",
    "\n",
    "BentoML cli supports loading and running a packaged model from CLI. With the DataframeInput adapter, the CLI command supports reading input Dataframe data from CLI argument or local csv or json files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml run FastaiTabularModel:latest predict \\\n",
    "    --input-file https://raw.githubusercontent.com/bentoml/gallery/master/fast-ai/salary-range-prediction/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Options\n",
    "\n",
    "If you are at a small team with limited engineering or DevOps resources, try out automated deployment with BentoML CLI, currently supporting AWS Lambda, AWS SageMaker, and Azure Functions:\n",
    "- [AWS Lambda Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_lambda.html)\n",
    "- [AWS SageMaker Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_sagemaker.html)\n",
    "- [Azure Functions Deployment Guide](https://docs.bentoml.org/en/latest/deployment/azure_functions.html)\n",
    "\n",
    "If the cloud platform you are working with is not on the list above, try out these step-by-step guide on manually deploying BentoML packaged model to cloud platforms:\n",
    "- [AWS ECS Deployment](https://docs.bentoml.org/en/latest/deployment/aws_ecs.html)\n",
    "- [Google Cloud Run Deployment](https://docs.bentoml.org/en/latest/deployment/google_cloud_run.html)\n",
    "- [Azure container instance Deployment](https://docs.bentoml.org/en/latest/deployment/azure_container_instance.html)\n",
    "- [Heroku Deployment](https://docs.bentoml.org/en/latest/deployment/heroku.html)\n",
    "\n",
    "Lastly, if you have a DevOps or ML Engineering team who's operating a Kubernetes or OpenShift cluster, use the following guides as references for implementating your deployment strategy:\n",
    "- [Kubernetes Deployment](https://docs.bentoml.org/en/latest/deployment/kubernetes.html)\n",
    "- [Knative Deployment](https://docs.bentoml.org/en/latest/deployment/knative.html)\n",
    "- [Kubeflow Deployment](https://docs.bentoml.org/en/latest/deployment/kubeflow.html)\n",
    "- [KFServing Deployment](https://docs.bentoml.org/en/latest/deployment/kfserving.html)\n",
    "- [Clipper.ai Deployment Guide](https://docs.bentoml.org/en/latest/deployment/clipper.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
