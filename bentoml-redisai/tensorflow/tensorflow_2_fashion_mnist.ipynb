{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Basic classification: Classify images of clothing with RedisAI\n",
    "\n",
    "**BentoML makes moving trained ML models to production easy:**\n",
    "\n",
    "* Package models trained with **any ML framework** and reproduce them for model serving in production\n",
    "* **Deploy anywhere** for online API serving or offline batch serving\n",
    "* High-Performance API model server with *adaptive micro-batching* support\n",
    "* Central hub for managing models and deployment process via Web UI and APIs\n",
    "* Modular and flexible design making it *adaptable to your infrastrcuture*\n",
    "\n",
    "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
    "\n",
    "\n",
    "[RedisAI](https://oss.redislabs.com/redisai/) is a popular model server for running ML models. RedisAI both maximizes computation throughput and reduces latency by adhering to the principle of data locality , as well as simplifies the deployment and serving of graphs by leveraging on Redis' production-proven infrastructure.\n",
    "\n",
    "In this handbook, I will deploy a tensorflow models to RedisAI with BentoML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bentoml in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (0.13.1)\n",
      "Requirement already satisfied: tensorflow in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (3.4.3)\n",
      "Requirement already satisfied: numpy in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (1.19.5)\n",
      "Requirement already satisfied: pillow in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (8.3.2)\n",
      "Requirement already satisfied: certifi in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (2021.5.30)\n",
      "Requirement already satisfied: psutil in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (5.8.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.15.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (0.17.16)\n",
      "Requirement already satisfied: configparser in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (5.0.2)\n",
      "Requirement already satisfied: aiohttp-cors==0.7.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (0.7.0)\n",
      "Requirement already satisfied: flask in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (2.0.1)\n",
      "Requirement already satisfied: chardet in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (4.0.0)\n",
      "Requirement already satisfied: humanfriendly in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (10.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (3.18.0)\n",
      "Requirement already satisfied: requests in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (2.26.0)\n",
      "Requirement already satisfied: tabulate in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (0.8.9)\n",
      "Requirement already satisfied: sqlalchemy<1.4.0,>=1.3.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (1.3.24)\n",
      "Requirement already satisfied: grpcio in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (1.40.0)\n",
      "Requirement already satisfied: cerberus in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (1.3.4)\n",
      "Requirement already satisfied: simple-di in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (0.1.1)\n",
      "Requirement already satisfied: aiohttp in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (3.7.4.post0)\n",
      "Requirement already satisfied: prometheus-client in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (2.8.2)\n",
      "Requirement already satisfied: sqlalchemy-utils<0.36.8 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (0.36.5)\n",
      "Requirement already satisfied: gunicorn in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (20.1.0)\n",
      "Requirement already satisfied: schema in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (0.7.4)\n",
      "Requirement already satisfied: boto3 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (1.18.48)\n",
      "Requirement already satisfied: urllib3<=1.25.11 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (1.25.11)\n",
      "Requirement already satisfied: packaging in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (21.0)\n",
      "Requirement already satisfied: alembic in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (1.7.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (8.0.1)\n",
      "Requirement already satisfied: docker in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (5.0.2)\n",
      "Requirement already satisfied: deepmerge in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (0.3.0)\n",
      "Requirement already satisfied: python-json-logger in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from bentoml) (2.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from aiohttp->bentoml) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from aiohttp->bentoml) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from aiohttp->bentoml) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from aiohttp->bentoml) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from aiohttp->bentoml) (3.10.0.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from click>=7.0->bentoml) (4.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.7.3->bentoml) (1.16.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.1.2 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from ruamel.yaml>=0.15.0->bentoml) (0.2.6)\n",
      "Requirement already satisfied: idna>=2.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->bentoml) (3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (0.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from requests->bentoml) (2.0.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: Mako in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from alembic->bentoml) (1.1.5)\n",
      "Requirement already satisfied: importlib-resources in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from alembic->bentoml) (5.2.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from boto3->bentoml) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from boto3->bentoml) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.48 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from boto3->bentoml) (1.21.48)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from docker->bentoml) (1.2.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from flask->bentoml) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from flask->bentoml) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from Jinja2>=3.0->flask->bentoml) (2.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from importlib-metadata->click>=7.0->bentoml) (3.5.0)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/longld/anaconda3/envs/redisai/lib/python3.7/site-packages (from schema->bentoml) (21.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bentoml tensorflow matplotlib numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(_train_images, train_labels), (_test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "train_images = _train_images / 255.0\n",
    "test_images = _test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle boot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f56a5768f50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import cv2\n",
    "# pick up a test image\n",
    "d_test_img = _test_images[0]\n",
    "print(class_names[test_labels[0]])\n",
    "\n",
    "# cv2.imwrite(\"test.png\", d_test_img)\n",
    "plt.imshow(d_test_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ODch-OFCaW4"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lhan11blCaW7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-28 09:51:36.650415: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-28 09:51:36.650458: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-28 09:51:36.650485: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vts-datnt114): /proc/driver/nvidia/version does not exist\n",
      "2021-09-28 09:51:36.650756: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-09-28 09:51:36.674715: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2799925000 Hz\n",
      "2021-09-28 09:51:36.675439: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f566c000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-28 09:51:36.675484: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-09-28 09:51:36.847342: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 856us/step - loss: 0.4945 - accuracy: 0.8271\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 800us/step - loss: 0.3729 - accuracy: 0.8657\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 764us/step - loss: 0.3352 - accuracy: 0.8772\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 738us/step - loss: 0.3105 - accuracy: 0.8852\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 741us/step - loss: 0.2950 - accuracy: 0.8911\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 759us/step - loss: 0.2822 - accuracy: 0.8949\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.2656 - accuracy: 0.9019\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 746us/step - loss: 0.2562 - accuracy: 0.9041\n",
      "Epoch 9/10\n",
      " 407/1875 [=====>........................] - ETA: 1s - loss: 0.2375 - accuracy: 0.9093"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28), name=\"input\"),\n",
    "            tf.keras.layers.Dense(128, activation='relu', name=\"dense\"),\n",
    "            tf.keras.layers.Dense(10, activation='softmax',name=\"output\" )\n",
    "        ])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('test.png')\n",
    "print(np.array(img).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "predict = model.predict(img)\n",
    "klass = tf.argmax(predict, axis=1)\n",
    "[class_names[c] for c in klass]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the model predicts a label as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because RedisAI currently supports PyTorch (libtorch), Tensorflow (libtensorflow) (max version is 1.15.0), TensorFlow Lite, and ONNXRuntime as backends; Keras and TensorFlow 2.x are supported through graph freezing.  Note that a frozen graph will be executed using the TensorFlow 1.15 backend.\n",
    "\n",
    "We export a frozen graph from Keras and TensorFlow 2.xs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/leimao/Frozen-Graph-TensorFlow/blob/master/TensorFlow_v2/example_2.py\n",
    "\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "\n",
    "full_model = tf.function(lambda x: model(x))\n",
    "full_model = full_model.get_concrete_function(\n",
    "    x=tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
    "\n",
    "# Get frozen ConcreteFunction\n",
    "frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "frozen_func.graph.as_graph_def()\n",
    "\n",
    "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model layers: \")\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model Serving with BentoML\n",
    "\n",
    "## Custom Artifact with Redisai\n",
    "\n",
    "If you are new to RedisAI and trying it out for the first time, you might not know the setup already (although it's quite easy to setup a local RedisAI instance). In that's the case, you need pull the latest docker image of RedisAI (yes, you need docker installed in your machine for this to work), run it on the default port, deploy the model you specified.\n",
    "\n",
    "Run docker redisai if cpu:\n",
    "```\n",
    "docker run -dp 6379:6379 -it --rm  redislabs/redisai:edge-cpu-bionic\n",
    "```\n",
    "and if gpu:\n",
    "```\n",
    "docker run -p 6379:6379 --gpus all -it --rm redislabs/redisai:edge-gpu-bionic\n",
    "```\n",
    "\n",
    "See all tag image rediasai [here](https://hub.docker.com/r/redislabs/redisai/tags?page=1&ordering=last_updated). \n",
    "\n",
    "PS: It's IMPORTANT to note that this API leaves the docker container running. You would need to manually stop the container once you are done with experimentation. Also, remember that if you trying to run this API twice without killing the first container, it throws an error saying the port is already in use.\n",
    "\n",
    "Here we will use redisai cpu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -dp 6379:6379 -it --rm  redislabs/redisai:edge-cpu-bionic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a subclass from the BentoServiceArtifact. It implements how to save and load the model.\n",
    "\n",
    "In the initialization of the artifact, we have the following parameters:\n",
    "\n",
    "- backend : the backend used by the model as a String\n",
    "- device : the device used to execute the model as a String\n",
    "- inputs : array reply with one or more names of the model's input nodes (applicable only for TensorFlow models). \n",
    "- outputs : array reply with one or more names of the model's output nodes (applicable only for TensorFlow models)\n",
    "\n",
    "**Here, names of the model's input nodes is 'x' and outputs note is 'Identity' (see Frozen model layers above)**\n",
    "\n",
    "This code was built based on A plugin that integrates RedisAI with MLflow pipeline https://github.com/RedisAI/mlflow-redisai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile redisai_artifact.py\n",
    "import os\n",
    "from bentoml.exceptions import (\n",
    "    BentoMLException,\n",
    "    InvalidArgument,\n",
    "    MissingDependencyException,\n",
    ")\n",
    "\n",
    "from bentoml.service.artifacts import BentoServiceArtifact\n",
    "import redisai as rai\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Connection parameters\n",
    "class Config(dict):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self['host'] = 'localhost'\n",
    "        self['port'] = 6379\n",
    "        self['username'] = None\n",
    "        self['password'] = None\n",
    "        self['db'] = 0\n",
    "\n",
    "\n",
    "SUPPORTED_BACKEND = [\"torch\", \"tf\", \"onnx\"]\n",
    "file_extension = {\n",
    "    'torch': '.pt',\n",
    "    'tf'   : '.pb',\n",
    "    'onnx' : '.onnx'}\n",
    "\n",
    "\n",
    "class RedisaiArtifact(BentoServiceArtifact):\n",
    "    def __init__(self, name, backend='torch', input=None, output=None, device='cpu'):\n",
    "        super(RedisaiArtifact, self).__init__(name)\n",
    "        if backend not in SUPPORTED_BACKEND:\n",
    "            raise BentoMLException(\n",
    "                f'\"{backend}\" runtime is currently not supported for RedisaiArtifact'\n",
    "            )\n",
    "        server_config = Config()\n",
    "        # Connecting to a RedisAI \n",
    "        self.con = rai.Client(**server_config)\n",
    "        self._input = input\n",
    "        self._output = output\n",
    "        self._backend = backend\n",
    "        self._device = device\n",
    "        self._model = None\n",
    "\n",
    "    def pack(self, model):\n",
    "        if self._backend == 'torch':\n",
    "            try:\n",
    "                import torch\n",
    "            except ImportError:\n",
    "                raise MissingDependencyException(\n",
    "                    \"torch package is required to use RedisaiArtifact\"\n",
    "                )\n",
    "\n",
    "            if not isinstance(model, torch.nn.Module):\n",
    "                raise InvalidArgument(\n",
    "                    \"RedisaiArtifact can only pack type 'torch.jit.ScriptModule'\"\n",
    "                )\n",
    "\n",
    "        elif self._backend == 'tf':\n",
    "            try:\n",
    "                import tensorflow as tf\n",
    "\n",
    "            except ImportError:\n",
    "                raise MissingDependencyException(\n",
    "                    \"Tensorflow package is required to use RedisaiArtifact.\"\n",
    "                )\n",
    "\n",
    "        elif self._backend == 'onnx':\n",
    "            try:\n",
    "                import onnx\n",
    "\n",
    "                if not isinstance(model, onnx.ModelProto):\n",
    "                    raise InvalidArgument(\n",
    "                        \"onnx.ModelProto model file path is required to \"\n",
    "                        \"pack an RedisaiArtifact\"\n",
    "                    )\n",
    "\n",
    "            except ImportError:\n",
    "                raise InvalidArgument(\n",
    "                    \"ONNX package is required to use RedisaiArtifact.\"\n",
    "                )\n",
    "\n",
    "        self._model = model\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get(self):\n",
    "        return self.con\n",
    "\n",
    "    def save(self, dst):\n",
    "\n",
    "        if self._backend == 'torch':\n",
    "            import torch\n",
    "\n",
    "            if self._model.training is True:\n",
    "                logger.warn('Graph is in training mode. Converting to evaluation mode')\n",
    "\n",
    "                self._model.eval()\n",
    "\n",
    "            torch.jit.save(self._model, self._file_path(dst))\n",
    "\n",
    "        elif self._backend == 'tf':\n",
    "            import tensorflow as tf\n",
    "\n",
    "            TF2 = tf.__version__.startswith('2')\n",
    "            if TF2:\n",
    "                tf.io.write_graph(graph_or_graph_def=self._model.graph,\n",
    "                                  logdir=dst,\n",
    "                                  name=self.name + file_extension[self._backend],\n",
    "                                  as_text=False)\n",
    "            else:\n",
    "                tf.compat.v1.disable_eager_execution()\n",
    "                tf.train.write_graph(self._model, dst, self.name + file_extension[self._backend], as_text=False)\n",
    "\n",
    "        elif self._backend == 'onnx':\n",
    "            import onnx\n",
    "            onnx.save_model(self._model, self._file_path(dst))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def load(self, path):\n",
    "        with open(self._file_path(path), 'rb') as f:\n",
    "            model_redisai = f.read()\n",
    "\n",
    "        self.con.modelstore(self.name, self._backend, self._device, model_redisai, inputs=self._input,\n",
    "                            outputs=self._output)\n",
    "\n",
    "\n",
    "    def _file_path(self, base_path):\n",
    "        return os.path.join(base_path, self.name + file_extension[self._backend])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and save BentoService with the custom Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tensorflow_fashion_mnist.py\n",
    "from typing import List, BinaryIO\n",
    "import bentoml\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# from bentoml.frameworks.tensorflow import TensorflowSavedModelArtifact\n",
    "from redisai_artifact import RedisaiArtifact\n",
    "from bentoml.adapters import FileInput\n",
    "from bentoml import BentoService, env, api, artifacts\n",
    "\n",
    "FASHION_MNIST_CLASSES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "\n",
    "@env(pip_packages=['tensorflow', 'numpy', 'pillow'])\n",
    "# @artifacts([TensorflowSavedModelArtifact('model')])\n",
    "@artifacts([RedisaiArtifact('model', 'tf', 'x', 'Identity')])\n",
    "class FashionMnistTensorflow(BentoService):\n",
    "\n",
    "    @api(input=FileInput(), batch=True)\n",
    "    def predict(self, file_streams: List[BinaryIO]) -> List[str]:\n",
    "        inputs = []\n",
    "        \n",
    "        for fs in file_streams:\n",
    "            print(fs)\n",
    "            img = Image.open(fs)\n",
    "            img = np.array(img)/225\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            inputs.append(img)\n",
    "        imgs = np.vstack(inputs).astype(dtype=np.float32)    \n",
    "        \n",
    "        con = self.artifacts.model\n",
    "        con.tensorset('x', imgs, dtype='float')\n",
    " \n",
    "        con.modelrun('model', 'x', 'Identity')\n",
    "        outputs = con.tensorget('Identity')\n",
    "        output_classes = outputs.argmax(axis=1)\n",
    "\n",
    "        return [FASHION_MNIST_CLASSES[c] for c in output_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can instantiate a BentoService defined above with the trained model, and save the entire BentoService to a file archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_fashion_mnist import FashionMnistTensorflow\n",
    "\n",
    "bento_svc = FashionMnistTensorflow()\n",
    "bento_svc.pack(\"model\", frozen_func)\n",
    "saved_path = bento_svc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BentoService with BentoML CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService Name>` list all of BentoService's versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml get FashionMnistTensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService name>:<bentoService version>` display detailed information of the specific BentoService version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml get FashionMnistTensorflow:latest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Serve bentoml REST server locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve FashionMnistTensorflow:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a terminal and go to the directory of the current notebook, then run the following command to evaluate.\n",
    "\n",
    "```bash\n",
    "curl -X POST \"http://127.0.0.1:5000/predict\" -H \"Content-Type: image/*\" --data-binary \"@test.png\"\n",
    "```\n",
    "\n",
    "alternatively:\n",
    "```bash\n",
    "curl -X POST \"http://127.0.0.1:5000/predict\" -F image=@test.png\n",
    "```\n",
    "\n",
    "\n",
    "Go visit http://127.0.0.1:5000/ from your browser, click `/predict` -> `Try it out` -> `Choose File` -> `Execute` to sumbit an image from your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the DataframeInput adapter, the CLI command supports reading input Dataframe data from CLI argument or local csv or json files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml run FashionMnistTensorflow:latest predict  --input-file test.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Options\n",
    "\n",
    "If you are at a small team with limited engineering or DevOps resources, try out automated deployment with BentoML CLI, currently supporting AWS Lambda, AWS SageMaker, and Azure Functions:\n",
    "- [AWS Lambda Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_lambda.html)\n",
    "- [AWS SageMaker Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_sagemaker.html)\n",
    "- [Azure Functions Deployment Guide](https://docs.bentoml.org/en/latest/deployment/azure_functions.html)\n",
    "\n",
    "If the cloud platform you are working with is not on the list above, try out these step-by-step guide on manually deploying BentoML packaged model to cloud platforms:\n",
    "- [AWS ECS Deployment](https://docs.bentoml.org/en/latest/deployment/aws_ecs.html)\n",
    "- [Google Cloud Run Deployment](https://docs.bentoml.org/en/latest/deployment/google_cloud_run.html)\n",
    "- [Azure container instance Deployment](https://docs.bentoml.org/en/latest/deployment/azure_container_instance.html)\n",
    "- [Heroku Deployment](https://docs.bentoml.org/en/latest/deployment/heroku.html)\n",
    "\n",
    "Lastly, if you have a DevOps or ML Engineering team who's operating a Kubernetes or OpenShift cluster, use the following guides as references for implementating your deployment strategy:\n",
    "- [Kubernetes Deployment](https://docs.bentoml.org/en/latest/deployment/kubernetes.html)\n",
    "- [Knative Deployment](https://docs.bentoml.org/en/latest/deployment/knative.html)\n",
    "- [Kubeflow Deployment](https://docs.bentoml.org/en/latest/deployment/kubeflow.html)\n",
    "- [KFServing Deployment](https://docs.bentoml.org/en/latest/deployment/kfserving.html)\n",
    "- [Clipper.ai Deployment Guide](https://docs.bentoml.org/en/latest/deployment/clipper.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "redisai",
   "language": "python",
   "name": "redisai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
