{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a682ea0b",
   "metadata": {},
   "source": [
    "# BentoML PyTorch MNIST Tutorial\n",
    "\n",
    "Link to source code: https://github.com/bentoml/gallery/tree/main/pytorch_yolov5_torchhub/\n",
    "\n",
    "Install required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad00863",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45393b74",
   "metadata": {},
   "source": [
    "## Load the pre-trained model from Torch Hub\n",
    "\n",
    "take `ultralytics/yolov5` as the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee440480-fec6-4da1-a38b-e70fd5dab70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 12446, done.\u001b[K\n",
      "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
      "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
      "remote: Total 12446 (delta 24), reused 14 (delta 4), pack-reused 12400\u001b[K\n",
      "Receiving objects: 100% (12446/12446), 12.43 MiB | 5.75 MiB/s, done.\n",
      "Resolving deltas: 100% (8523/8523), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone 'https://github.com/ultralytics/yolov5.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae5cf59-8423-49d3-a2d4-d5837ce94c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-8-3 Python-3.10.5 torch-1.12.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "original_model = torch.hub.load(\".\", \"yolov5s\", pretrained=True, source=\"local\")\n",
    "\n",
    "\n",
    "class WrapperModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        print(imgs)\n",
    "        outputs = self.model(imgs)\n",
    "\n",
    "        # convert outputs to a json serializable list\n",
    "        results = []\n",
    "        for det in outputs.pred:\n",
    "            detections = []\n",
    "            for i in det:\n",
    "                d = {}\n",
    "                d[\"obj\"] = outputs.names[int(i[5])]\n",
    "                d[\"position\"] = i[:4].tolist()\n",
    "                d[\"prob\"] = i[4].tolist()\n",
    "                detections.append(d)\n",
    "            results.append(detections)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "model = WrapperModel(original_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0950faa2-256f-46ef-b7c1-62737a85ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c821e28-1001-4aae-91b0-5684d458be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[172, 148, 122],\n",
      "        [170, 146, 120],\n",
      "        [177, 153, 125],\n",
      "        ...,\n",
      "        [184, 170, 157],\n",
      "        [185, 171, 158],\n",
      "        [185, 171, 158]],\n",
      "\n",
      "       [[177, 153, 127],\n",
      "        [174, 150, 124],\n",
      "        [179, 155, 127],\n",
      "        ...,\n",
      "        [185, 171, 158],\n",
      "        [186, 172, 159],\n",
      "        [186, 172, 159]],\n",
      "\n",
      "       [[178, 154, 128],\n",
      "        [176, 152, 126],\n",
      "        [178, 154, 126],\n",
      "        ...,\n",
      "        [185, 171, 158],\n",
      "        [185, 171, 158],\n",
      "        [185, 171, 158]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[191, 185, 185],\n",
      "        [188, 182, 182],\n",
      "        [185, 179, 179],\n",
      "        ...,\n",
      "        [112, 107, 114],\n",
      "        [111, 105, 115],\n",
      "        [112, 106, 116]],\n",
      "\n",
      "       [[163, 157, 157],\n",
      "        [186, 180, 180],\n",
      "        [190, 186, 185],\n",
      "        ...,\n",
      "        [103,  97, 107],\n",
      "        [ 98,  92, 102],\n",
      "        [104,  98, 108]],\n",
      "\n",
      "       [[118, 112, 112],\n",
      "        [166, 160, 160],\n",
      "        [174, 170, 169],\n",
      "        ...,\n",
      "        [ 95,  89,  99],\n",
      "        [ 92,  86,  96],\n",
      "        [ 98,  92, 102]]], dtype=uint8), array([[[72, 48, 38],\n",
      "        [74, 50, 40],\n",
      "        [73, 51, 40],\n",
      "        ...,\n",
      "        [56, 21, 25],\n",
      "        [55, 19, 21],\n",
      "        [51, 15, 17]],\n",
      "\n",
      "       [[71, 47, 37],\n",
      "        [71, 47, 37],\n",
      "        [70, 48, 37],\n",
      "        ...,\n",
      "        [55, 20, 24],\n",
      "        [52, 16, 18],\n",
      "        [47, 11, 13]],\n",
      "\n",
      "       [[75, 51, 41],\n",
      "        [73, 49, 39],\n",
      "        [70, 48, 37],\n",
      "        ...,\n",
      "        [56, 20, 24],\n",
      "        [52, 16, 20],\n",
      "        [48, 12, 16]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[40, 43, 48],\n",
      "        [41, 44, 49],\n",
      "        [40, 43, 48],\n",
      "        ...,\n",
      "        [35, 49, 49],\n",
      "        [35, 49, 49],\n",
      "        [36, 50, 50]],\n",
      "\n",
      "       [[39, 42, 49],\n",
      "        [39, 42, 49],\n",
      "        [39, 42, 49],\n",
      "        ...,\n",
      "        [35, 49, 50],\n",
      "        [35, 49, 50],\n",
      "        [36, 50, 51]],\n",
      "\n",
      "       [[38, 41, 48],\n",
      "        [38, 41, 48],\n",
      "        [38, 41, 48],\n",
      "        ...,\n",
      "        [35, 49, 50],\n",
      "        [35, 49, 50],\n",
      "        [36, 50, 51]]], dtype=uint8)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'obj': 'person',\n",
       "   'position': [220.8684844970703,\n",
       "    407.4215087890625,\n",
       "    345.7237854003906,\n",
       "    874.6875610351562],\n",
       "   'prob': 0.83514803647995},\n",
       "  {'obj': 'person',\n",
       "   'position': [662.5741577148438,\n",
       "    386.1648254394531,\n",
       "    810.0,\n",
       "    880.3662719726562],\n",
       "   'prob': 0.8289433717727661},\n",
       "  {'obj': 'person',\n",
       "   'position': [57.57133865356445,\n",
       "    397.30712890625,\n",
       "    214.79830932617188,\n",
       "    918.2418212890625],\n",
       "   'prob': 0.7853637337684631},\n",
       "  {'obj': 'bus',\n",
       "   'position': [14.668447494506836,\n",
       "    222.18931579589844,\n",
       "    798.4093627929688,\n",
       "    784.870849609375],\n",
       "   'prob': 0.7814343571662903},\n",
       "  {'obj': 'person',\n",
       "   'position': [0.0, 553.4059448242188, 72.45738983154297, 874.6781616210938],\n",
       "   'prob': 0.4649430215358734}],\n",
       " [{'obj': 'person',\n",
       "   'position': [742.89697265625,\n",
       "    47.978546142578125,\n",
       "    1141.1422119140625,\n",
       "    716.822998046875],\n",
       "   'prob': 0.8807235956192017},\n",
       "  {'obj': 'tie',\n",
       "   'position': [442.0389709472656,\n",
       "    437.349853515625,\n",
       "    496.7195739746094,\n",
       "    709.8829345703125],\n",
       "   'prob': 0.6872661113739014},\n",
       "  {'obj': 'person',\n",
       "   'position': [125.21511840820312,\n",
       "    193.6068115234375,\n",
       "    710.8411865234375,\n",
       "    713.0703125],\n",
       "   'prob': 0.642234206199646},\n",
       "  {'obj': 'tie',\n",
       "   'position': [982.893310546875,\n",
       "    308.404541015625,\n",
       "    1027.32958984375,\n",
       "    420.2301025390625],\n",
       "   'prob': 0.2630458176136017}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Images\n",
    "imgs = [\n",
    "    np.array(PIL.Image.open(\"data/images/bus.jpg\")),\n",
    "    np.array(PIL.Image.open(\"data/images/zidane.jpg\")),\n",
    "]  # batch of images\n",
    "\n",
    "model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2a8b2ec-875b-43d7-9d23-c9fa4c938a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Runner.init_local' is for debugging and testing only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[172, 148, 122],\n",
      "        [170, 146, 120],\n",
      "        [177, 153, 125],\n",
      "        ...,\n",
      "        [184, 170, 157],\n",
      "        [185, 171, 158],\n",
      "        [185, 171, 158]],\n",
      "\n",
      "       [[177, 153, 127],\n",
      "        [174, 150, 124],\n",
      "        [179, 155, 127],\n",
      "        ...,\n",
      "        [185, 171, 158],\n",
      "        [186, 172, 159],\n",
      "        [186, 172, 159]],\n",
      "\n",
      "       [[178, 154, 128],\n",
      "        [176, 152, 126],\n",
      "        [178, 154, 126],\n",
      "        ...,\n",
      "        [185, 171, 158],\n",
      "        [185, 171, 158],\n",
      "        [185, 171, 158]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[191, 185, 185],\n",
      "        [188, 182, 182],\n",
      "        [185, 179, 179],\n",
      "        ...,\n",
      "        [112, 107, 114],\n",
      "        [111, 105, 115],\n",
      "        [112, 106, 116]],\n",
      "\n",
      "       [[163, 157, 157],\n",
      "        [186, 180, 180],\n",
      "        [190, 186, 185],\n",
      "        ...,\n",
      "        [103,  97, 107],\n",
      "        [ 98,  92, 102],\n",
      "        [104,  98, 108]],\n",
      "\n",
      "       [[118, 112, 112],\n",
      "        [166, 160, 160],\n",
      "        [174, 170, 169],\n",
      "        ...,\n",
      "        [ 95,  89,  99],\n",
      "        [ 92,  86,  96],\n",
      "        [ 98,  92, 102]]], dtype=uint8), array([[[72, 48, 38],\n",
      "        [74, 50, 40],\n",
      "        [73, 51, 40],\n",
      "        ...,\n",
      "        [56, 21, 25],\n",
      "        [55, 19, 21],\n",
      "        [51, 15, 17]],\n",
      "\n",
      "       [[71, 47, 37],\n",
      "        [71, 47, 37],\n",
      "        [70, 48, 37],\n",
      "        ...,\n",
      "        [55, 20, 24],\n",
      "        [52, 16, 18],\n",
      "        [47, 11, 13]],\n",
      "\n",
      "       [[75, 51, 41],\n",
      "        [73, 49, 39],\n",
      "        [70, 48, 37],\n",
      "        ...,\n",
      "        [56, 20, 24],\n",
      "        [52, 16, 20],\n",
      "        [48, 12, 16]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[40, 43, 48],\n",
      "        [41, 44, 49],\n",
      "        [40, 43, 48],\n",
      "        ...,\n",
      "        [35, 49, 49],\n",
      "        [35, 49, 49],\n",
      "        [36, 50, 50]],\n",
      "\n",
      "       [[39, 42, 49],\n",
      "        [39, 42, 49],\n",
      "        [39, 42, 49],\n",
      "        ...,\n",
      "        [35, 49, 50],\n",
      "        [35, 49, 50],\n",
      "        [36, 50, 51]],\n",
      "\n",
      "       [[38, 41, 48],\n",
      "        [38, 41, 48],\n",
      "        [38, 41, 48],\n",
      "        ...,\n",
      "        [35, 49, 50],\n",
      "        [35, 49, 50],\n",
      "        [36, 50, 51]]], dtype=uint8)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'obj': 'person',\n",
       "   'position': [220.8684844970703,\n",
       "    407.4215087890625,\n",
       "    345.7237854003906,\n",
       "    874.6875610351562],\n",
       "   'prob': 0.83514803647995},\n",
       "  {'obj': 'person',\n",
       "   'position': [662.5741577148438,\n",
       "    386.1648254394531,\n",
       "    810.0,\n",
       "    880.3662719726562],\n",
       "   'prob': 0.8289433717727661},\n",
       "  {'obj': 'person',\n",
       "   'position': [57.57133865356445,\n",
       "    397.30712890625,\n",
       "    214.79830932617188,\n",
       "    918.2418212890625],\n",
       "   'prob': 0.7853637337684631},\n",
       "  {'obj': 'bus',\n",
       "   'position': [14.668447494506836,\n",
       "    222.18931579589844,\n",
       "    798.4093627929688,\n",
       "    784.870849609375],\n",
       "   'prob': 0.7814343571662903},\n",
       "  {'obj': 'person',\n",
       "   'position': [0.0, 553.4059448242188, 72.45738983154297, 874.6781616210938],\n",
       "   'prob': 0.4649430215358734}],\n",
       " [{'obj': 'person',\n",
       "   'position': [742.89697265625,\n",
       "    47.978546142578125,\n",
       "    1141.1422119140625,\n",
       "    716.822998046875],\n",
       "   'prob': 0.8807235956192017},\n",
       "  {'obj': 'tie',\n",
       "   'position': [442.0389709472656,\n",
       "    437.349853515625,\n",
       "    496.7195739746094,\n",
       "    709.8829345703125],\n",
       "   'prob': 0.6872661113739014},\n",
       "  {'obj': 'person',\n",
       "   'position': [125.21511840820312,\n",
       "    193.6068115234375,\n",
       "    710.8411865234375,\n",
       "    713.0703125],\n",
       "   'prob': 0.642234206199646},\n",
       "  {'obj': 'tie',\n",
       "   'position': [982.893310546875,\n",
       "    308.404541015625,\n",
       "    1027.32958984375,\n",
       "    420.2301025390625],\n",
       "   'prob': 0.2630458176136017}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = bentoml.pytorch.get(\"yolo\").to_runner()\n",
    "runner.init_local()\n",
    "arr = np.array(PIL.Image.open(\"data/images/bus.jpg\"))\n",
    "runner.run(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38888f0a",
   "metadata": {},
   "source": [
    "## Training and Saving the model\n",
    "\n",
    "Then we define a simple PyTorch network and some helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9b23c",
   "metadata": {},
   "source": [
    "### saving the model with some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "048518a2-9a87-4672-8807-2e180534bab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully saved Model(tag=\"yolo:erxus7qtvssc7gxi\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(tag=\"yolo:erxus7qtvssc7gxi\", path=\"/Users/aarnphm/bentoml/models/yolo/erxus7qtvssc7gxi/\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "bentoml.pytorch.save_model(\n",
    "    \"yolo\",\n",
    "    model,\n",
    "    signatures={\"__call__\": {\"batchable\": True, \"batchdim\": 0}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf35e55",
   "metadata": {},
   "source": [
    "## Create a BentoML Service for serving the model\n",
    "\n",
    "Note: using `%%writefile` here because `bentoml.Service` instance must be created in a separate `.py` file\n",
    "\n",
    "Even though we have only one model, we can create as many api endpoints as we want. Here we create two end points `predict_ndarray` and `predict_image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e2f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import typing as t\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import bentoml\n",
    "from bentoml.io import Image\n",
    "from bentoml.io import JSON\n",
    "\n",
    "\n",
    "yolo_runner = bentoml.pytorch.get(\"yolo\").to_runner()\n",
    "\n",
    "svc = bentoml.Service(\n",
    "    name=\"pytorch_yolo_demo\",\n",
    "    runners=[yolo_runner],\n",
    ")\n",
    "\n",
    "@svc.api(input=Image(), output=JSON())\n",
    "async def predict_image(img: PIL.Image.Image) -> list:\n",
    "    assert isinstance(img, PIL.Image.Image)\n",
    "    return await yolo_runner.async_run([np.array(img)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590147aa",
   "metadata": {},
   "source": [
    "Start a dev model server to test out the service defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29173871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-03T15:03:37-0700 [INFO] [cli] Starting development BentoServer from \"service.py:svc\" running on http://127.0.0.1:3000 (Press CTRL+C to quit)\n",
      "2022-08-03T15:03:38-0700 [INFO] [dev_api_server] Application startup complete.\n",
      "Application startup complete.\n",
      "2022-08-03T15:03:39-0700 [INFO] [dev_api_server] 127.0.0.1:52399 - \"GET /predict_image HTTP/1.1\" 405 (trace=309718792821503138221890529290886270006,span=7761146729387849767,sampled=0)\n",
      "127.0.0.1:52399 - \"GET /predict_image HTTP/1.1\" 405\n",
      "2022-08-03T15:03:39-0700 [INFO] [dev_api_server] 127.0.0.1:52399 (scheme=http,method=GET,path=/predict_image,type=,length=) (status=405,type=text/plain; charset=utf-8,length=18) 0.041ms (trace=309718792821503138221890529290886270006,span=8052578800026703988,sampled=0)\n",
      "2022-08-03T15:03:39-0700 [INFO] [dev_api_server] 127.0.0.1:52399 - \"GET /favicon.ico HTTP/1.1\" 404 (trace=7885246619689750063735489602899778642,span=4292379705180510720,sampled=0)\n",
      "127.0.0.1:52399 - \"GET /favicon.ico HTTP/1.1\" 404\n",
      "2022-08-03T15:03:39-0700 [INFO] [dev_api_server] 127.0.0.1:52399 (scheme=http,method=GET,path=/favicon.ico,type=,length=) (status=404,type=text/plain; charset=utf-8,length=9) 0.002ms (trace=7885246619689750063735489602899778642,span=2559606266397040752,sampled=0)\n",
      "2022-08-03T15:03:45-0700 [ERROR] [dev_api_server] Exception on /predict_image [POST] (trace=145738999799465846813986344509624300930,span=3193917975601576449,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aarnphm/workspace/bentoml/aarnphm_fork/bentoml/_internal/server/service_app.py\", line 300, in api_func\n",
      "    output = await api.func(input_data)\n",
      "  File \"/Users/aarnphm/workspace/bentoml/gallery/pytorch_yolov5_torchhub/service.py\", line 27, in predict_image\n",
      "    return await yolo_runner.async_run([np.array(img)])\n",
      "  File \"/Users/aarnphm/workspace/bentoml/aarnphm_fork/bentoml/_internal/runner/runner.py\", line 47, in async_run\n",
      "    return await self.runner._runner_handle.async_run_method(  # type: ignore\n",
      "  File \"/Users/aarnphm/workspace/bentoml/aarnphm_fork/bentoml/_internal/runner/runner_handle/local.py\", line 57, in async_run_method\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/Users/aarnphm/.pyenv/versions/3.10.5/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/aarnphm/.pyenv/versions/3.10.5/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/aarnphm/.pyenv/versions/3.10.5/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/aarnphm/workspace/bentoml/aarnphm_fork/bentoml/_internal/runner/runnable.py\", line 136, in method\n",
      "    return self.func(obj, *args, **kwargs)\n",
      "  File \"/Users/aarnphm/workspace/bentoml/aarnphm_fork/bentoml/_internal/frameworks/common/pytorch.py\", line 102, in _run\n",
      "    params = params.map(_mapping)\n",
      "  File \"/Users/aarnphm/workspace/bentoml/aarnphm_fork/bentoml/_internal/runner/utils.py\", line 68, in map\n",
      "    args = tuple(function(a) for a in self.args)\n",
      "  File \"/Users/aarnphm/workspace/bentoml/aarnphm_fork/bentoml/_internal/runner/utils.py\", line 68, in <genexpr>\n",
      "    args = tuple(function(a) for a in self.args)\n",
      "  File \"/Users/aarnphm/workspace/bentoml/aarnphm_fork/bentoml/_internal/frameworks/common/pytorch.py\", line 99, in _mapping\n",
      "    return item.to(self.device_id)  # type: ignore # the overhead is trivial if it is already on the right device\n",
      "AttributeError: 'list' object has no attribute 'to'\n",
      "2022-08-03T15:03:45-0700 [INFO] [dev_api_server] 127.0.0.1:52403 - \"POST /predict_image HTTP/1.1\" 500 (trace=145738999799465846813986344509624300930,span=3601462412572963500,sampled=0)\n",
      "127.0.0.1:52403 - \"POST /predict_image HTTP/1.1\" 500\n",
      "2022-08-03T15:03:45-0700 [INFO] [dev_api_server] 127.0.0.1:52403 (scheme=http,method=POST,path=/predict_image,type=multipart/form-data; boundary=------------------------b4cd2c5fb0362c35,length=487625) (status=500,type=application/json,length=110) 0.021ms (trace=145738999799465846813986344509624300930,span=3193917975601576449,sampled=0)\n",
      "^C\n",
      "2022-08-03T15:03:50-0700 [INFO] [dev_api_server] Shutting down\n",
      "Shutting down\n",
      "2022-08-03T15:03:50-0700 [INFO] [dev_api_server] Waiting for application shutdown.\n",
      "Waiting for application shutdown.\n",
      "2022-08-03T15:03:50-0700 [INFO] [dev_api_server] Application shutdown complete.\n",
      "Application shutdown complete.\n",
      "2022-08-03T15:03:50-0700 [INFO] [dev_api_server] Finished server process [48539]\n",
      "Finished server process [48539]\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service.py:svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c1b36",
   "metadata": {},
   "source": [
    "Now you can use something like:\n",
    "\n",
    "`curl -H \"Content-Type: multipart/form-data\" -F'fileobj=@yolov5/data/images/bus.jpg;type=image/png' http://127.0.0.1:3000/predict_image`\n",
    "    \n",
    "to send an image to the digit recognition service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f03564",
   "metadata": {},
   "source": [
    "## Build a Bento for distribution and deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36306933",
   "metadata": {},
   "source": [
    "Starting a dev server with the Bento build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01436c-a244-4504-bf05-1bbdef5d815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve pytorch_yolo_demo:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fae93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "name": "pytorch_mnist.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
